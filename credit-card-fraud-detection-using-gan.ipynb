{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-12-22T15:56:56.412925Z",
     "iopub.status.busy": "2023-12-22T15:56:56.412556Z",
     "iopub.status.idle": "2023-12-22T15:56:56.461768Z",
     "shell.execute_reply": "2023-12-22T15:56:56.460731Z",
     "shell.execute_reply.started": "2023-12-22T15:56:56.412863Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from keras.layers import Input, Embedding, multiply, BatchNormalization\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers.core import Reshape, Dense, Dropout, Flatten\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import Conv2D, UpSampling2D\n",
    "from keras.datasets import mnist\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "from keras import initializers\n",
    "from keras.utils import to_categorical\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "# Deterministic output.\n",
    "# Tired of seeing the same results every time? Remove the line below.\n",
    "np.random.seed(1000)\n",
    "\n",
    "# The results are a little better when the dimensionality of the random vector is only 10.\n",
    "# The dimensionality has been left at 100 for consistency with other GAN implementations.\n",
    "randomDim = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "1fa9c421-e3e1-4a2c-978f-28f78e01ab34",
    "_uuid": "04bcbe2c5f6b3f74f6f8732c41e8e8e15654d311",
    "execution": {
     "iopub.execute_input": "2023-12-22T15:56:56.464185Z",
     "iopub.status.busy": "2023-12-22T15:56:56.463696Z",
     "iopub.status.idle": "2023-12-22T15:56:56.478255Z",
     "shell.execute_reply": "2023-12-22T15:56:56.477337Z",
     "shell.execute_reply.started": "2023-12-22T15:56:56.464089Z"
    }
   },
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2023-12-22T15:56:56.480350Z",
     "iopub.status.busy": "2023-12-22T15:56:56.479885Z",
     "iopub.status.idle": "2023-12-22T15:57:01.599563Z",
     "shell.execute_reply": "2023-12-22T15:57:01.598530Z",
     "shell.execute_reply.started": "2023-12-22T15:56:56.480277Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../input/creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "ad3d861f-12e4-49ca-a221-6d8bd6be6f8a",
    "_uuid": "24bc772bdd624e7d844b74020e273ffe3def4246",
    "execution": {
     "iopub.execute_input": "2023-12-22T15:57:01.601857Z",
     "iopub.status.busy": "2023-12-22T15:57:01.601441Z",
     "iopub.status.idle": "2023-12-22T15:57:01.652934Z",
     "shell.execute_reply": "2023-12-22T15:57:01.651888Z",
     "shell.execute_reply.started": "2023-12-22T15:57:01.601780Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...         V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...   -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ...   -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...    0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...   -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "ac5f5f90-1607-4c5e-b0e7-845c724c7521",
    "_uuid": "7f9f454f8341834b0c6ab1a3de99b2577dcd7dd0",
    "execution": {
     "iopub.execute_input": "2023-12-22T15:57:01.655055Z",
     "iopub.status.busy": "2023-12-22T15:57:01.654566Z",
     "iopub.status.idle": "2023-12-22T15:57:02.416117Z",
     "shell.execute_reply": "2023-12-22T15:57:02.415272Z",
     "shell.execute_reply.started": "2023-12-22T15:57:01.654976Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>3.919560e-15</td>\n",
       "      <td>5.688174e-16</td>\n",
       "      <td>-8.769071e-15</td>\n",
       "      <td>2.782312e-15</td>\n",
       "      <td>-1.552563e-15</td>\n",
       "      <td>2.010663e-15</td>\n",
       "      <td>-1.694249e-15</td>\n",
       "      <td>-1.927028e-16</td>\n",
       "      <td>-3.137024e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.537294e-16</td>\n",
       "      <td>7.959909e-16</td>\n",
       "      <td>5.367590e-16</td>\n",
       "      <td>4.458112e-15</td>\n",
       "      <td>1.453003e-15</td>\n",
       "      <td>1.699104e-15</td>\n",
       "      <td>-3.660161e-16</td>\n",
       "      <td>-1.206049e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  3.919560e-15  5.688174e-16 -8.769071e-15  2.782312e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean  -1.552563e-15  2.010663e-15 -1.694249e-15 -1.927028e-16 -3.137024e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "           ...                 V21           V22           V23           V24  \\\n",
       "count      ...        2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean       ...        1.537294e-16  7.959909e-16  5.367590e-16  4.458112e-15   \n",
       "std        ...        7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min        ...       -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%        ...       -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%        ...       -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%        ...        1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max        ...        2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   1.453003e-15  1.699104e-15 -3.660161e-16 -1.206049e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "8f0c6894-0f3c-4f1a-9b2e-5155cc434ab8",
    "_uuid": "ae27e9aac252b8abebe73a7f152e8285f6ae6671",
    "execution": {
     "iopub.execute_input": "2023-12-22T15:57:02.418331Z",
     "iopub.status.busy": "2023-12-22T15:57:02.417810Z",
     "iopub.status.idle": "2023-12-22T15:57:02.690524Z",
     "shell.execute_reply": "2023-12-22T15:57:02.689486Z",
     "shell.execute_reply.started": "2023-12-22T15:57:02.418254Z"
    }
   },
   "outputs": [],
   "source": [
    "df.isnull().sum().any()\n",
    "df = df.drop('Time',axis=1)\n",
    "X = df.drop('Class',axis=1).values \n",
    "y = df['Class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "5788dbeb-8aa2-42a5-99af-b4e367de3808",
    "_uuid": "66ce9da4edfea3e8b6619d5f543b365899a59a5e",
    "execution": {
     "iopub.execute_input": "2023-12-22T15:57:02.692571Z",
     "iopub.status.busy": "2023-12-22T15:57:02.692053Z",
     "iopub.status.idle": "2023-12-22T15:57:02.787161Z",
     "shell.execute_reply": "2023-12-22T15:57:02.786323Z",
     "shell.execute_reply.started": "2023-12-22T15:57:02.692493Z"
    }
   },
   "outputs": [],
   "source": [
    "X -= X.min(axis=0)\n",
    "X /= X.max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "78e7cc64-e345-45c4-8c4e-52aa50cb9c21",
    "_uuid": "156872c244cdf82a28daa404fe1ebaaa96c52d0d",
    "execution": {
     "iopub.execute_input": "2023-12-22T15:57:02.788858Z",
     "iopub.status.busy": "2023-12-22T15:57:02.788558Z",
     "iopub.status.idle": "2023-12-22T15:57:03.104064Z",
     "shell.execute_reply": "2023-12-22T15:57:03.103132Z",
     "shell.execute_reply.started": "2023-12-22T15:57:02.788816Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train,y_test = train_test_split(X,y,test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "0e0dc6cbb6ba7841c404ad1722a1bf957b9c0c71",
    "execution": {
     "iopub.execute_input": "2023-12-22T15:57:03.106086Z",
     "iopub.status.busy": "2023-12-22T15:57:03.105682Z",
     "iopub.status.idle": "2023-12-22T15:57:03.136533Z",
     "shell.execute_reply": "2023-12-22T15:57:03.135396Z",
     "shell.execute_reply.started": "2023-12-22T15:57:03.106005Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_generator(latent_dim,data_dim):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(16, input_dim=latent_dim))\n",
    "    \n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(32, input_dim=latent_dim))\n",
    "    \n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(data_dim,activation='tanh'))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=(latent_dim,))\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "dff92e28df4d9b059f7e302aff0d4d374f4380bc",
    "execution": {
     "iopub.execute_input": "2023-12-22T15:57:03.138229Z",
     "iopub.status.busy": "2023-12-22T15:57:03.137912Z",
     "iopub.status.idle": "2023-12-22T15:57:03.559316Z",
     "shell.execute_reply": "2023-12-22T15:57:03.558088Z",
     "shell.execute_reply.started": "2023-12-22T15:57:03.138174Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16)                176       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 29)                957       \n",
      "=================================================================\n",
      "Total params: 1,869\n",
      "Trainable params: 1,773\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator = build_generator(latent_dim=10,data_dim=29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "52ff75e25d1db36679536594e80073f1e98a8205",
    "execution": {
     "iopub.execute_input": "2023-12-22T15:57:03.561168Z",
     "iopub.status.busy": "2023-12-22T15:57:03.560828Z",
     "iopub.status.idle": "2023-12-22T15:57:03.586286Z",
     "shell.execute_reply": "2023-12-22T15:57:03.584807Z",
     "shell.execute_reply.started": "2023-12-22T15:57:03.561075Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_discriminator(data_dim,num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(31,input_dim=data_dim))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(16,input_dim=data_dim))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    model.summary()\n",
    "    img = Input(shape=(data_dim,))\n",
    "    features = model(img)\n",
    "    valid = Dense(1, activation=\"sigmoid\")(features)\n",
    "    label = Dense(num_classes+1, activation=\"softmax\")(features)\n",
    "    return Model(img, [valid, label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "c4497a47e1f8d9218ea5463f9476a7c3c7592369",
    "execution": {
     "iopub.execute_input": "2023-12-22T15:57:03.588503Z",
     "iopub.status.busy": "2023-12-22T15:57:03.587957Z",
     "iopub.status.idle": "2023-12-22T15:57:04.007061Z",
     "shell.execute_reply": "2023-12-22T15:57:04.006053Z",
     "shell.execute_reply.started": "2023-12-22T15:57:03.588434Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 31)                930       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 31)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 31)                124       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 31)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 16)                0         \n",
      "=================================================================\n",
      "Total params: 1,566\n",
      "Trainable params: 1,504\n",
      "Non-trainable params: 62\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator = build_discriminator(data_dim=29,num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "c29a35e4e0a2e9d0b349373c24ab0fae1bdf85f3",
    "execution": {
     "iopub.execute_input": "2023-12-22T15:57:04.009228Z",
     "iopub.status.busy": "2023-12-22T15:57:04.008715Z",
     "iopub.status.idle": "2023-12-22T15:57:04.083630Z",
     "shell.execute_reply": "2023-12-22T15:57:04.082509Z",
     "shell.execute_reply.started": "2023-12-22T15:57:04.009133Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = Adam(0.0002, 0.5)\n",
    "discriminator.compile(loss=['binary_crossentropy', 'categorical_crossentropy'],\n",
    "    loss_weights=[0.5, 0.5],\n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "868d72058acc8074c6144032890def6deb200def",
    "execution": {
     "iopub.execute_input": "2023-12-22T15:57:04.085842Z",
     "iopub.status.busy": "2023-12-22T15:57:04.085435Z",
     "iopub.status.idle": "2023-12-22T15:57:04.395381Z",
     "shell.execute_reply": "2023-12-22T15:57:04.394516Z",
     "shell.execute_reply.started": "2023-12-22T15:57:04.085760Z"
    }
   },
   "outputs": [],
   "source": [
    "noise = Input(shape=(10,))\n",
    "img = generator(noise)\n",
    "discriminator.trainable = False\n",
    "valid,_ = discriminator(img)\n",
    "combined = Model(noise , valid)\n",
    "combined.compile(loss=['binary_crossentropy'],\n",
    "    optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "e6a1493cf4397402463a18b85a2ae24d7ed93639",
    "execution": {
     "iopub.execute_input": "2023-12-22T15:57:04.397093Z",
     "iopub.status.busy": "2023-12-22T15:57:04.396794Z",
     "iopub.status.idle": "2023-12-22T15:57:04.402133Z",
     "shell.execute_reply": "2023-12-22T15:57:04.401178Z",
     "shell.execute_reply.started": "2023-12-22T15:57:04.397040Z"
    }
   },
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "faf05a4ef5cded3a5e21681d0956cebfbf9c2efb",
    "execution": {
     "iopub.execute_input": "2023-12-22T15:57:04.403877Z",
     "iopub.status.busy": "2023-12-22T15:57:04.403598Z",
     "iopub.status.idle": "2023-12-22T15:57:04.760085Z",
     "shell.execute_reply": "2023-12-22T15:57:04.759158Z",
     "shell.execute_reply.started": "2023-12-22T15:57:04.403823Z"
    }
   },
   "outputs": [],
   "source": [
    "X_res, y_res = rus.fit_sample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "3ee6d6276b542dbb9484e14dbd75156ba8e16efb",
    "execution": {
     "iopub.execute_input": "2023-12-22T15:57:04.761973Z",
     "iopub.status.busy": "2023-12-22T15:57:04.761639Z",
     "iopub.status.idle": "2023-12-22T15:57:04.767671Z",
     "shell.execute_reply": "2023-12-22T15:57:04.766522Z",
     "shell.execute_reply.started": "2023-12-22T15:57:04.761917Z"
    }
   },
   "outputs": [],
   "source": [
    "X_res -= X_res.min()\n",
    "X_res /= X_res.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "f906b0eb02f40139ed4ee9adde6e0175358d8cc4",
    "execution": {
     "iopub.execute_input": "2023-12-22T15:57:04.769602Z",
     "iopub.status.busy": "2023-12-22T15:57:04.769281Z",
     "iopub.status.idle": "2023-12-22T15:57:04.785778Z",
     "shell.execute_reply": "2023-12-22T15:57:04.784677Z",
     "shell.execute_reply.started": "2023-12-22T15:57:04.769540Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test -= X_test.min()\n",
    "X_test /= X_test.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "b85f188577271c544c6b82a133f70380a1ba303f",
    "execution": {
     "iopub.execute_input": "2023-12-22T15:57:04.787820Z",
     "iopub.status.busy": "2023-12-22T15:57:04.787352Z",
     "iopub.status.idle": "2023-12-22T15:57:04.819002Z",
     "shell.execute_reply": "2023-12-22T15:57:04.817976Z",
     "shell.execute_reply.started": "2023-12-22T15:57:04.787756Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test_res, y_test_res = rus.fit_sample(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "d0ed0b90189d4ae0ffad536db958905c0270d0b4",
    "execution": {
     "iopub.execute_input": "2023-12-22T15:57:04.820905Z",
     "iopub.status.busy": "2023-12-22T15:57:04.820552Z",
     "iopub.status.idle": "2023-12-22T15:57:04.828390Z",
     "shell.execute_reply": "2023-12-22T15:57:04.827192Z",
     "shell.execute_reply.started": "2023-12-22T15:57:04.820842Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "68eee475d3fa477523453ff78aeef868f36f6079",
    "execution": {
     "iopub.execute_input": "2023-12-22T15:57:04.830745Z",
     "iopub.status.busy": "2023-12-22T15:57:04.830136Z",
     "iopub.status.idle": "2023-12-22T15:57:05.131534Z",
     "shell.execute_reply": "2023-12-22T15:57:05.130640Z",
     "shell.execute_reply.started": "2023-12-22T15:57:04.830672Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(X_train,y_train,\n",
    "          X_test,y_test,\n",
    "          generator,discriminator,\n",
    "          combined,\n",
    "          num_classes,\n",
    "          epochs, \n",
    "          batch_size=128):\n",
    "    \n",
    "    f1_progress = []\n",
    "    d_loss_progress = []\n",
    "    half_batch = int(batch_size / 2)\n",
    "\n",
    "    noise_until = epochs\n",
    "\n",
    "    # Class weights:\n",
    "    # To balance the difference in occurences of digit class labels.\n",
    "    # 50% of labels that the discriminator trains on are 'fake'.\n",
    "    # Weight = 1 / frequency\n",
    "    cw1 = {0: 1, 1: 1}\n",
    "    cw2 = {i: num_classes / half_batch for i in range(num_classes)}\n",
    "    cw2[num_classes] = 1 / half_batch \n",
    "    d_loss_sum = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "        # Select a random half batch of images\n",
    "        idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "        imgs = X_train[idx]\n",
    "\n",
    "        # Sample noise and generate a half batch of new images\n",
    "        noise = np.random.normal(0, 1, (half_batch, 10))\n",
    "        gen_imgs = generator.predict(noise)\n",
    "\n",
    "        valid = np.ones((half_batch, 1))\n",
    "        fake = np.zeros((half_batch, 1))\n",
    "\n",
    "        labels = to_categorical(y_train[idx], num_classes=num_classes+1)\n",
    "        fake_labels = to_categorical(np.full((half_batch, 1), num_classes), num_classes=num_classes+1)\n",
    "\n",
    "        # Train the discriminator\n",
    "        d_loss_real = discriminator.train_on_batch(imgs, [valid, labels], class_weight=[cw1, cw2])\n",
    "        d_loss_fake = discriminator.train_on_batch(gen_imgs, [fake, fake_labels], class_weight=[cw1, cw2])\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Generator\n",
    "        # ---------------------\n",
    "\n",
    "        noise = np.random.normal(0, 1, (batch_size, 10))\n",
    "        validity = np.ones((batch_size, 1))\n",
    "\n",
    "        # Train the generator\n",
    "        g_loss = combined.train_on_batch(noise, validity, class_weight=[cw1, cw2])\n",
    "\n",
    "        # Plot the progress\n",
    "        print (\"%d [D loss: %f, acc: %.2f%%, op_acc: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[3], 100*d_loss[4], g_loss))\n",
    "        d_loss_sum += 100*d_loss[3]\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            _,y_pred = discriminator.predict(X_test,batch_size=batch_size)\n",
    "            #print(y_pred.shape)\n",
    "            y_pred = np.argmax(y_pred[:,:-1],axis=1)\n",
    "            \n",
    "            f1 = f1_score(y_test,y_pred)\n",
    "            print('Epoch: {}, F1: {:.5f}, F1P: {}'.format(epoch,f1,len(f1_progress)))\n",
    "            cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "            print(cm)\n",
    "            print(d_loss_sum/10)\n",
    "            d_loss_progress.append(d_loss_sum/10)\n",
    "            f1_progress.append(f1)\n",
    "            d_loss_sum = 0\n",
    "    \n",
    "    return f1_progress, d_loss_progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "bf5e4c217d9b0036e859b818561a9274d32027ce",
    "execution": {
     "iopub.execute_input": "2023-12-22T15:57:05.133311Z",
     "iopub.status.busy": "2023-12-22T15:57:05.132792Z",
     "iopub.status.idle": "2023-12-22T15:58:35.932355Z",
     "shell.execute_reply": "2023-12-22T15:58:35.931342Z",
     "shell.execute_reply.started": "2023-12-22T15:57:05.133245Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/Keras-2.1.5-py3.6.egg/keras/engine/training.py:973: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss: 0.451055, acc: 45.31%, op_acc: 24.22%] [G loss: 0.593363]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, F1: 0.00000, F1P: 0\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "4.53125\n",
      "1 [D loss: 0.442756, acc: 46.09%, op_acc: 25.78%] [G loss: 0.603959]\n",
      "2 [D loss: 0.451729, acc: 50.78%, op_acc: 32.03%] [G loss: 0.634167]\n",
      "3 [D loss: 0.460006, acc: 50.00%, op_acc: 26.56%] [G loss: 0.648444]\n",
      "4 [D loss: 0.444264, acc: 45.31%, op_acc: 26.56%] [G loss: 0.608890]\n",
      "5 [D loss: 0.458245, acc: 48.44%, op_acc: 28.91%] [G loss: 0.572532]\n",
      "6 [D loss: 0.435555, acc: 50.00%, op_acc: 19.53%] [G loss: 0.622673]\n",
      "7 [D loss: 0.411423, acc: 48.44%, op_acc: 25.00%] [G loss: 0.608667]\n",
      "8 [D loss: 0.459988, acc: 43.75%, op_acc: 31.25%] [G loss: 0.637255]\n",
      "9 [D loss: 0.445127, acc: 49.22%, op_acc: 26.56%] [G loss: 0.633556]\n",
      "10 [D loss: 0.436110, acc: 46.09%, op_acc: 23.44%] [G loss: 0.591626]\n",
      "Epoch: 10, F1: 0.00000, F1P: 1\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "47.8125\n",
      "11 [D loss: 0.460545, acc: 46.09%, op_acc: 28.12%] [G loss: 0.599877]\n",
      "12 [D loss: 0.439558, acc: 46.88%, op_acc: 33.59%] [G loss: 0.627461]\n",
      "13 [D loss: 0.436180, acc: 50.78%, op_acc: 25.78%] [G loss: 0.585138]\n",
      "14 [D loss: 0.458001, acc: 44.53%, op_acc: 29.69%] [G loss: 0.580730]\n",
      "15 [D loss: 0.458248, acc: 38.28%, op_acc: 28.91%] [G loss: 0.609037]\n",
      "16 [D loss: 0.429570, acc: 46.09%, op_acc: 28.12%] [G loss: 0.602548]\n",
      "17 [D loss: 0.422789, acc: 46.88%, op_acc: 25.78%] [G loss: 0.603727]\n",
      "18 [D loss: 0.449689, acc: 42.97%, op_acc: 25.78%] [G loss: 0.559639]\n",
      "19 [D loss: 0.410830, acc: 48.44%, op_acc: 32.03%] [G loss: 0.598692]\n",
      "20 [D loss: 0.438226, acc: 41.41%, op_acc: 32.03%] [G loss: 0.570863]\n",
      "Epoch: 20, F1: 0.00000, F1P: 2\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "45.234375\n",
      "21 [D loss: 0.443306, acc: 42.97%, op_acc: 29.69%] [G loss: 0.614330]\n",
      "22 [D loss: 0.430397, acc: 49.22%, op_acc: 34.38%] [G loss: 0.598053]\n",
      "23 [D loss: 0.440638, acc: 41.41%, op_acc: 32.03%] [G loss: 0.590229]\n",
      "24 [D loss: 0.427636, acc: 50.00%, op_acc: 25.78%] [G loss: 0.582102]\n",
      "25 [D loss: 0.412669, acc: 49.22%, op_acc: 28.12%] [G loss: 0.629839]\n",
      "26 [D loss: 0.422203, acc: 53.91%, op_acc: 26.56%] [G loss: 0.586247]\n",
      "27 [D loss: 0.435660, acc: 43.75%, op_acc: 24.22%] [G loss: 0.593384]\n",
      "28 [D loss: 0.424383, acc: 47.66%, op_acc: 30.47%] [G loss: 0.583487]\n",
      "29 [D loss: 0.432027, acc: 46.88%, op_acc: 29.69%] [G loss: 0.597717]\n",
      "30 [D loss: 0.419487, acc: 47.66%, op_acc: 37.50%] [G loss: 0.579913]\n",
      "Epoch: 30, F1: 0.00000, F1P: 3\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "47.265625\n",
      "31 [D loss: 0.405313, acc: 50.00%, op_acc: 34.38%] [G loss: 0.588498]\n",
      "32 [D loss: 0.429868, acc: 47.66%, op_acc: 26.56%] [G loss: 0.611508]\n",
      "33 [D loss: 0.402492, acc: 46.88%, op_acc: 25.78%] [G loss: 0.583613]\n",
      "34 [D loss: 0.412632, acc: 49.22%, op_acc: 30.47%] [G loss: 0.605420]\n",
      "35 [D loss: 0.413120, acc: 48.44%, op_acc: 32.81%] [G loss: 0.623610]\n",
      "36 [D loss: 0.413305, acc: 48.44%, op_acc: 31.25%] [G loss: 0.611601]\n",
      "37 [D loss: 0.408610, acc: 50.78%, op_acc: 33.59%] [G loss: 0.574468]\n",
      "38 [D loss: 0.413347, acc: 50.00%, op_acc: 33.59%] [G loss: 0.549349]\n",
      "39 [D loss: 0.401069, acc: 47.66%, op_acc: 32.03%] [G loss: 0.594683]\n",
      "40 [D loss: 0.406295, acc: 47.66%, op_acc: 28.91%] [G loss: 0.583616]\n",
      "Epoch: 40, F1: 0.00000, F1P: 4\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "48.671875\n",
      "41 [D loss: 0.401495, acc: 50.00%, op_acc: 21.09%] [G loss: 0.573645]\n",
      "42 [D loss: 0.405211, acc: 47.66%, op_acc: 28.91%] [G loss: 0.583679]\n",
      "43 [D loss: 0.412707, acc: 46.88%, op_acc: 35.16%] [G loss: 0.534927]\n",
      "44 [D loss: 0.407818, acc: 45.31%, op_acc: 32.03%] [G loss: 0.604535]\n",
      "45 [D loss: 0.406247, acc: 47.66%, op_acc: 27.34%] [G loss: 0.574364]\n",
      "46 [D loss: 0.415816, acc: 43.75%, op_acc: 29.69%] [G loss: 0.589551]\n",
      "47 [D loss: 0.377067, acc: 53.91%, op_acc: 32.81%] [G loss: 0.623470]\n",
      "48 [D loss: 0.420382, acc: 42.97%, op_acc: 30.47%] [G loss: 0.571072]\n",
      "49 [D loss: 0.396394, acc: 48.44%, op_acc: 37.50%] [G loss: 0.599163]\n",
      "50 [D loss: 0.403815, acc: 50.00%, op_acc: 31.25%] [G loss: 0.596513]\n",
      "Epoch: 50, F1: 0.00000, F1P: 5\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "47.65625\n",
      "51 [D loss: 0.397523, acc: 47.66%, op_acc: 36.72%] [G loss: 0.594174]\n",
      "52 [D loss: 0.409606, acc: 44.53%, op_acc: 34.38%] [G loss: 0.585801]\n",
      "53 [D loss: 0.389490, acc: 49.22%, op_acc: 32.03%] [G loss: 0.586081]\n",
      "54 [D loss: 0.409336, acc: 53.91%, op_acc: 30.47%] [G loss: 0.602106]\n",
      "55 [D loss: 0.393787, acc: 53.12%, op_acc: 30.47%] [G loss: 0.624639]\n",
      "56 [D loss: 0.402491, acc: 50.00%, op_acc: 33.59%] [G loss: 0.590426]\n",
      "57 [D loss: 0.407540, acc: 43.75%, op_acc: 33.59%] [G loss: 0.582425]\n",
      "58 [D loss: 0.413055, acc: 44.53%, op_acc: 28.12%] [G loss: 0.607003]\n",
      "59 [D loss: 0.380127, acc: 53.91%, op_acc: 27.34%] [G loss: 0.581561]\n",
      "60 [D loss: 0.408700, acc: 50.78%, op_acc: 22.66%] [G loss: 0.581875]\n",
      "Epoch: 60, F1: 0.00000, F1P: 6\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "49.140625\n",
      "61 [D loss: 0.412355, acc: 42.19%, op_acc: 29.69%] [G loss: 0.571735]\n",
      "62 [D loss: 0.405144, acc: 57.03%, op_acc: 26.56%] [G loss: 0.577425]\n",
      "63 [D loss: 0.396495, acc: 53.91%, op_acc: 32.81%] [G loss: 0.605779]\n",
      "64 [D loss: 0.374616, acc: 51.56%, op_acc: 33.59%] [G loss: 0.583402]\n",
      "65 [D loss: 0.425461, acc: 46.09%, op_acc: 37.50%] [G loss: 0.589902]\n",
      "66 [D loss: 0.400213, acc: 50.00%, op_acc: 30.47%] [G loss: 0.595507]\n",
      "67 [D loss: 0.388824, acc: 49.22%, op_acc: 32.03%] [G loss: 0.575872]\n",
      "68 [D loss: 0.388961, acc: 50.78%, op_acc: 29.69%] [G loss: 0.598083]\n",
      "69 [D loss: 0.387857, acc: 52.34%, op_acc: 25.78%] [G loss: 0.582828]\n",
      "70 [D loss: 0.384500, acc: 50.00%, op_acc: 38.28%] [G loss: 0.628196]\n",
      "Epoch: 70, F1: 0.00000, F1P: 7\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "50.3125\n",
      "71 [D loss: 0.381719, acc: 51.56%, op_acc: 28.12%] [G loss: 0.581431]\n",
      "72 [D loss: 0.385924, acc: 52.34%, op_acc: 32.03%] [G loss: 0.575128]\n",
      "73 [D loss: 0.363671, acc: 56.25%, op_acc: 31.25%] [G loss: 0.548621]\n",
      "74 [D loss: 0.415960, acc: 53.91%, op_acc: 32.81%] [G loss: 0.577165]\n",
      "75 [D loss: 0.398023, acc: 50.78%, op_acc: 28.91%] [G loss: 0.568505]\n",
      "76 [D loss: 0.383410, acc: 54.69%, op_acc: 31.25%] [G loss: 0.585357]\n",
      "77 [D loss: 0.386651, acc: 57.81%, op_acc: 34.38%] [G loss: 0.580842]\n",
      "78 [D loss: 0.394467, acc: 49.22%, op_acc: 31.25%] [G loss: 0.571340]\n",
      "79 [D loss: 0.395507, acc: 47.66%, op_acc: 32.81%] [G loss: 0.576386]\n",
      "80 [D loss: 0.371439, acc: 51.56%, op_acc: 37.50%] [G loss: 0.611278]\n",
      "Epoch: 80, F1: 0.00000, F1P: 8\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "52.578125\n",
      "81 [D loss: 0.382295, acc: 57.81%, op_acc: 32.81%] [G loss: 0.607481]\n",
      "82 [D loss: 0.371483, acc: 59.38%, op_acc: 35.16%] [G loss: 0.596846]\n",
      "83 [D loss: 0.369821, acc: 60.94%, op_acc: 32.81%] [G loss: 0.582581]\n",
      "84 [D loss: 0.409791, acc: 50.78%, op_acc: 31.25%] [G loss: 0.594373]\n",
      "85 [D loss: 0.382500, acc: 57.03%, op_acc: 29.69%] [G loss: 0.589086]\n",
      "86 [D loss: 0.361393, acc: 59.38%, op_acc: 29.69%] [G loss: 0.594112]\n",
      "87 [D loss: 0.384329, acc: 53.91%, op_acc: 32.03%] [G loss: 0.615875]\n",
      "88 [D loss: 0.368199, acc: 58.59%, op_acc: 35.94%] [G loss: 0.578461]\n",
      "89 [D loss: 0.377451, acc: 53.12%, op_acc: 37.50%] [G loss: 0.616069]\n",
      "90 [D loss: 0.382509, acc: 49.22%, op_acc: 42.97%] [G loss: 0.629995]\n",
      "Epoch: 90, F1: 0.00000, F1P: 9\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "56.015625\n",
      "91 [D loss: 0.383103, acc: 53.12%, op_acc: 38.28%] [G loss: 0.565014]\n",
      "92 [D loss: 0.373571, acc: 53.91%, op_acc: 35.16%] [G loss: 0.619415]\n",
      "93 [D loss: 0.376076, acc: 53.91%, op_acc: 39.06%] [G loss: 0.586023]\n",
      "94 [D loss: 0.383518, acc: 53.91%, op_acc: 33.59%] [G loss: 0.621655]\n",
      "95 [D loss: 0.382998, acc: 56.25%, op_acc: 35.16%] [G loss: 0.614422]\n",
      "96 [D loss: 0.364233, acc: 60.16%, op_acc: 34.38%] [G loss: 0.614623]\n",
      "97 [D loss: 0.397232, acc: 49.22%, op_acc: 28.91%] [G loss: 0.589298]\n",
      "98 [D loss: 0.382401, acc: 55.47%, op_acc: 37.50%] [G loss: 0.582303]\n",
      "99 [D loss: 0.385475, acc: 58.59%, op_acc: 28.91%] [G loss: 0.603494]\n",
      "100 [D loss: 0.383342, acc: 55.47%, op_acc: 28.91%] [G loss: 0.594028]\n",
      "Epoch: 100, F1: 0.00000, F1P: 10\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "55.0\n",
      "101 [D loss: 0.373742, acc: 57.03%, op_acc: 33.59%] [G loss: 0.595232]\n",
      "102 [D loss: 0.390172, acc: 53.12%, op_acc: 26.56%] [G loss: 0.604771]\n",
      "103 [D loss: 0.372361, acc: 60.94%, op_acc: 32.03%] [G loss: 0.599785]\n",
      "104 [D loss: 0.383974, acc: 54.69%, op_acc: 32.03%] [G loss: 0.619308]\n",
      "105 [D loss: 0.371601, acc: 61.72%, op_acc: 22.66%] [G loss: 0.586997]\n",
      "106 [D loss: 0.381283, acc: 51.56%, op_acc: 35.94%] [G loss: 0.638667]\n",
      "107 [D loss: 0.372384, acc: 57.03%, op_acc: 37.50%] [G loss: 0.614859]\n",
      "108 [D loss: 0.353541, acc: 58.59%, op_acc: 28.91%] [G loss: 0.592105]\n",
      "109 [D loss: 0.377456, acc: 56.25%, op_acc: 39.06%] [G loss: 0.627460]\n",
      "110 [D loss: 0.355098, acc: 63.28%, op_acc: 31.25%] [G loss: 0.623832]\n",
      "Epoch: 110, F1: 0.00000, F1P: 11\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "57.421875\n",
      "111 [D loss: 0.368391, acc: 58.59%, op_acc: 31.25%] [G loss: 0.583464]\n",
      "112 [D loss: 0.385274, acc: 56.25%, op_acc: 33.59%] [G loss: 0.601975]\n",
      "113 [D loss: 0.382906, acc: 53.91%, op_acc: 32.81%] [G loss: 0.618737]\n",
      "114 [D loss: 0.347878, acc: 60.16%, op_acc: 35.16%] [G loss: 0.604360]\n",
      "115 [D loss: 0.379856, acc: 55.47%, op_acc: 29.69%] [G loss: 0.584985]\n",
      "116 [D loss: 0.384426, acc: 53.12%, op_acc: 32.03%] [G loss: 0.671609]\n",
      "117 [D loss: 0.382783, acc: 59.38%, op_acc: 27.34%] [G loss: 0.634140]\n",
      "118 [D loss: 0.380096, acc: 56.25%, op_acc: 32.81%] [G loss: 0.583373]\n",
      "119 [D loss: 0.363737, acc: 57.03%, op_acc: 32.03%] [G loss: 0.654163]\n",
      "120 [D loss: 0.373470, acc: 56.25%, op_acc: 26.56%] [G loss: 0.614581]\n",
      "Epoch: 120, F1: 0.00000, F1P: 12\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "56.640625\n",
      "121 [D loss: 0.352031, acc: 59.38%, op_acc: 28.91%] [G loss: 0.619255]\n",
      "122 [D loss: 0.382430, acc: 53.12%, op_acc: 41.41%] [G loss: 0.600670]\n",
      "123 [D loss: 0.355143, acc: 64.84%, op_acc: 35.94%] [G loss: 0.591893]\n",
      "124 [D loss: 0.344267, acc: 65.62%, op_acc: 39.84%] [G loss: 0.583968]\n",
      "125 [D loss: 0.351767, acc: 60.16%, op_acc: 37.50%] [G loss: 0.598321]\n",
      "126 [D loss: 0.388596, acc: 55.47%, op_acc: 35.16%] [G loss: 0.596961]\n",
      "127 [D loss: 0.357132, acc: 57.81%, op_acc: 35.16%] [G loss: 0.599223]\n",
      "128 [D loss: 0.368159, acc: 60.16%, op_acc: 29.69%] [G loss: 0.591065]\n",
      "129 [D loss: 0.352007, acc: 59.38%, op_acc: 33.59%] [G loss: 0.628422]\n",
      "130 [D loss: 0.359766, acc: 60.16%, op_acc: 39.84%] [G loss: 0.593173]\n",
      "Epoch: 130, F1: 0.00000, F1P: 13\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "59.609375\n",
      "131 [D loss: 0.360326, acc: 58.59%, op_acc: 33.59%] [G loss: 0.568926]\n",
      "132 [D loss: 0.361807, acc: 53.91%, op_acc: 42.19%] [G loss: 0.621125]\n",
      "133 [D loss: 0.351479, acc: 59.38%, op_acc: 33.59%] [G loss: 0.591488]\n",
      "134 [D loss: 0.366077, acc: 54.69%, op_acc: 33.59%] [G loss: 0.590443]\n",
      "135 [D loss: 0.355943, acc: 59.38%, op_acc: 26.56%] [G loss: 0.634446]\n",
      "136 [D loss: 0.363941, acc: 59.38%, op_acc: 28.12%] [G loss: 0.611569]\n",
      "137 [D loss: 0.361974, acc: 60.16%, op_acc: 31.25%] [G loss: 0.588481]\n",
      "138 [D loss: 0.381231, acc: 54.69%, op_acc: 38.28%] [G loss: 0.614958]\n",
      "139 [D loss: 0.352622, acc: 62.50%, op_acc: 34.38%] [G loss: 0.597152]\n",
      "140 [D loss: 0.332666, acc: 60.94%, op_acc: 40.62%] [G loss: 0.607231]\n",
      "Epoch: 140, F1: 0.00000, F1P: 14\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "58.359375\n",
      "141 [D loss: 0.362746, acc: 58.59%, op_acc: 34.38%] [G loss: 0.627373]\n",
      "142 [D loss: 0.336085, acc: 62.50%, op_acc: 34.38%] [G loss: 0.610820]\n",
      "143 [D loss: 0.374430, acc: 59.38%, op_acc: 29.69%] [G loss: 0.611808]\n",
      "144 [D loss: 0.359979, acc: 58.59%, op_acc: 32.81%] [G loss: 0.654247]\n",
      "145 [D loss: 0.357453, acc: 51.56%, op_acc: 35.16%] [G loss: 0.623054]\n",
      "146 [D loss: 0.357693, acc: 62.50%, op_acc: 34.38%] [G loss: 0.605369]\n",
      "147 [D loss: 0.347395, acc: 64.84%, op_acc: 34.38%] [G loss: 0.653813]\n",
      "148 [D loss: 0.353163, acc: 60.94%, op_acc: 35.16%] [G loss: 0.563342]\n",
      "149 [D loss: 0.364304, acc: 54.69%, op_acc: 34.38%] [G loss: 0.633752]\n",
      "150 [D loss: 0.363008, acc: 60.16%, op_acc: 35.16%] [G loss: 0.599862]\n",
      "Epoch: 150, F1: 0.00000, F1P: 15\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "59.375\n",
      "151 [D loss: 0.343629, acc: 62.50%, op_acc: 29.69%] [G loss: 0.613450]\n",
      "152 [D loss: 0.356213, acc: 54.69%, op_acc: 32.03%] [G loss: 0.574503]\n",
      "153 [D loss: 0.363103, acc: 57.81%, op_acc: 40.62%] [G loss: 0.604641]\n",
      "154 [D loss: 0.369311, acc: 57.03%, op_acc: 30.47%] [G loss: 0.578835]\n",
      "155 [D loss: 0.366107, acc: 57.81%, op_acc: 38.28%] [G loss: 0.608582]\n",
      "156 [D loss: 0.367369, acc: 55.47%, op_acc: 34.38%] [G loss: 0.642863]\n",
      "157 [D loss: 0.353832, acc: 60.16%, op_acc: 29.69%] [G loss: 0.617571]\n",
      "158 [D loss: 0.326362, acc: 64.06%, op_acc: 40.62%] [G loss: 0.632620]\n",
      "159 [D loss: 0.351433, acc: 63.28%, op_acc: 38.28%] [G loss: 0.605745]\n",
      "160 [D loss: 0.334381, acc: 61.72%, op_acc: 34.38%] [G loss: 0.634693]\n",
      "Epoch: 160, F1: 0.00000, F1P: 16\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "59.453125\n",
      "161 [D loss: 0.347759, acc: 60.94%, op_acc: 28.91%] [G loss: 0.575386]\n",
      "162 [D loss: 0.360694, acc: 58.59%, op_acc: 31.25%] [G loss: 0.586162]\n",
      "163 [D loss: 0.326494, acc: 65.62%, op_acc: 39.84%] [G loss: 0.606971]\n",
      "164 [D loss: 0.341483, acc: 66.41%, op_acc: 35.94%] [G loss: 0.620253]\n",
      "165 [D loss: 0.350879, acc: 63.28%, op_acc: 36.72%] [G loss: 0.593707]\n",
      "166 [D loss: 0.330095, acc: 64.06%, op_acc: 35.94%] [G loss: 0.617164]\n",
      "167 [D loss: 0.344594, acc: 61.72%, op_acc: 34.38%] [G loss: 0.634351]\n",
      "168 [D loss: 0.341622, acc: 62.50%, op_acc: 36.72%] [G loss: 0.644580]\n",
      "169 [D loss: 0.335966, acc: 64.06%, op_acc: 40.62%] [G loss: 0.623552]\n",
      "170 [D loss: 0.364018, acc: 57.03%, op_acc: 35.94%] [G loss: 0.634669]\n",
      "Epoch: 170, F1: 0.00000, F1P: 17\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "62.421875\n",
      "171 [D loss: 0.351293, acc: 60.94%, op_acc: 36.72%] [G loss: 0.613995]\n",
      "172 [D loss: 0.334659, acc: 62.50%, op_acc: 37.50%] [G loss: 0.603693]\n",
      "173 [D loss: 0.359769, acc: 59.38%, op_acc: 39.06%] [G loss: 0.632805]\n",
      "174 [D loss: 0.351638, acc: 56.25%, op_acc: 39.06%] [G loss: 0.628909]\n",
      "175 [D loss: 0.344962, acc: 64.06%, op_acc: 30.47%] [G loss: 0.644683]\n",
      "176 [D loss: 0.351686, acc: 60.94%, op_acc: 34.38%] [G loss: 0.637320]\n",
      "177 [D loss: 0.358487, acc: 57.03%, op_acc: 39.84%] [G loss: 0.630280]\n",
      "178 [D loss: 0.340460, acc: 66.41%, op_acc: 42.97%] [G loss: 0.620587]\n",
      "179 [D loss: 0.344365, acc: 60.94%, op_acc: 37.50%] [G loss: 0.648414]\n",
      "180 [D loss: 0.353506, acc: 59.38%, op_acc: 35.16%] [G loss: 0.629197]\n",
      "Epoch: 180, F1: 0.00000, F1P: 18\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "60.78125\n",
      "181 [D loss: 0.347093, acc: 59.38%, op_acc: 39.06%] [G loss: 0.634770]\n",
      "182 [D loss: 0.328357, acc: 65.62%, op_acc: 37.50%] [G loss: 0.590117]\n",
      "183 [D loss: 0.359022, acc: 58.59%, op_acc: 39.84%] [G loss: 0.636123]\n",
      "184 [D loss: 0.333599, acc: 64.84%, op_acc: 36.72%] [G loss: 0.637086]\n",
      "185 [D loss: 0.337719, acc: 61.72%, op_acc: 43.75%] [G loss: 0.637087]\n",
      "186 [D loss: 0.342313, acc: 62.50%, op_acc: 33.59%] [G loss: 0.622767]\n",
      "187 [D loss: 0.346938, acc: 63.28%, op_acc: 41.41%] [G loss: 0.630340]\n",
      "188 [D loss: 0.349232, acc: 65.62%, op_acc: 37.50%] [G loss: 0.598494]\n",
      "189 [D loss: 0.360283, acc: 55.47%, op_acc: 46.88%] [G loss: 0.627127]\n",
      "190 [D loss: 0.350837, acc: 60.94%, op_acc: 38.28%] [G loss: 0.629932]\n",
      "Epoch: 190, F1: 0.00000, F1P: 19\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "61.796875\n",
      "191 [D loss: 0.328955, acc: 64.84%, op_acc: 37.50%] [G loss: 0.615858]\n",
      "192 [D loss: 0.348129, acc: 64.84%, op_acc: 35.16%] [G loss: 0.622568]\n",
      "193 [D loss: 0.356586, acc: 55.47%, op_acc: 37.50%] [G loss: 0.631484]\n",
      "194 [D loss: 0.323895, acc: 67.97%, op_acc: 39.84%] [G loss: 0.634504]\n",
      "195 [D loss: 0.338463, acc: 64.84%, op_acc: 40.62%] [G loss: 0.648620]\n",
      "196 [D loss: 0.358603, acc: 59.38%, op_acc: 30.47%] [G loss: 0.644404]\n",
      "197 [D loss: 0.359361, acc: 59.38%, op_acc: 37.50%] [G loss: 0.615769]\n",
      "198 [D loss: 0.327591, acc: 67.19%, op_acc: 41.41%] [G loss: 0.621925]\n",
      "199 [D loss: 0.346211, acc: 62.50%, op_acc: 36.72%] [G loss: 0.639172]\n",
      "200 [D loss: 0.336196, acc: 60.94%, op_acc: 41.41%] [G loss: 0.609622]\n",
      "Epoch: 200, F1: 0.00000, F1P: 20\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "62.734375\n",
      "201 [D loss: 0.327778, acc: 64.06%, op_acc: 41.41%] [G loss: 0.622213]\n",
      "202 [D loss: 0.333802, acc: 68.75%, op_acc: 31.25%] [G loss: 0.604894]\n",
      "203 [D loss: 0.355258, acc: 57.03%, op_acc: 37.50%] [G loss: 0.631419]\n",
      "204 [D loss: 0.331943, acc: 62.50%, op_acc: 39.06%] [G loss: 0.657378]\n",
      "205 [D loss: 0.334914, acc: 70.31%, op_acc: 32.81%] [G loss: 0.629138]\n",
      "206 [D loss: 0.352815, acc: 59.38%, op_acc: 35.94%] [G loss: 0.638033]\n",
      "207 [D loss: 0.349390, acc: 60.94%, op_acc: 32.03%] [G loss: 0.605661]\n",
      "208 [D loss: 0.344440, acc: 57.03%, op_acc: 39.84%] [G loss: 0.626408]\n",
      "209 [D loss: 0.341001, acc: 60.94%, op_acc: 39.84%] [G loss: 0.655846]\n",
      "210 [D loss: 0.344803, acc: 64.84%, op_acc: 33.59%] [G loss: 0.671646]\n",
      "Epoch: 210, F1: 0.00000, F1P: 21\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "62.578125\n",
      "211 [D loss: 0.373748, acc: 57.81%, op_acc: 40.62%] [G loss: 0.632788]\n",
      "212 [D loss: 0.338760, acc: 62.50%, op_acc: 45.31%] [G loss: 0.630702]\n",
      "213 [D loss: 0.346273, acc: 64.84%, op_acc: 32.81%] [G loss: 0.631368]\n",
      "214 [D loss: 0.364932, acc: 56.25%, op_acc: 28.12%] [G loss: 0.649222]\n",
      "215 [D loss: 0.353491, acc: 60.94%, op_acc: 35.94%] [G loss: 0.677823]\n",
      "216 [D loss: 0.337167, acc: 60.94%, op_acc: 36.72%] [G loss: 0.619621]\n",
      "217 [D loss: 0.353718, acc: 67.97%, op_acc: 40.62%] [G loss: 0.613448]\n",
      "218 [D loss: 0.338727, acc: 66.41%, op_acc: 33.59%] [G loss: 0.642529]\n",
      "219 [D loss: 0.333220, acc: 60.16%, op_acc: 36.72%] [G loss: 0.641231]\n",
      "220 [D loss: 0.342915, acc: 60.94%, op_acc: 32.81%] [G loss: 0.627200]\n",
      "Epoch: 220, F1: 0.00000, F1P: 22\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "61.875\n",
      "221 [D loss: 0.332847, acc: 64.06%, op_acc: 39.84%] [G loss: 0.623873]\n",
      "222 [D loss: 0.348506, acc: 59.38%, op_acc: 46.09%] [G loss: 0.655702]\n",
      "223 [D loss: 0.362862, acc: 57.81%, op_acc: 35.16%] [G loss: 0.631769]\n",
      "224 [D loss: 0.328143, acc: 64.84%, op_acc: 39.06%] [G loss: 0.613364]\n",
      "225 [D loss: 0.355068, acc: 61.72%, op_acc: 39.06%] [G loss: 0.620885]\n",
      "226 [D loss: 0.349153, acc: 55.47%, op_acc: 35.94%] [G loss: 0.631389]\n",
      "227 [D loss: 0.343142, acc: 60.16%, op_acc: 34.38%] [G loss: 0.623369]\n",
      "228 [D loss: 0.352674, acc: 57.81%, op_acc: 35.94%] [G loss: 0.658037]\n",
      "229 [D loss: 0.347826, acc: 58.59%, op_acc: 35.94%] [G loss: 0.629746]\n",
      "230 [D loss: 0.345150, acc: 61.72%, op_acc: 42.97%] [G loss: 0.619421]\n",
      "Epoch: 230, F1: 0.00000, F1P: 23\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "60.15625\n",
      "231 [D loss: 0.334243, acc: 60.94%, op_acc: 34.38%] [G loss: 0.658511]\n",
      "232 [D loss: 0.350536, acc: 59.38%, op_acc: 34.38%] [G loss: 0.643217]\n",
      "233 [D loss: 0.323008, acc: 64.06%, op_acc: 42.19%] [G loss: 0.620031]\n",
      "234 [D loss: 0.342027, acc: 60.16%, op_acc: 48.44%] [G loss: 0.632639]\n",
      "235 [D loss: 0.326197, acc: 64.84%, op_acc: 42.97%] [G loss: 0.664889]\n",
      "236 [D loss: 0.357621, acc: 62.50%, op_acc: 36.72%] [G loss: 0.652832]\n",
      "237 [D loss: 0.339126, acc: 65.62%, op_acc: 38.28%] [G loss: 0.657426]\n",
      "238 [D loss: 0.344207, acc: 64.84%, op_acc: 40.62%] [G loss: 0.651054]\n",
      "239 [D loss: 0.343745, acc: 60.16%, op_acc: 39.84%] [G loss: 0.623319]\n",
      "240 [D loss: 0.343915, acc: 57.81%, op_acc: 34.38%] [G loss: 0.658582]\n",
      "Epoch: 240, F1: 0.00000, F1P: 24\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "62.03125\n",
      "241 [D loss: 0.336932, acc: 57.81%, op_acc: 34.38%] [G loss: 0.625943]\n",
      "242 [D loss: 0.355214, acc: 59.38%, op_acc: 35.16%] [G loss: 0.618825]\n",
      "243 [D loss: 0.342038, acc: 60.94%, op_acc: 43.75%] [G loss: 0.621050]\n",
      "244 [D loss: 0.361624, acc: 57.81%, op_acc: 45.31%] [G loss: 0.664080]\n",
      "245 [D loss: 0.364872, acc: 53.91%, op_acc: 37.50%] [G loss: 0.626158]\n",
      "246 [D loss: 0.358081, acc: 60.16%, op_acc: 40.62%] [G loss: 0.633953]\n",
      "247 [D loss: 0.344282, acc: 63.28%, op_acc: 41.41%] [G loss: 0.610436]\n",
      "248 [D loss: 0.329617, acc: 60.16%, op_acc: 40.62%] [G loss: 0.661531]\n",
      "249 [D loss: 0.344641, acc: 59.38%, op_acc: 47.66%] [G loss: 0.620660]\n",
      "250 [D loss: 0.332692, acc: 64.06%, op_acc: 42.97%] [G loss: 0.621460]\n",
      "Epoch: 250, F1: 0.00000, F1P: 25\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "59.6875\n",
      "251 [D loss: 0.338114, acc: 65.62%, op_acc: 37.50%] [G loss: 0.599559]\n",
      "252 [D loss: 0.355632, acc: 60.94%, op_acc: 46.88%] [G loss: 0.652817]\n",
      "253 [D loss: 0.362481, acc: 57.03%, op_acc: 46.88%] [G loss: 0.653190]\n",
      "254 [D loss: 0.333170, acc: 69.53%, op_acc: 41.41%] [G loss: 0.624504]\n",
      "255 [D loss: 0.361447, acc: 57.81%, op_acc: 33.59%] [G loss: 0.612945]\n",
      "256 [D loss: 0.376157, acc: 61.72%, op_acc: 41.41%] [G loss: 0.601136]\n",
      "257 [D loss: 0.340026, acc: 64.84%, op_acc: 42.19%] [G loss: 0.661486]\n",
      "258 [D loss: 0.346005, acc: 64.84%, op_acc: 50.00%] [G loss: 0.652253]\n",
      "259 [D loss: 0.337361, acc: 64.84%, op_acc: 45.31%] [G loss: 0.642149]\n",
      "260 [D loss: 0.337754, acc: 62.50%, op_acc: 44.53%] [G loss: 0.654591]\n",
      "Epoch: 260, F1: 0.00000, F1P: 26\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "62.96875\n",
      "261 [D loss: 0.342905, acc: 57.81%, op_acc: 42.97%] [G loss: 0.643801]\n",
      "262 [D loss: 0.327898, acc: 61.72%, op_acc: 39.84%] [G loss: 0.644357]\n",
      "263 [D loss: 0.355316, acc: 58.59%, op_acc: 45.31%] [G loss: 0.618428]\n",
      "264 [D loss: 0.357480, acc: 55.47%, op_acc: 48.44%] [G loss: 0.655403]\n",
      "265 [D loss: 0.359268, acc: 59.38%, op_acc: 47.66%] [G loss: 0.641722]\n",
      "266 [D loss: 0.335198, acc: 64.84%, op_acc: 47.66%] [G loss: 0.655768]\n",
      "267 [D loss: 0.359066, acc: 60.94%, op_acc: 38.28%] [G loss: 0.639953]\n",
      "268 [D loss: 0.348258, acc: 63.28%, op_acc: 42.19%] [G loss: 0.591132]\n",
      "269 [D loss: 0.354709, acc: 62.50%, op_acc: 43.75%] [G loss: 0.637335]\n",
      "270 [D loss: 0.353820, acc: 63.28%, op_acc: 38.28%] [G loss: 0.651567]\n",
      "Epoch: 270, F1: 0.00000, F1P: 27\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "60.78125\n",
      "271 [D loss: 0.345063, acc: 62.50%, op_acc: 42.97%] [G loss: 0.625070]\n",
      "272 [D loss: 0.334357, acc: 64.06%, op_acc: 46.09%] [G loss: 0.622714]\n",
      "273 [D loss: 0.346734, acc: 64.06%, op_acc: 53.91%] [G loss: 0.627382]\n",
      "274 [D loss: 0.359692, acc: 56.25%, op_acc: 48.44%] [G loss: 0.628016]\n",
      "275 [D loss: 0.350365, acc: 60.94%, op_acc: 45.31%] [G loss: 0.660053]\n",
      "276 [D loss: 0.343249, acc: 59.38%, op_acc: 48.44%] [G loss: 0.613107]\n",
      "277 [D loss: 0.344232, acc: 63.28%, op_acc: 50.00%] [G loss: 0.614377]\n",
      "278 [D loss: 0.337453, acc: 60.94%, op_acc: 43.75%] [G loss: 0.625077]\n",
      "279 [D loss: 0.354925, acc: 58.59%, op_acc: 45.31%] [G loss: 0.592514]\n",
      "280 [D loss: 0.347204, acc: 63.28%, op_acc: 46.09%] [G loss: 0.619888]\n",
      "Epoch: 280, F1: 0.00000, F1P: 28\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "61.328125\n",
      "281 [D loss: 0.363941, acc: 59.38%, op_acc: 45.31%] [G loss: 0.608724]\n",
      "282 [D loss: 0.345954, acc: 61.72%, op_acc: 50.00%] [G loss: 0.609126]\n",
      "283 [D loss: 0.363574, acc: 51.56%, op_acc: 39.84%] [G loss: 0.651425]\n",
      "284 [D loss: 0.332464, acc: 64.84%, op_acc: 41.41%] [G loss: 0.650500]\n",
      "285 [D loss: 0.329866, acc: 65.62%, op_acc: 48.44%] [G loss: 0.655971]\n",
      "286 [D loss: 0.327673, acc: 67.97%, op_acc: 46.88%] [G loss: 0.630613]\n",
      "287 [D loss: 0.356303, acc: 63.28%, op_acc: 46.88%] [G loss: 0.617769]\n",
      "288 [D loss: 0.344361, acc: 62.50%, op_acc: 38.28%] [G loss: 0.652262]\n",
      "289 [D loss: 0.351015, acc: 66.41%, op_acc: 35.94%] [G loss: 0.645437]\n",
      "290 [D loss: 0.340957, acc: 65.62%, op_acc: 38.28%] [G loss: 0.621202]\n",
      "Epoch: 290, F1: 0.00000, F1P: 29\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "62.890625\n",
      "291 [D loss: 0.352180, acc: 61.72%, op_acc: 40.62%] [G loss: 0.664754]\n",
      "292 [D loss: 0.341964, acc: 64.84%, op_acc: 42.19%] [G loss: 0.659233]\n",
      "293 [D loss: 0.336536, acc: 62.50%, op_acc: 42.19%] [G loss: 0.666665]\n",
      "294 [D loss: 0.370055, acc: 61.72%, op_acc: 50.78%] [G loss: 0.676097]\n",
      "295 [D loss: 0.335305, acc: 60.94%, op_acc: 43.75%] [G loss: 0.647834]\n",
      "296 [D loss: 0.336816, acc: 64.84%, op_acc: 43.75%] [G loss: 0.608786]\n",
      "297 [D loss: 0.336931, acc: 67.97%, op_acc: 44.53%] [G loss: 0.635945]\n",
      "298 [D loss: 0.361400, acc: 57.81%, op_acc: 43.75%] [G loss: 0.629116]\n",
      "299 [D loss: 0.353244, acc: 60.94%, op_acc: 40.62%] [G loss: 0.635076]\n",
      "300 [D loss: 0.351399, acc: 59.38%, op_acc: 43.75%] [G loss: 0.618556]\n",
      "Epoch: 300, F1: 0.00000, F1P: 30\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "62.265625\n",
      "301 [D loss: 0.323622, acc: 67.19%, op_acc: 46.88%] [G loss: 0.616825]\n",
      "302 [D loss: 0.346678, acc: 64.84%, op_acc: 49.22%] [G loss: 0.609662]\n",
      "303 [D loss: 0.352925, acc: 60.16%, op_acc: 50.00%] [G loss: 0.635831]\n",
      "304 [D loss: 0.344480, acc: 60.16%, op_acc: 56.25%] [G loss: 0.640604]\n",
      "305 [D loss: 0.325369, acc: 67.19%, op_acc: 53.12%] [G loss: 0.638847]\n",
      "306 [D loss: 0.343826, acc: 60.16%, op_acc: 46.88%] [G loss: 0.668169]\n",
      "307 [D loss: 0.359121, acc: 57.81%, op_acc: 47.66%] [G loss: 0.651685]\n",
      "308 [D loss: 0.333416, acc: 61.72%, op_acc: 48.44%] [G loss: 0.648428]\n",
      "309 [D loss: 0.357892, acc: 60.16%, op_acc: 41.41%] [G loss: 0.616438]\n",
      "310 [D loss: 0.340320, acc: 63.28%, op_acc: 44.53%] [G loss: 0.605148]\n",
      "Epoch: 310, F1: 0.00000, F1P: 31\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "62.265625\n",
      "311 [D loss: 0.334024, acc: 69.53%, op_acc: 44.53%] [G loss: 0.649327]\n",
      "312 [D loss: 0.331150, acc: 64.06%, op_acc: 44.53%] [G loss: 0.618680]\n",
      "313 [D loss: 0.344320, acc: 62.50%, op_acc: 43.75%] [G loss: 0.633388]\n",
      "314 [D loss: 0.362981, acc: 57.81%, op_acc: 47.66%] [G loss: 0.618340]\n",
      "315 [D loss: 0.371454, acc: 52.34%, op_acc: 40.62%] [G loss: 0.641145]\n",
      "316 [D loss: 0.344233, acc: 62.50%, op_acc: 53.12%] [G loss: 0.622238]\n",
      "317 [D loss: 0.360219, acc: 58.59%, op_acc: 46.88%] [G loss: 0.618760]\n",
      "318 [D loss: 0.345592, acc: 60.94%, op_acc: 49.22%] [G loss: 0.623400]\n",
      "319 [D loss: 0.360060, acc: 59.38%, op_acc: 47.66%] [G loss: 0.637578]\n",
      "320 [D loss: 0.338293, acc: 64.84%, op_acc: 47.66%] [G loss: 0.599841]\n",
      "Epoch: 320, F1: 0.00000, F1P: 32\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "61.25\n",
      "321 [D loss: 0.340930, acc: 60.94%, op_acc: 50.00%] [G loss: 0.661063]\n",
      "322 [D loss: 0.364135, acc: 57.81%, op_acc: 46.09%] [G loss: 0.619327]\n",
      "323 [D loss: 0.341555, acc: 65.62%, op_acc: 49.22%] [G loss: 0.627327]\n",
      "324 [D loss: 0.352645, acc: 63.28%, op_acc: 49.22%] [G loss: 0.670441]\n",
      "325 [D loss: 0.345479, acc: 60.94%, op_acc: 46.09%] [G loss: 0.623713]\n",
      "326 [D loss: 0.341524, acc: 64.06%, op_acc: 49.22%] [G loss: 0.690749]\n",
      "327 [D loss: 0.334282, acc: 60.16%, op_acc: 47.66%] [G loss: 0.631804]\n",
      "328 [D loss: 0.369986, acc: 55.47%, op_acc: 48.44%] [G loss: 0.636167]\n",
      "329 [D loss: 0.336437, acc: 61.72%, op_acc: 51.56%] [G loss: 0.651201]\n",
      "330 [D loss: 0.342274, acc: 62.50%, op_acc: 48.44%] [G loss: 0.620515]\n",
      "Epoch: 330, F1: 0.00000, F1P: 33\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "61.25\n",
      "331 [D loss: 0.356494, acc: 59.38%, op_acc: 53.12%] [G loss: 0.652413]\n",
      "332 [D loss: 0.326409, acc: 66.41%, op_acc: 49.22%] [G loss: 0.625697]\n",
      "333 [D loss: 0.335963, acc: 64.06%, op_acc: 54.69%] [G loss: 0.648715]\n",
      "334 [D loss: 0.368579, acc: 53.91%, op_acc: 43.75%] [G loss: 0.649372]\n",
      "335 [D loss: 0.376087, acc: 51.56%, op_acc: 46.88%] [G loss: 0.628404]\n",
      "336 [D loss: 0.360022, acc: 53.91%, op_acc: 50.00%] [G loss: 0.688617]\n",
      "337 [D loss: 0.331130, acc: 64.84%, op_acc: 47.66%] [G loss: 0.607300]\n",
      "338 [D loss: 0.360061, acc: 62.50%, op_acc: 40.62%] [G loss: 0.625227]\n",
      "339 [D loss: 0.341047, acc: 66.41%, op_acc: 50.78%] [G loss: 0.643936]\n",
      "340 [D loss: 0.353173, acc: 65.62%, op_acc: 55.47%] [G loss: 0.639665]\n",
      "Epoch: 340, F1: 0.00000, F1P: 34\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "60.859375\n",
      "341 [D loss: 0.321222, acc: 64.84%, op_acc: 49.22%] [G loss: 0.668334]\n",
      "342 [D loss: 0.352701, acc: 61.72%, op_acc: 50.00%] [G loss: 0.659376]\n",
      "343 [D loss: 0.344844, acc: 65.62%, op_acc: 48.44%] [G loss: 0.659662]\n",
      "344 [D loss: 0.349932, acc: 58.59%, op_acc: 53.12%] [G loss: 0.612546]\n",
      "345 [D loss: 0.353891, acc: 57.03%, op_acc: 53.91%] [G loss: 0.644534]\n",
      "346 [D loss: 0.353469, acc: 54.69%, op_acc: 50.00%] [G loss: 0.646706]\n",
      "347 [D loss: 0.349113, acc: 62.50%, op_acc: 53.12%] [G loss: 0.639484]\n",
      "348 [D loss: 0.366123, acc: 58.59%, op_acc: 49.22%] [G loss: 0.686725]\n",
      "349 [D loss: 0.348287, acc: 62.50%, op_acc: 45.31%] [G loss: 0.667034]\n",
      "350 [D loss: 0.344833, acc: 63.28%, op_acc: 51.56%] [G loss: 0.649392]\n",
      "Epoch: 350, F1: 0.00000, F1P: 35\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "60.9375\n",
      "351 [D loss: 0.364936, acc: 61.72%, op_acc: 50.78%] [G loss: 0.693405]\n",
      "352 [D loss: 0.343641, acc: 66.41%, op_acc: 44.53%] [G loss: 0.639752]\n",
      "353 [D loss: 0.336389, acc: 64.84%, op_acc: 49.22%] [G loss: 0.644855]\n",
      "354 [D loss: 0.346460, acc: 65.62%, op_acc: 52.34%] [G loss: 0.644778]\n",
      "355 [D loss: 0.353252, acc: 62.50%, op_acc: 50.00%] [G loss: 0.667433]\n",
      "356 [D loss: 0.344162, acc: 61.72%, op_acc: 52.34%] [G loss: 0.654126]\n",
      "357 [D loss: 0.342586, acc: 60.16%, op_acc: 50.78%] [G loss: 0.643886]\n",
      "358 [D loss: 0.329805, acc: 62.50%, op_acc: 58.59%] [G loss: 0.659708]\n",
      "359 [D loss: 0.356956, acc: 55.47%, op_acc: 50.00%] [G loss: 0.686769]\n",
      "360 [D loss: 0.355547, acc: 64.06%, op_acc: 53.91%] [G loss: 0.649157]\n",
      "Epoch: 360, F1: 0.00000, F1P: 36\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "62.5\n",
      "361 [D loss: 0.350270, acc: 62.50%, op_acc: 39.84%] [G loss: 0.663236]\n",
      "362 [D loss: 0.344475, acc: 61.72%, op_acc: 46.09%] [G loss: 0.624598]\n",
      "363 [D loss: 0.341084, acc: 63.28%, op_acc: 49.22%] [G loss: 0.648970]\n",
      "364 [D loss: 0.362000, acc: 55.47%, op_acc: 49.22%] [G loss: 0.659012]\n",
      "365 [D loss: 0.346834, acc: 60.16%, op_acc: 47.66%] [G loss: 0.668901]\n",
      "366 [D loss: 0.368576, acc: 53.91%, op_acc: 49.22%] [G loss: 0.672019]\n",
      "367 [D loss: 0.344443, acc: 58.59%, op_acc: 51.56%] [G loss: 0.684510]\n",
      "368 [D loss: 0.346873, acc: 61.72%, op_acc: 40.62%] [G loss: 0.714363]\n",
      "369 [D loss: 0.363519, acc: 57.03%, op_acc: 41.41%] [G loss: 0.685214]\n",
      "370 [D loss: 0.341437, acc: 66.41%, op_acc: 42.19%] [G loss: 0.645196]\n",
      "Epoch: 370, F1: 0.00000, F1P: 37\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "60.078125\n",
      "371 [D loss: 0.331059, acc: 64.84%, op_acc: 51.56%] [G loss: 0.669715]\n",
      "372 [D loss: 0.350081, acc: 60.94%, op_acc: 44.53%] [G loss: 0.664587]\n",
      "373 [D loss: 0.365297, acc: 54.69%, op_acc: 47.66%] [G loss: 0.663026]\n",
      "374 [D loss: 0.352425, acc: 59.38%, op_acc: 50.78%] [G loss: 0.635866]\n",
      "375 [D loss: 0.328340, acc: 65.62%, op_acc: 48.44%] [G loss: 0.687648]\n",
      "376 [D loss: 0.335254, acc: 61.72%, op_acc: 47.66%] [G loss: 0.674994]\n",
      "377 [D loss: 0.345561, acc: 58.59%, op_acc: 51.56%] [G loss: 0.671500]\n",
      "378 [D loss: 0.345946, acc: 58.59%, op_acc: 47.66%] [G loss: 0.697115]\n",
      "379 [D loss: 0.353003, acc: 59.38%, op_acc: 51.56%] [G loss: 0.670163]\n",
      "380 [D loss: 0.360690, acc: 60.16%, op_acc: 46.88%] [G loss: 0.669748]\n",
      "Epoch: 380, F1: 0.00000, F1P: 38\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "60.390625\n",
      "381 [D loss: 0.336106, acc: 65.62%, op_acc: 57.03%] [G loss: 0.651455]\n",
      "382 [D loss: 0.330534, acc: 61.72%, op_acc: 52.34%] [G loss: 0.717081]\n",
      "383 [D loss: 0.337820, acc: 63.28%, op_acc: 48.44%] [G loss: 0.666426]\n",
      "384 [D loss: 0.352048, acc: 59.38%, op_acc: 50.00%] [G loss: 0.670790]\n",
      "385 [D loss: 0.329654, acc: 66.41%, op_acc: 50.78%] [G loss: 0.659906]\n",
      "386 [D loss: 0.353969, acc: 60.16%, op_acc: 46.09%] [G loss: 0.661102]\n",
      "387 [D loss: 0.345520, acc: 61.72%, op_acc: 47.66%] [G loss: 0.678563]\n",
      "388 [D loss: 0.328107, acc: 63.28%, op_acc: 46.88%] [G loss: 0.661859]\n",
      "389 [D loss: 0.326360, acc: 65.62%, op_acc: 53.12%] [G loss: 0.677785]\n",
      "390 [D loss: 0.352193, acc: 57.81%, op_acc: 48.44%] [G loss: 0.629479]\n",
      "Epoch: 390, F1: 0.00000, F1P: 39\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "62.5\n",
      "391 [D loss: 0.342023, acc: 60.94%, op_acc: 46.09%] [G loss: 0.711924]\n",
      "392 [D loss: 0.339329, acc: 61.72%, op_acc: 49.22%] [G loss: 0.661363]\n",
      "393 [D loss: 0.350554, acc: 59.38%, op_acc: 52.34%] [G loss: 0.642864]\n",
      "394 [D loss: 0.353875, acc: 57.81%, op_acc: 41.41%] [G loss: 0.692442]\n",
      "395 [D loss: 0.327069, acc: 66.41%, op_acc: 59.38%] [G loss: 0.660267]\n",
      "396 [D loss: 0.348359, acc: 57.81%, op_acc: 50.00%] [G loss: 0.645885]\n",
      "397 [D loss: 0.349887, acc: 59.38%, op_acc: 46.88%] [G loss: 0.691869]\n",
      "398 [D loss: 0.347612, acc: 61.72%, op_acc: 50.78%] [G loss: 0.630200]\n",
      "399 [D loss: 0.356570, acc: 57.03%, op_acc: 46.88%] [G loss: 0.635703]\n",
      "400 [D loss: 0.351989, acc: 57.81%, op_acc: 49.22%] [G loss: 0.692867]\n",
      "Epoch: 400, F1: 0.00000, F1P: 40\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "60.0\n",
      "401 [D loss: 0.325810, acc: 69.53%, op_acc: 50.00%] [G loss: 0.658087]\n",
      "402 [D loss: 0.333491, acc: 67.19%, op_acc: 59.38%] [G loss: 0.681658]\n",
      "403 [D loss: 0.349845, acc: 59.38%, op_acc: 49.22%] [G loss: 0.652016]\n",
      "404 [D loss: 0.347367, acc: 60.94%, op_acc: 46.88%] [G loss: 0.690851]\n",
      "405 [D loss: 0.334066, acc: 67.97%, op_acc: 57.81%] [G loss: 0.650269]\n",
      "406 [D loss: 0.338738, acc: 63.28%, op_acc: 43.75%] [G loss: 0.675153]\n",
      "407 [D loss: 0.343345, acc: 63.28%, op_acc: 45.31%] [G loss: 0.696115]\n",
      "408 [D loss: 0.350472, acc: 60.94%, op_acc: 49.22%] [G loss: 0.678534]\n",
      "409 [D loss: 0.341189, acc: 62.50%, op_acc: 42.97%] [G loss: 0.714311]\n",
      "410 [D loss: 0.343023, acc: 57.81%, op_acc: 49.22%] [G loss: 0.680351]\n",
      "Epoch: 410, F1: 0.00000, F1P: 41\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "63.28125\n",
      "411 [D loss: 0.361411, acc: 53.91%, op_acc: 53.91%] [G loss: 0.691748]\n",
      "412 [D loss: 0.340788, acc: 63.28%, op_acc: 53.91%] [G loss: 0.699766]\n",
      "413 [D loss: 0.340243, acc: 63.28%, op_acc: 49.22%] [G loss: 0.667498]\n",
      "414 [D loss: 0.357173, acc: 53.91%, op_acc: 47.66%] [G loss: 0.676398]\n",
      "415 [D loss: 0.347857, acc: 56.25%, op_acc: 49.22%] [G loss: 0.688509]\n",
      "416 [D loss: 0.341483, acc: 60.16%, op_acc: 50.78%] [G loss: 0.692291]\n",
      "417 [D loss: 0.349571, acc: 59.38%, op_acc: 51.56%] [G loss: 0.668040]\n",
      "418 [D loss: 0.352147, acc: 61.72%, op_acc: 46.88%] [G loss: 0.694598]\n",
      "419 [D loss: 0.345123, acc: 59.38%, op_acc: 42.97%] [G loss: 0.674911]\n",
      "420 [D loss: 0.372994, acc: 50.78%, op_acc: 50.00%] [G loss: 0.694783]\n",
      "Epoch: 420, F1: 0.00000, F1P: 42\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "58.203125\n",
      "421 [D loss: 0.324784, acc: 64.84%, op_acc: 57.81%] [G loss: 0.693446]\n",
      "422 [D loss: 0.350475, acc: 57.81%, op_acc: 47.66%] [G loss: 0.683806]\n",
      "423 [D loss: 0.353551, acc: 59.38%, op_acc: 52.34%] [G loss: 0.683347]\n",
      "424 [D loss: 0.332926, acc: 65.62%, op_acc: 53.12%] [G loss: 0.695651]\n",
      "425 [D loss: 0.352955, acc: 58.59%, op_acc: 51.56%] [G loss: 0.718926]\n",
      "426 [D loss: 0.325100, acc: 65.62%, op_acc: 50.00%] [G loss: 0.702207]\n",
      "427 [D loss: 0.347368, acc: 60.16%, op_acc: 47.66%] [G loss: 0.684802]\n",
      "428 [D loss: 0.368506, acc: 50.00%, op_acc: 46.88%] [G loss: 0.716823]\n",
      "429 [D loss: 0.337242, acc: 67.97%, op_acc: 48.44%] [G loss: 0.717481]\n",
      "430 [D loss: 0.342403, acc: 61.72%, op_acc: 56.25%] [G loss: 0.685259]\n",
      "Epoch: 430, F1: 0.00000, F1P: 43\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "61.171875\n",
      "431 [D loss: 0.333028, acc: 61.72%, op_acc: 50.00%] [G loss: 0.726416]\n",
      "432 [D loss: 0.344044, acc: 59.38%, op_acc: 56.25%] [G loss: 0.740416]\n",
      "433 [D loss: 0.343072, acc: 59.38%, op_acc: 57.81%] [G loss: 0.681935]\n",
      "434 [D loss: 0.349461, acc: 57.81%, op_acc: 50.00%] [G loss: 0.718397]\n",
      "435 [D loss: 0.349232, acc: 55.47%, op_acc: 53.12%] [G loss: 0.697362]\n",
      "436 [D loss: 0.355958, acc: 53.91%, op_acc: 53.91%] [G loss: 0.710530]\n",
      "437 [D loss: 0.344068, acc: 58.59%, op_acc: 47.66%] [G loss: 0.709962]\n",
      "438 [D loss: 0.348594, acc: 59.38%, op_acc: 55.47%] [G loss: 0.701298]\n",
      "439 [D loss: 0.322823, acc: 65.62%, op_acc: 64.84%] [G loss: 0.679826]\n",
      "440 [D loss: 0.338919, acc: 61.72%, op_acc: 53.91%] [G loss: 0.723167]\n",
      "Epoch: 440, F1: 0.00000, F1P: 44\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "59.296875\n",
      "441 [D loss: 0.352046, acc: 58.59%, op_acc: 43.75%] [G loss: 0.664537]\n",
      "442 [D loss: 0.358588, acc: 59.38%, op_acc: 50.00%] [G loss: 0.699307]\n",
      "443 [D loss: 0.357018, acc: 57.81%, op_acc: 56.25%] [G loss: 0.707856]\n",
      "444 [D loss: 0.351312, acc: 60.16%, op_acc: 46.09%] [G loss: 0.704202]\n",
      "445 [D loss: 0.333347, acc: 68.75%, op_acc: 50.78%] [G loss: 0.672882]\n",
      "446 [D loss: 0.365838, acc: 54.69%, op_acc: 44.53%] [G loss: 0.689045]\n",
      "447 [D loss: 0.356637, acc: 58.59%, op_acc: 51.56%] [G loss: 0.662737]\n",
      "448 [D loss: 0.346372, acc: 63.28%, op_acc: 51.56%] [G loss: 0.703146]\n",
      "449 [D loss: 0.346826, acc: 57.81%, op_acc: 58.59%] [G loss: 0.729162]\n",
      "450 [D loss: 0.331070, acc: 62.50%, op_acc: 49.22%] [G loss: 0.703133]\n",
      "Epoch: 450, F1: 0.00000, F1P: 45\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "60.15625\n",
      "451 [D loss: 0.349774, acc: 58.59%, op_acc: 46.88%] [G loss: 0.700558]\n",
      "452 [D loss: 0.352778, acc: 59.38%, op_acc: 50.00%] [G loss: 0.679406]\n",
      "453 [D loss: 0.332423, acc: 64.06%, op_acc: 50.78%] [G loss: 0.688258]\n",
      "454 [D loss: 0.345396, acc: 54.69%, op_acc: 51.56%] [G loss: 0.693625]\n",
      "455 [D loss: 0.345274, acc: 63.28%, op_acc: 49.22%] [G loss: 0.731682]\n",
      "456 [D loss: 0.341921, acc: 61.72%, op_acc: 51.56%] [G loss: 0.709589]\n",
      "457 [D loss: 0.350163, acc: 53.91%, op_acc: 46.09%] [G loss: 0.711082]\n",
      "458 [D loss: 0.350689, acc: 60.16%, op_acc: 48.44%] [G loss: 0.708456]\n",
      "459 [D loss: 0.339906, acc: 61.72%, op_acc: 53.91%] [G loss: 0.661037]\n",
      "460 [D loss: 0.324376, acc: 60.94%, op_acc: 50.00%] [G loss: 0.710532]\n",
      "Epoch: 460, F1: 0.00000, F1P: 46\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "59.84375\n",
      "461 [D loss: 0.347500, acc: 60.16%, op_acc: 46.09%] [G loss: 0.675435]\n",
      "462 [D loss: 0.335289, acc: 64.06%, op_acc: 47.66%] [G loss: 0.700415]\n",
      "463 [D loss: 0.335802, acc: 67.97%, op_acc: 51.56%] [G loss: 0.690406]\n",
      "464 [D loss: 0.342134, acc: 64.06%, op_acc: 47.66%] [G loss: 0.720541]\n",
      "465 [D loss: 0.332620, acc: 63.28%, op_acc: 53.91%] [G loss: 0.687180]\n",
      "466 [D loss: 0.337349, acc: 60.94%, op_acc: 57.81%] [G loss: 0.689255]\n",
      "467 [D loss: 0.334616, acc: 63.28%, op_acc: 51.56%] [G loss: 0.739384]\n",
      "468 [D loss: 0.366297, acc: 57.03%, op_acc: 55.47%] [G loss: 0.667120]\n",
      "469 [D loss: 0.354859, acc: 57.81%, op_acc: 53.12%] [G loss: 0.741318]\n",
      "470 [D loss: 0.326379, acc: 66.41%, op_acc: 50.78%] [G loss: 0.712208]\n",
      "Epoch: 470, F1: 0.00000, F1P: 47\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "62.5\n",
      "471 [D loss: 0.341259, acc: 61.72%, op_acc: 53.12%] [G loss: 0.724568]\n",
      "472 [D loss: 0.353179, acc: 59.38%, op_acc: 52.34%] [G loss: 0.732602]\n",
      "473 [D loss: 0.342953, acc: 60.16%, op_acc: 47.66%] [G loss: 0.716256]\n",
      "474 [D loss: 0.338649, acc: 61.72%, op_acc: 52.34%] [G loss: 0.702619]\n",
      "475 [D loss: 0.348226, acc: 62.50%, op_acc: 40.62%] [G loss: 0.668131]\n",
      "476 [D loss: 0.347337, acc: 60.16%, op_acc: 50.00%] [G loss: 0.728912]\n",
      "477 [D loss: 0.326802, acc: 67.19%, op_acc: 48.44%] [G loss: 0.730755]\n",
      "478 [D loss: 0.343526, acc: 59.38%, op_acc: 53.91%] [G loss: 0.689843]\n",
      "479 [D loss: 0.338615, acc: 63.28%, op_acc: 52.34%] [G loss: 0.718446]\n",
      "480 [D loss: 0.337753, acc: 60.94%, op_acc: 47.66%] [G loss: 0.667236]\n",
      "Epoch: 480, F1: 0.00000, F1P: 48\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "61.640625\n",
      "481 [D loss: 0.352416, acc: 57.03%, op_acc: 51.56%] [G loss: 0.703628]\n",
      "482 [D loss: 0.340842, acc: 60.16%, op_acc: 51.56%] [G loss: 0.716811]\n",
      "483 [D loss: 0.338338, acc: 62.50%, op_acc: 53.12%] [G loss: 0.686986]\n",
      "484 [D loss: 0.361139, acc: 60.94%, op_acc: 48.44%] [G loss: 0.758285]\n",
      "485 [D loss: 0.340280, acc: 62.50%, op_acc: 58.59%] [G loss: 0.730942]\n",
      "486 [D loss: 0.348639, acc: 57.03%, op_acc: 46.88%] [G loss: 0.700051]\n",
      "487 [D loss: 0.334624, acc: 63.28%, op_acc: 57.03%] [G loss: 0.704890]\n",
      "488 [D loss: 0.359895, acc: 56.25%, op_acc: 48.44%] [G loss: 0.716012]\n",
      "489 [D loss: 0.354329, acc: 57.03%, op_acc: 53.91%] [G loss: 0.731126]\n",
      "490 [D loss: 0.358006, acc: 55.47%, op_acc: 51.56%] [G loss: 0.735262]\n",
      "Epoch: 490, F1: 0.00000, F1P: 49\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "59.21875\n",
      "491 [D loss: 0.349843, acc: 54.69%, op_acc: 49.22%] [G loss: 0.720536]\n",
      "492 [D loss: 0.347794, acc: 57.81%, op_acc: 50.78%] [G loss: 0.696707]\n",
      "493 [D loss: 0.343259, acc: 60.16%, op_acc: 51.56%] [G loss: 0.705578]\n",
      "494 [D loss: 0.343697, acc: 60.16%, op_acc: 50.78%] [G loss: 0.730216]\n",
      "495 [D loss: 0.338116, acc: 59.38%, op_acc: 50.78%] [G loss: 0.721938]\n",
      "496 [D loss: 0.352656, acc: 61.72%, op_acc: 46.09%] [G loss: 0.756429]\n",
      "497 [D loss: 0.345692, acc: 55.47%, op_acc: 48.44%] [G loss: 0.708827]\n",
      "498 [D loss: 0.348681, acc: 57.81%, op_acc: 58.59%] [G loss: 0.698014]\n",
      "499 [D loss: 0.338834, acc: 61.72%, op_acc: 54.69%] [G loss: 0.702477]\n",
      "500 [D loss: 0.349429, acc: 60.16%, op_acc: 50.00%] [G loss: 0.718035]\n",
      "Epoch: 500, F1: 0.00000, F1P: 50\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "58.90625\n",
      "501 [D loss: 0.341475, acc: 60.16%, op_acc: 49.22%] [G loss: 0.703570]\n",
      "502 [D loss: 0.342276, acc: 62.50%, op_acc: 55.47%] [G loss: 0.723217]\n",
      "503 [D loss: 0.346204, acc: 64.06%, op_acc: 54.69%] [G loss: 0.736876]\n",
      "504 [D loss: 0.335898, acc: 62.50%, op_acc: 50.78%] [G loss: 0.707839]\n",
      "505 [D loss: 0.349588, acc: 60.16%, op_acc: 50.78%] [G loss: 0.726067]\n",
      "506 [D loss: 0.329143, acc: 67.97%, op_acc: 55.47%] [G loss: 0.749447]\n",
      "507 [D loss: 0.336323, acc: 62.50%, op_acc: 56.25%] [G loss: 0.691063]\n",
      "508 [D loss: 0.343992, acc: 61.72%, op_acc: 42.19%] [G loss: 0.715441]\n",
      "509 [D loss: 0.339098, acc: 64.84%, op_acc: 53.12%] [G loss: 0.745538]\n",
      "510 [D loss: 0.349600, acc: 59.38%, op_acc: 50.00%] [G loss: 0.764374]\n",
      "Epoch: 510, F1: 0.00000, F1P: 51\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "62.578125\n",
      "511 [D loss: 0.346414, acc: 59.38%, op_acc: 53.12%] [G loss: 0.739100]\n",
      "512 [D loss: 0.357241, acc: 55.47%, op_acc: 54.69%] [G loss: 0.739300]\n",
      "513 [D loss: 0.325888, acc: 69.53%, op_acc: 46.09%] [G loss: 0.742994]\n",
      "514 [D loss: 0.349478, acc: 52.34%, op_acc: 49.22%] [G loss: 0.739604]\n",
      "515 [D loss: 0.342890, acc: 58.59%, op_acc: 52.34%] [G loss: 0.716937]\n",
      "516 [D loss: 0.353238, acc: 57.81%, op_acc: 52.34%] [G loss: 0.699341]\n",
      "517 [D loss: 0.327127, acc: 64.84%, op_acc: 58.59%] [G loss: 0.713149]\n",
      "518 [D loss: 0.341381, acc: 56.25%, op_acc: 51.56%] [G loss: 0.732876]\n",
      "519 [D loss: 0.328143, acc: 64.06%, op_acc: 49.22%] [G loss: 0.721005]\n",
      "520 [D loss: 0.349190, acc: 57.03%, op_acc: 51.56%] [G loss: 0.744676]\n",
      "Epoch: 520, F1: 0.00000, F1P: 52\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "59.53125\n",
      "521 [D loss: 0.344057, acc: 56.25%, op_acc: 51.56%] [G loss: 0.735592]\n",
      "522 [D loss: 0.355356, acc: 57.81%, op_acc: 45.31%] [G loss: 0.731317]\n",
      "523 [D loss: 0.335756, acc: 59.38%, op_acc: 54.69%] [G loss: 0.728536]\n",
      "524 [D loss: 0.330586, acc: 65.62%, op_acc: 51.56%] [G loss: 0.730465]\n",
      "525 [D loss: 0.332375, acc: 64.84%, op_acc: 46.88%] [G loss: 0.728287]\n",
      "526 [D loss: 0.341881, acc: 59.38%, op_acc: 46.09%] [G loss: 0.759925]\n",
      "527 [D loss: 0.366651, acc: 49.22%, op_acc: 47.66%] [G loss: 0.722238]\n",
      "528 [D loss: 0.341778, acc: 63.28%, op_acc: 57.03%] [G loss: 0.688017]\n",
      "529 [D loss: 0.353543, acc: 57.81%, op_acc: 50.00%] [G loss: 0.743605]\n",
      "530 [D loss: 0.347155, acc: 60.16%, op_acc: 50.00%] [G loss: 0.726543]\n",
      "Epoch: 530, F1: 0.00000, F1P: 53\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "59.375\n",
      "531 [D loss: 0.331787, acc: 66.41%, op_acc: 57.03%] [G loss: 0.749347]\n",
      "532 [D loss: 0.335402, acc: 63.28%, op_acc: 51.56%] [G loss: 0.734723]\n",
      "533 [D loss: 0.334406, acc: 64.06%, op_acc: 51.56%] [G loss: 0.726224]\n",
      "534 [D loss: 0.322179, acc: 67.19%, op_acc: 57.03%] [G loss: 0.735297]\n",
      "535 [D loss: 0.339442, acc: 67.97%, op_acc: 49.22%] [G loss: 0.684877]\n",
      "536 [D loss: 0.333167, acc: 63.28%, op_acc: 53.12%] [G loss: 0.740659]\n",
      "537 [D loss: 0.322944, acc: 66.41%, op_acc: 58.59%] [G loss: 0.732934]\n",
      "538 [D loss: 0.348684, acc: 55.47%, op_acc: 47.66%] [G loss: 0.746285]\n",
      "539 [D loss: 0.345524, acc: 57.81%, op_acc: 52.34%] [G loss: 0.740112]\n",
      "540 [D loss: 0.323227, acc: 64.06%, op_acc: 57.81%] [G loss: 0.762973]\n",
      "Epoch: 540, F1: 0.00000, F1P: 54\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "63.59375\n",
      "541 [D loss: 0.339763, acc: 63.28%, op_acc: 53.12%] [G loss: 0.782906]\n",
      "542 [D loss: 0.330963, acc: 62.50%, op_acc: 55.47%] [G loss: 0.674273]\n",
      "543 [D loss: 0.335259, acc: 60.16%, op_acc: 56.25%] [G loss: 0.726800]\n",
      "544 [D loss: 0.344134, acc: 63.28%, op_acc: 54.69%] [G loss: 0.717269]\n",
      "545 [D loss: 0.351403, acc: 64.06%, op_acc: 55.47%] [G loss: 0.716758]\n",
      "546 [D loss: 0.352244, acc: 52.34%, op_acc: 57.81%] [G loss: 0.717177]\n",
      "547 [D loss: 0.331423, acc: 66.41%, op_acc: 56.25%] [G loss: 0.735776]\n",
      "548 [D loss: 0.342310, acc: 59.38%, op_acc: 58.59%] [G loss: 0.734894]\n",
      "549 [D loss: 0.339565, acc: 60.16%, op_acc: 52.34%] [G loss: 0.730383]\n",
      "550 [D loss: 0.350371, acc: 53.91%, op_acc: 54.69%] [G loss: 0.745414]\n",
      "Epoch: 550, F1: 0.00000, F1P: 55\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "60.546875\n",
      "551 [D loss: 0.340187, acc: 62.50%, op_acc: 49.22%] [G loss: 0.752321]\n",
      "552 [D loss: 0.344035, acc: 60.16%, op_acc: 48.44%] [G loss: 0.737016]\n",
      "553 [D loss: 0.322578, acc: 67.97%, op_acc: 57.03%] [G loss: 0.750128]\n",
      "554 [D loss: 0.332054, acc: 67.97%, op_acc: 45.31%] [G loss: 0.708452]\n",
      "555 [D loss: 0.341875, acc: 60.16%, op_acc: 55.47%] [G loss: 0.739522]\n",
      "556 [D loss: 0.330363, acc: 64.06%, op_acc: 50.78%] [G loss: 0.739393]\n",
      "557 [D loss: 0.325735, acc: 64.84%, op_acc: 57.81%] [G loss: 0.739529]\n",
      "558 [D loss: 0.347876, acc: 60.16%, op_acc: 51.56%] [G loss: 0.712568]\n",
      "559 [D loss: 0.348237, acc: 58.59%, op_acc: 57.03%] [G loss: 0.708301]\n",
      "560 [D loss: 0.335178, acc: 61.72%, op_acc: 51.56%] [G loss: 0.739467]\n",
      "Epoch: 560, F1: 0.04000, F1P: 56\n",
      "[[28432     0]\n",
      " [   48     1]]\n",
      "62.8125\n",
      "561 [D loss: 0.339258, acc: 61.72%, op_acc: 50.78%] [G loss: 0.751740]\n",
      "562 [D loss: 0.338474, acc: 62.50%, op_acc: 52.34%] [G loss: 0.725344]\n",
      "563 [D loss: 0.336236, acc: 66.41%, op_acc: 53.91%] [G loss: 0.733433]\n",
      "564 [D loss: 0.340044, acc: 60.16%, op_acc: 53.91%] [G loss: 0.740868]\n",
      "565 [D loss: 0.332671, acc: 64.84%, op_acc: 54.69%] [G loss: 0.739791]\n",
      "566 [D loss: 0.344198, acc: 57.81%, op_acc: 57.03%] [G loss: 0.753522]\n",
      "567 [D loss: 0.341043, acc: 57.81%, op_acc: 57.03%] [G loss: 0.743907]\n",
      "568 [D loss: 0.336163, acc: 60.16%, op_acc: 54.69%] [G loss: 0.781660]\n",
      "569 [D loss: 0.333841, acc: 60.16%, op_acc: 55.47%] [G loss: 0.749597]\n",
      "570 [D loss: 0.343176, acc: 59.38%, op_acc: 50.78%] [G loss: 0.717674]\n",
      "Epoch: 570, F1: 0.04000, F1P: 57\n",
      "[[28432     0]\n",
      " [   48     1]]\n",
      "61.09375\n",
      "571 [D loss: 0.342573, acc: 63.28%, op_acc: 50.00%] [G loss: 0.747953]\n",
      "572 [D loss: 0.348083, acc: 53.12%, op_acc: 53.91%] [G loss: 0.732788]\n",
      "573 [D loss: 0.337521, acc: 62.50%, op_acc: 58.59%] [G loss: 0.704804]\n",
      "574 [D loss: 0.342151, acc: 61.72%, op_acc: 57.81%] [G loss: 0.754435]\n",
      "575 [D loss: 0.337315, acc: 60.16%, op_acc: 52.34%] [G loss: 0.756939]\n",
      "576 [D loss: 0.336410, acc: 63.28%, op_acc: 46.09%] [G loss: 0.745870]\n",
      "577 [D loss: 0.342616, acc: 62.50%, op_acc: 57.03%] [G loss: 0.771638]\n",
      "578 [D loss: 0.340538, acc: 57.03%, op_acc: 53.12%] [G loss: 0.722371]\n",
      "579 [D loss: 0.354086, acc: 56.25%, op_acc: 53.12%] [G loss: 0.735203]\n",
      "580 [D loss: 0.331306, acc: 65.62%, op_acc: 60.16%] [G loss: 0.719708]\n",
      "Epoch: 580, F1: 0.04000, F1P: 58\n",
      "[[28432     0]\n",
      " [   48     1]]\n",
      "60.546875\n",
      "581 [D loss: 0.340346, acc: 57.81%, op_acc: 54.69%] [G loss: 0.768285]\n",
      "582 [D loss: 0.342358, acc: 60.94%, op_acc: 49.22%] [G loss: 0.740216]\n",
      "583 [D loss: 0.338572, acc: 59.38%, op_acc: 56.25%] [G loss: 0.722589]\n",
      "584 [D loss: 0.341963, acc: 63.28%, op_acc: 52.34%] [G loss: 0.770688]\n",
      "585 [D loss: 0.340890, acc: 68.75%, op_acc: 48.44%] [G loss: 0.729884]\n",
      "586 [D loss: 0.314791, acc: 75.00%, op_acc: 56.25%] [G loss: 0.756998]\n",
      "587 [D loss: 0.335790, acc: 65.62%, op_acc: 47.66%] [G loss: 0.759759]\n",
      "588 [D loss: 0.328275, acc: 70.31%, op_acc: 53.91%] [G loss: 0.766671]\n",
      "589 [D loss: 0.320410, acc: 65.62%, op_acc: 63.28%] [G loss: 0.785519]\n",
      "590 [D loss: 0.333481, acc: 65.62%, op_acc: 50.78%] [G loss: 0.745685]\n",
      "Epoch: 590, F1: 0.04000, F1P: 59\n",
      "[[28432     0]\n",
      " [   48     1]]\n",
      "65.234375\n",
      "591 [D loss: 0.339248, acc: 64.06%, op_acc: 52.34%] [G loss: 0.762755]\n",
      "592 [D loss: 0.338353, acc: 63.28%, op_acc: 50.00%] [G loss: 0.754807]\n",
      "593 [D loss: 0.335651, acc: 64.06%, op_acc: 57.81%] [G loss: 0.782340]\n",
      "594 [D loss: 0.344344, acc: 58.59%, op_acc: 46.09%] [G loss: 0.781726]\n",
      "595 [D loss: 0.355976, acc: 61.72%, op_acc: 59.38%] [G loss: 0.725304]\n",
      "596 [D loss: 0.335508, acc: 60.94%, op_acc: 52.34%] [G loss: 0.741011]\n",
      "597 [D loss: 0.311408, acc: 71.88%, op_acc: 52.34%] [G loss: 0.751108]\n",
      "598 [D loss: 0.335651, acc: 62.50%, op_acc: 50.78%] [G loss: 0.771576]\n",
      "599 [D loss: 0.334493, acc: 64.06%, op_acc: 57.81%] [G loss: 0.780084]\n",
      "600 [D loss: 0.337900, acc: 64.84%, op_acc: 49.22%] [G loss: 0.750809]\n",
      "Epoch: 600, F1: 0.11538, F1P: 60\n",
      "[[28432     0]\n",
      " [   46     3]]\n",
      "63.59375\n",
      "601 [D loss: 0.342555, acc: 64.84%, op_acc: 53.12%] [G loss: 0.732872]\n",
      "602 [D loss: 0.337534, acc: 62.50%, op_acc: 55.47%] [G loss: 0.752597]\n",
      "603 [D loss: 0.333151, acc: 62.50%, op_acc: 53.91%] [G loss: 0.742832]\n",
      "604 [D loss: 0.331805, acc: 67.19%, op_acc: 52.34%] [G loss: 0.759795]\n",
      "605 [D loss: 0.354212, acc: 57.03%, op_acc: 51.56%] [G loss: 0.749205]\n",
      "606 [D loss: 0.341365, acc: 65.62%, op_acc: 50.00%] [G loss: 0.771677]\n",
      "607 [D loss: 0.326542, acc: 64.06%, op_acc: 57.81%] [G loss: 0.721224]\n",
      "608 [D loss: 0.327461, acc: 71.09%, op_acc: 54.69%] [G loss: 0.739632]\n",
      "609 [D loss: 0.337984, acc: 57.81%, op_acc: 57.03%] [G loss: 0.766666]\n",
      "610 [D loss: 0.344759, acc: 51.56%, op_acc: 50.00%] [G loss: 0.709472]\n",
      "Epoch: 610, F1: 0.11538, F1P: 61\n",
      "[[28432     0]\n",
      " [   46     3]]\n",
      "62.421875\n",
      "611 [D loss: 0.327471, acc: 67.97%, op_acc: 45.31%] [G loss: 0.749067]\n",
      "612 [D loss: 0.335874, acc: 57.81%, op_acc: 51.56%] [G loss: 0.762819]\n",
      "613 [D loss: 0.329681, acc: 68.75%, op_acc: 54.69%] [G loss: 0.774996]\n",
      "614 [D loss: 0.343202, acc: 59.38%, op_acc: 52.34%] [G loss: 0.778605]\n",
      "615 [D loss: 0.328350, acc: 68.75%, op_acc: 46.88%] [G loss: 0.768140]\n",
      "616 [D loss: 0.332775, acc: 63.28%, op_acc: 54.69%] [G loss: 0.785255]\n",
      "617 [D loss: 0.336620, acc: 64.06%, op_acc: 49.22%] [G loss: 0.738058]\n",
      "618 [D loss: 0.334475, acc: 63.28%, op_acc: 53.91%] [G loss: 0.727958]\n",
      "619 [D loss: 0.339384, acc: 62.50%, op_acc: 55.47%] [G loss: 0.750040]\n",
      "620 [D loss: 0.332822, acc: 60.94%, op_acc: 51.56%] [G loss: 0.807560]\n",
      "Epoch: 620, F1: 0.15094, F1P: 62\n",
      "[[28432     0]\n",
      " [   45     4]]\n",
      "63.671875\n",
      "621 [D loss: 0.325753, acc: 65.62%, op_acc: 55.47%] [G loss: 0.777145]\n",
      "622 [D loss: 0.321821, acc: 64.84%, op_acc: 62.50%] [G loss: 0.771961]\n",
      "623 [D loss: 0.336558, acc: 58.59%, op_acc: 50.78%] [G loss: 0.766256]\n",
      "624 [D loss: 0.331414, acc: 66.41%, op_acc: 60.16%] [G loss: 0.731481]\n",
      "625 [D loss: 0.332172, acc: 60.16%, op_acc: 50.00%] [G loss: 0.786574]\n",
      "626 [D loss: 0.328208, acc: 67.19%, op_acc: 55.47%] [G loss: 0.805164]\n",
      "627 [D loss: 0.342940, acc: 61.72%, op_acc: 56.25%] [G loss: 0.729313]\n",
      "628 [D loss: 0.320149, acc: 69.53%, op_acc: 57.81%] [G loss: 0.771500]\n",
      "629 [D loss: 0.336322, acc: 60.16%, op_acc: 57.03%] [G loss: 0.786747]\n",
      "630 [D loss: 0.331016, acc: 63.28%, op_acc: 48.44%] [G loss: 0.807859]\n",
      "Epoch: 630, F1: 0.15094, F1P: 63\n",
      "[[28432     0]\n",
      " [   45     4]]\n",
      "63.75\n",
      "631 [D loss: 0.331419, acc: 62.50%, op_acc: 52.34%] [G loss: 0.745990]\n",
      "632 [D loss: 0.335775, acc: 61.72%, op_acc: 54.69%] [G loss: 0.791658]\n",
      "633 [D loss: 0.331150, acc: 71.88%, op_acc: 58.59%] [G loss: 0.763623]\n",
      "634 [D loss: 0.349775, acc: 61.72%, op_acc: 48.44%] [G loss: 0.773025]\n",
      "635 [D loss: 0.322079, acc: 68.75%, op_acc: 51.56%] [G loss: 0.784582]\n",
      "636 [D loss: 0.326316, acc: 66.41%, op_acc: 53.12%] [G loss: 0.795488]\n",
      "637 [D loss: 0.330412, acc: 60.16%, op_acc: 53.91%] [G loss: 0.769060]\n",
      "638 [D loss: 0.331600, acc: 66.41%, op_acc: 53.12%] [G loss: 0.758572]\n",
      "639 [D loss: 0.332296, acc: 66.41%, op_acc: 55.47%] [G loss: 0.773163]\n",
      "640 [D loss: 0.327518, acc: 64.84%, op_acc: 57.03%] [G loss: 0.778935]\n",
      "Epoch: 640, F1: 0.15094, F1P: 64\n",
      "[[28432     0]\n",
      " [   45     4]]\n",
      "65.078125\n",
      "641 [D loss: 0.336578, acc: 59.38%, op_acc: 56.25%] [G loss: 0.801276]\n",
      "642 [D loss: 0.334399, acc: 66.41%, op_acc: 51.56%] [G loss: 0.762504]\n",
      "643 [D loss: 0.332050, acc: 60.94%, op_acc: 53.91%] [G loss: 0.770463]\n",
      "644 [D loss: 0.328024, acc: 66.41%, op_acc: 54.69%] [G loss: 0.802344]\n",
      "645 [D loss: 0.329939, acc: 64.06%, op_acc: 50.78%] [G loss: 0.810113]\n",
      "646 [D loss: 0.329129, acc: 67.19%, op_acc: 60.94%] [G loss: 0.751681]\n",
      "647 [D loss: 0.317375, acc: 67.97%, op_acc: 53.91%] [G loss: 0.751233]\n",
      "648 [D loss: 0.329788, acc: 69.53%, op_acc: 59.38%] [G loss: 0.773230]\n",
      "649 [D loss: 0.331013, acc: 64.84%, op_acc: 54.69%] [G loss: 0.810465]\n",
      "650 [D loss: 0.335419, acc: 65.62%, op_acc: 48.44%] [G loss: 0.741225]\n",
      "Epoch: 650, F1: 0.15094, F1P: 65\n",
      "[[28432     0]\n",
      " [   45     4]]\n",
      "65.234375\n",
      "651 [D loss: 0.308631, acc: 74.22%, op_acc: 57.81%] [G loss: 0.747597]\n",
      "652 [D loss: 0.334367, acc: 68.75%, op_acc: 50.78%] [G loss: 0.746165]\n",
      "653 [D loss: 0.322608, acc: 67.19%, op_acc: 57.81%] [G loss: 0.753944]\n",
      "654 [D loss: 0.329103, acc: 67.19%, op_acc: 53.12%] [G loss: 0.777150]\n",
      "655 [D loss: 0.316945, acc: 73.44%, op_acc: 60.94%] [G loss: 0.778855]\n",
      "656 [D loss: 0.328151, acc: 65.62%, op_acc: 53.12%] [G loss: 0.772891]\n",
      "657 [D loss: 0.320859, acc: 67.97%, op_acc: 59.38%] [G loss: 0.754969]\n",
      "658 [D loss: 0.325836, acc: 67.97%, op_acc: 50.78%] [G loss: 0.781061]\n",
      "659 [D loss: 0.319010, acc: 66.41%, op_acc: 53.91%] [G loss: 0.786908]\n",
      "660 [D loss: 0.314726, acc: 71.09%, op_acc: 54.69%] [G loss: 0.761849]\n",
      "Epoch: 660, F1: 0.18519, F1P: 66\n",
      "[[28432     0]\n",
      " [   44     5]]\n",
      "68.984375\n",
      "661 [D loss: 0.335854, acc: 64.84%, op_acc: 53.91%] [G loss: 0.806358]\n",
      "662 [D loss: 0.326369, acc: 71.88%, op_acc: 51.56%] [G loss: 0.800920]\n",
      "663 [D loss: 0.334116, acc: 67.19%, op_acc: 55.47%] [G loss: 0.785182]\n",
      "664 [D loss: 0.322052, acc: 67.19%, op_acc: 54.69%] [G loss: 0.758028]\n",
      "665 [D loss: 0.310229, acc: 72.66%, op_acc: 58.59%] [G loss: 0.784289]\n",
      "666 [D loss: 0.326288, acc: 65.62%, op_acc: 53.91%] [G loss: 0.821638]\n",
      "667 [D loss: 0.316858, acc: 71.88%, op_acc: 53.91%] [G loss: 0.761650]\n",
      "668 [D loss: 0.333130, acc: 65.62%, op_acc: 59.38%] [G loss: 0.789791]\n",
      "669 [D loss: 0.321171, acc: 70.31%, op_acc: 50.00%] [G loss: 0.763771]\n",
      "670 [D loss: 0.318615, acc: 70.31%, op_acc: 63.28%] [G loss: 0.798413]\n",
      "Epoch: 670, F1: 0.18519, F1P: 67\n",
      "[[28432     0]\n",
      " [   44     5]]\n",
      "68.75\n",
      "671 [D loss: 0.312721, acc: 71.09%, op_acc: 49.22%] [G loss: 0.824833]\n",
      "672 [D loss: 0.326887, acc: 67.97%, op_acc: 53.12%] [G loss: 0.784016]\n",
      "673 [D loss: 0.340818, acc: 60.94%, op_acc: 53.12%] [G loss: 0.786354]\n",
      "674 [D loss: 0.314318, acc: 68.75%, op_acc: 56.25%] [G loss: 0.783054]\n",
      "675 [D loss: 0.316047, acc: 72.66%, op_acc: 57.81%] [G loss: 0.820475]\n",
      "676 [D loss: 0.322589, acc: 67.19%, op_acc: 55.47%] [G loss: 0.788644]\n",
      "677 [D loss: 0.320071, acc: 72.66%, op_acc: 55.47%] [G loss: 0.785203]\n",
      "678 [D loss: 0.319099, acc: 69.53%, op_acc: 55.47%] [G loss: 0.815527]\n",
      "679 [D loss: 0.300261, acc: 75.00%, op_acc: 56.25%] [G loss: 0.790014]\n",
      "680 [D loss: 0.306756, acc: 78.12%, op_acc: 59.38%] [G loss: 0.779843]\n",
      "Epoch: 680, F1: 0.25000, F1P: 68\n",
      "[[28432     0]\n",
      " [   42     7]]\n",
      "70.390625\n",
      "681 [D loss: 0.326135, acc: 65.62%, op_acc: 55.47%] [G loss: 0.785614]\n",
      "682 [D loss: 0.337338, acc: 62.50%, op_acc: 53.91%] [G loss: 0.818124]\n",
      "683 [D loss: 0.317528, acc: 70.31%, op_acc: 50.78%] [G loss: 0.786773]\n",
      "684 [D loss: 0.330250, acc: 68.75%, op_acc: 57.81%] [G loss: 0.837386]\n",
      "685 [D loss: 0.320225, acc: 64.84%, op_acc: 57.81%] [G loss: 0.780296]\n",
      "686 [D loss: 0.329953, acc: 67.19%, op_acc: 52.34%] [G loss: 0.804206]\n",
      "687 [D loss: 0.329997, acc: 61.72%, op_acc: 62.50%] [G loss: 0.807089]\n",
      "688 [D loss: 0.311067, acc: 72.66%, op_acc: 60.94%] [G loss: 0.798861]\n",
      "689 [D loss: 0.334338, acc: 64.84%, op_acc: 61.72%] [G loss: 0.819445]\n",
      "690 [D loss: 0.323209, acc: 67.97%, op_acc: 57.03%] [G loss: 0.791499]\n",
      "Epoch: 690, F1: 0.23729, F1P: 69\n",
      "[[28429     3]\n",
      " [   42     7]]\n",
      "66.640625\n",
      "691 [D loss: 0.316276, acc: 71.09%, op_acc: 60.94%] [G loss: 0.787989]\n",
      "692 [D loss: 0.326146, acc: 71.09%, op_acc: 56.25%] [G loss: 0.801997]\n",
      "693 [D loss: 0.327500, acc: 67.19%, op_acc: 55.47%] [G loss: 0.734506]\n",
      "694 [D loss: 0.322630, acc: 71.09%, op_acc: 48.44%] [G loss: 0.775520]\n",
      "695 [D loss: 0.308518, acc: 75.00%, op_acc: 57.03%] [G loss: 0.774535]\n",
      "696 [D loss: 0.329170, acc: 71.09%, op_acc: 53.91%] [G loss: 0.808155]\n",
      "697 [D loss: 0.322717, acc: 65.62%, op_acc: 53.91%] [G loss: 0.793760]\n",
      "698 [D loss: 0.299708, acc: 75.00%, op_acc: 57.81%] [G loss: 0.769716]\n",
      "699 [D loss: 0.325665, acc: 60.94%, op_acc: 53.91%] [G loss: 0.788100]\n",
      "700 [D loss: 0.320700, acc: 70.31%, op_acc: 63.28%] [G loss: 0.844122]\n",
      "Epoch: 700, F1: 0.23729, F1P: 70\n",
      "[[28429     3]\n",
      " [   42     7]]\n",
      "69.84375\n",
      "701 [D loss: 0.330836, acc: 61.72%, op_acc: 52.34%] [G loss: 0.797818]\n",
      "702 [D loss: 0.326086, acc: 67.97%, op_acc: 56.25%] [G loss: 0.860062]\n",
      "703 [D loss: 0.321606, acc: 67.19%, op_acc: 57.03%] [G loss: 0.830967]\n",
      "704 [D loss: 0.316643, acc: 71.09%, op_acc: 63.28%] [G loss: 0.811006]\n",
      "705 [D loss: 0.309832, acc: 70.31%, op_acc: 50.78%] [G loss: 0.794918]\n",
      "706 [D loss: 0.329970, acc: 67.19%, op_acc: 48.44%] [G loss: 0.815204]\n",
      "707 [D loss: 0.336382, acc: 64.84%, op_acc: 54.69%] [G loss: 0.802610]\n",
      "708 [D loss: 0.333673, acc: 65.62%, op_acc: 48.44%] [G loss: 0.766820]\n",
      "709 [D loss: 0.340862, acc: 58.59%, op_acc: 57.03%] [G loss: 0.822447]\n",
      "710 [D loss: 0.313466, acc: 67.19%, op_acc: 55.47%] [G loss: 0.810044]\n",
      "Epoch: 710, F1: 0.23729, F1P: 71\n",
      "[[28429     3]\n",
      " [   42     7]]\n",
      "66.171875\n",
      "711 [D loss: 0.336622, acc: 60.16%, op_acc: 54.69%] [G loss: 0.816747]\n",
      "712 [D loss: 0.307236, acc: 78.91%, op_acc: 62.50%] [G loss: 0.812793]\n",
      "713 [D loss: 0.318818, acc: 70.31%, op_acc: 59.38%] [G loss: 0.817665]\n",
      "714 [D loss: 0.321950, acc: 67.97%, op_acc: 58.59%] [G loss: 0.790720]\n",
      "715 [D loss: 0.318995, acc: 71.88%, op_acc: 55.47%] [G loss: 0.796763]\n",
      "716 [D loss: 0.317067, acc: 70.31%, op_acc: 57.03%] [G loss: 0.773424]\n",
      "717 [D loss: 0.334434, acc: 60.94%, op_acc: 59.38%] [G loss: 0.806277]\n",
      "718 [D loss: 0.328709, acc: 67.19%, op_acc: 56.25%] [G loss: 0.838170]\n",
      "719 [D loss: 0.313364, acc: 73.44%, op_acc: 53.91%] [G loss: 0.774007]\n",
      "720 [D loss: 0.312000, acc: 75.00%, op_acc: 54.69%] [G loss: 0.807667]\n",
      "Epoch: 720, F1: 0.23333, F1P: 72\n",
      "[[28428     4]\n",
      " [   42     7]]\n",
      "69.609375\n",
      "721 [D loss: 0.322970, acc: 66.41%, op_acc: 61.72%] [G loss: 0.765985]\n",
      "722 [D loss: 0.314906, acc: 69.53%, op_acc: 58.59%] [G loss: 0.841711]\n",
      "723 [D loss: 0.331937, acc: 69.53%, op_acc: 50.00%] [G loss: 0.796202]\n",
      "724 [D loss: 0.328145, acc: 63.28%, op_acc: 56.25%] [G loss: 0.788062]\n",
      "725 [D loss: 0.327949, acc: 65.62%, op_acc: 51.56%] [G loss: 0.807697]\n",
      "726 [D loss: 0.315790, acc: 74.22%, op_acc: 53.12%] [G loss: 0.819529]\n",
      "727 [D loss: 0.301947, acc: 79.69%, op_acc: 57.81%] [G loss: 0.814316]\n",
      "728 [D loss: 0.326972, acc: 67.19%, op_acc: 51.56%] [G loss: 0.807786]\n",
      "729 [D loss: 0.307935, acc: 68.75%, op_acc: 58.59%] [G loss: 0.820359]\n",
      "730 [D loss: 0.318743, acc: 69.53%, op_acc: 59.38%] [G loss: 0.828587]\n",
      "Epoch: 730, F1: 0.23729, F1P: 73\n",
      "[[28429     3]\n",
      " [   42     7]]\n",
      "69.375\n",
      "731 [D loss: 0.311280, acc: 73.44%, op_acc: 60.16%] [G loss: 0.813851]\n",
      "732 [D loss: 0.330436, acc: 65.62%, op_acc: 57.03%] [G loss: 0.770265]\n",
      "733 [D loss: 0.317887, acc: 70.31%, op_acc: 55.47%] [G loss: 0.809888]\n",
      "734 [D loss: 0.317062, acc: 72.66%, op_acc: 60.94%] [G loss: 0.830561]\n",
      "735 [D loss: 0.321285, acc: 69.53%, op_acc: 49.22%] [G loss: 0.786971]\n",
      "736 [D loss: 0.317101, acc: 69.53%, op_acc: 60.16%] [G loss: 0.796492]\n",
      "737 [D loss: 0.315720, acc: 71.88%, op_acc: 53.91%] [G loss: 0.825876]\n",
      "738 [D loss: 0.329254, acc: 63.28%, op_acc: 52.34%] [G loss: 0.807083]\n",
      "739 [D loss: 0.321278, acc: 68.75%, op_acc: 56.25%] [G loss: 0.797343]\n",
      "740 [D loss: 0.311043, acc: 71.88%, op_acc: 53.91%] [G loss: 0.795357]\n",
      "Epoch: 740, F1: 0.23729, F1P: 74\n",
      "[[28429     3]\n",
      " [   42     7]]\n",
      "69.6875\n",
      "741 [D loss: 0.326378, acc: 68.75%, op_acc: 55.47%] [G loss: 0.803486]\n",
      "742 [D loss: 0.312175, acc: 68.75%, op_acc: 60.16%] [G loss: 0.798628]\n",
      "743 [D loss: 0.314438, acc: 71.88%, op_acc: 61.72%] [G loss: 0.814816]\n",
      "744 [D loss: 0.309912, acc: 72.66%, op_acc: 60.94%] [G loss: 0.798011]\n",
      "745 [D loss: 0.312212, acc: 75.00%, op_acc: 56.25%] [G loss: 0.784327]\n",
      "746 [D loss: 0.324679, acc: 67.19%, op_acc: 58.59%] [G loss: 0.796894]\n",
      "747 [D loss: 0.324400, acc: 64.84%, op_acc: 60.16%] [G loss: 0.792272]\n",
      "748 [D loss: 0.321733, acc: 69.53%, op_acc: 56.25%] [G loss: 0.811468]\n",
      "749 [D loss: 0.314195, acc: 69.53%, op_acc: 63.28%] [G loss: 0.813292]\n",
      "750 [D loss: 0.319152, acc: 64.84%, op_acc: 54.69%] [G loss: 0.782518]\n",
      "Epoch: 750, F1: 0.23729, F1P: 75\n",
      "[[28429     3]\n",
      " [   42     7]]\n",
      "69.296875\n",
      "751 [D loss: 0.307716, acc: 75.00%, op_acc: 54.69%] [G loss: 0.780663]\n",
      "752 [D loss: 0.321100, acc: 70.31%, op_acc: 57.03%] [G loss: 0.817904]\n",
      "753 [D loss: 0.321612, acc: 67.19%, op_acc: 52.34%] [G loss: 0.793546]\n",
      "754 [D loss: 0.306374, acc: 71.88%, op_acc: 57.03%] [G loss: 0.805049]\n",
      "755 [D loss: 0.316374, acc: 68.75%, op_acc: 57.03%] [G loss: 0.778061]\n",
      "756 [D loss: 0.306484, acc: 73.44%, op_acc: 60.94%] [G loss: 0.800220]\n",
      "757 [D loss: 0.302788, acc: 75.00%, op_acc: 60.94%] [G loss: 0.812648]\n",
      "758 [D loss: 0.311138, acc: 72.66%, op_acc: 60.16%] [G loss: 0.820487]\n",
      "759 [D loss: 0.320709, acc: 65.62%, op_acc: 60.16%] [G loss: 0.778007]\n",
      "760 [D loss: 0.314746, acc: 75.00%, op_acc: 58.59%] [G loss: 0.781772]\n",
      "Epoch: 760, F1: 0.23729, F1P: 76\n",
      "[[28429     3]\n",
      " [   42     7]]\n",
      "71.484375\n",
      "761 [D loss: 0.314779, acc: 69.53%, op_acc: 57.81%] [G loss: 0.783894]\n",
      "762 [D loss: 0.319202, acc: 68.75%, op_acc: 55.47%] [G loss: 0.802308]\n",
      "763 [D loss: 0.313290, acc: 71.09%, op_acc: 59.38%] [G loss: 0.820044]\n",
      "764 [D loss: 0.326182, acc: 70.31%, op_acc: 58.59%] [G loss: 0.778966]\n",
      "765 [D loss: 0.325198, acc: 69.53%, op_acc: 61.72%] [G loss: 0.778798]\n",
      "766 [D loss: 0.312339, acc: 71.09%, op_acc: 60.16%] [G loss: 0.817872]\n",
      "767 [D loss: 0.309357, acc: 75.00%, op_acc: 55.47%] [G loss: 0.800421]\n",
      "768 [D loss: 0.302692, acc: 71.09%, op_acc: 47.66%] [G loss: 0.829342]\n",
      "769 [D loss: 0.312513, acc: 75.78%, op_acc: 64.84%] [G loss: 0.786805]\n",
      "770 [D loss: 0.332767, acc: 62.50%, op_acc: 53.91%] [G loss: 0.766776]\n",
      "Epoch: 770, F1: 0.23729, F1P: 77\n",
      "[[28429     3]\n",
      " [   42     7]]\n",
      "70.46875\n",
      "771 [D loss: 0.316905, acc: 75.78%, op_acc: 53.91%] [G loss: 0.796572]\n",
      "772 [D loss: 0.324500, acc: 67.97%, op_acc: 59.38%] [G loss: 0.821185]\n",
      "773 [D loss: 0.316563, acc: 71.88%, op_acc: 61.72%] [G loss: 0.780664]\n",
      "774 [D loss: 0.314794, acc: 70.31%, op_acc: 55.47%] [G loss: 0.822885]\n",
      "775 [D loss: 0.310163, acc: 71.88%, op_acc: 59.38%] [G loss: 0.827063]\n",
      "776 [D loss: 0.305461, acc: 73.44%, op_acc: 55.47%] [G loss: 0.788020]\n",
      "777 [D loss: 0.307556, acc: 75.00%, op_acc: 56.25%] [G loss: 0.797667]\n",
      "778 [D loss: 0.321428, acc: 65.62%, op_acc: 61.72%] [G loss: 0.777677]\n",
      "779 [D loss: 0.317965, acc: 67.97%, op_acc: 53.12%] [G loss: 0.803708]\n",
      "780 [D loss: 0.303072, acc: 72.66%, op_acc: 56.25%] [G loss: 0.835508]\n",
      "Epoch: 780, F1: 0.23729, F1P: 78\n",
      "[[28429     3]\n",
      " [   42     7]]\n",
      "71.25\n",
      "781 [D loss: 0.316208, acc: 72.66%, op_acc: 58.59%] [G loss: 0.818981]\n",
      "782 [D loss: 0.309899, acc: 71.09%, op_acc: 54.69%] [G loss: 0.771174]\n",
      "783 [D loss: 0.316664, acc: 69.53%, op_acc: 60.16%] [G loss: 0.802498]\n",
      "784 [D loss: 0.329687, acc: 65.62%, op_acc: 60.16%] [G loss: 0.798723]\n",
      "785 [D loss: 0.310207, acc: 67.97%, op_acc: 55.47%] [G loss: 0.825086]\n",
      "786 [D loss: 0.316213, acc: 75.00%, op_acc: 50.00%] [G loss: 0.780735]\n",
      "787 [D loss: 0.322583, acc: 69.53%, op_acc: 57.81%] [G loss: 0.824849]\n",
      "788 [D loss: 0.316806, acc: 72.66%, op_acc: 56.25%] [G loss: 0.790291]\n",
      "789 [D loss: 0.313822, acc: 70.31%, op_acc: 55.47%] [G loss: 0.820047]\n",
      "790 [D loss: 0.315203, acc: 71.09%, op_acc: 56.25%] [G loss: 0.831645]\n",
      "Epoch: 790, F1: 0.23729, F1P: 79\n",
      "[[28429     3]\n",
      " [   42     7]]\n",
      "70.546875\n",
      "791 [D loss: 0.316172, acc: 74.22%, op_acc: 56.25%] [G loss: 0.803648]\n",
      "792 [D loss: 0.298461, acc: 71.09%, op_acc: 61.72%] [G loss: 0.778536]\n",
      "793 [D loss: 0.315404, acc: 67.97%, op_acc: 58.59%] [G loss: 0.776256]\n",
      "794 [D loss: 0.317462, acc: 69.53%, op_acc: 60.16%] [G loss: 0.770911]\n",
      "795 [D loss: 0.315236, acc: 71.88%, op_acc: 54.69%] [G loss: 0.774639]\n",
      "796 [D loss: 0.321429, acc: 67.19%, op_acc: 53.91%] [G loss: 0.802474]\n",
      "797 [D loss: 0.322617, acc: 70.31%, op_acc: 57.03%] [G loss: 0.829681]\n",
      "798 [D loss: 0.315711, acc: 69.53%, op_acc: 62.50%] [G loss: 0.803926]\n",
      "799 [D loss: 0.315747, acc: 67.19%, op_acc: 53.12%] [G loss: 0.807022]\n",
      "800 [D loss: 0.314923, acc: 68.75%, op_acc: 57.81%] [G loss: 0.811889]\n",
      "Epoch: 800, F1: 0.24138, F1P: 80\n",
      "[[28430     2]\n",
      " [   42     7]]\n",
      "69.765625\n",
      "801 [D loss: 0.314638, acc: 70.31%, op_acc: 51.56%] [G loss: 0.822386]\n",
      "802 [D loss: 0.304158, acc: 76.56%, op_acc: 54.69%] [G loss: 0.804961]\n",
      "803 [D loss: 0.316654, acc: 71.09%, op_acc: 53.91%] [G loss: 0.796034]\n",
      "804 [D loss: 0.293822, acc: 80.47%, op_acc: 54.69%] [G loss: 0.817906]\n",
      "805 [D loss: 0.321331, acc: 66.41%, op_acc: 53.12%] [G loss: 0.823121]\n",
      "806 [D loss: 0.311282, acc: 69.53%, op_acc: 52.34%] [G loss: 0.813480]\n",
      "807 [D loss: 0.301094, acc: 76.56%, op_acc: 58.59%] [G loss: 0.845769]\n",
      "808 [D loss: 0.320822, acc: 70.31%, op_acc: 54.69%] [G loss: 0.856777]\n",
      "809 [D loss: 0.308580, acc: 71.09%, op_acc: 59.38%] [G loss: 0.802753]\n",
      "810 [D loss: 0.314235, acc: 65.62%, op_acc: 50.78%] [G loss: 0.830262]\n",
      "Epoch: 810, F1: 0.18519, F1P: 81\n",
      "[[28432     0]\n",
      " [   44     5]]\n",
      "71.796875\n",
      "811 [D loss: 0.332437, acc: 64.06%, op_acc: 60.16%] [G loss: 0.828713]\n",
      "812 [D loss: 0.318566, acc: 68.75%, op_acc: 53.91%] [G loss: 0.808824]\n",
      "813 [D loss: 0.331764, acc: 66.41%, op_acc: 45.31%] [G loss: 0.819440]\n",
      "814 [D loss: 0.299944, acc: 78.12%, op_acc: 56.25%] [G loss: 0.812694]\n",
      "815 [D loss: 0.310090, acc: 72.66%, op_acc: 51.56%] [G loss: 0.808290]\n",
      "816 [D loss: 0.316755, acc: 67.19%, op_acc: 57.03%] [G loss: 0.780370]\n",
      "817 [D loss: 0.314377, acc: 74.22%, op_acc: 59.38%] [G loss: 0.833321]\n",
      "818 [D loss: 0.318072, acc: 67.19%, op_acc: 57.03%] [G loss: 0.830059]\n",
      "819 [D loss: 0.319068, acc: 68.75%, op_acc: 53.91%] [G loss: 0.841506]\n",
      "820 [D loss: 0.309550, acc: 71.88%, op_acc: 55.47%] [G loss: 0.830036]\n",
      "Epoch: 820, F1: 0.15094, F1P: 82\n",
      "[[28432     0]\n",
      " [   45     4]]\n",
      "69.921875\n",
      "821 [D loss: 0.302185, acc: 69.53%, op_acc: 64.06%] [G loss: 0.847415]\n",
      "822 [D loss: 0.322159, acc: 66.41%, op_acc: 52.34%] [G loss: 0.795913]\n",
      "823 [D loss: 0.318820, acc: 71.88%, op_acc: 65.62%] [G loss: 0.840093]\n",
      "824 [D loss: 0.315708, acc: 73.44%, op_acc: 58.59%] [G loss: 0.811327]\n",
      "825 [D loss: 0.325224, acc: 68.75%, op_acc: 57.81%] [G loss: 0.803293]\n",
      "826 [D loss: 0.312703, acc: 75.00%, op_acc: 55.47%] [G loss: 0.815040]\n",
      "827 [D loss: 0.303479, acc: 74.22%, op_acc: 53.12%] [G loss: 0.831710]\n",
      "828 [D loss: 0.310136, acc: 73.44%, op_acc: 57.03%] [G loss: 0.786160]\n",
      "829 [D loss: 0.306847, acc: 71.88%, op_acc: 62.50%] [G loss: 0.850998]\n",
      "830 [D loss: 0.315513, acc: 73.44%, op_acc: 53.91%] [G loss: 0.816216]\n",
      "Epoch: 830, F1: 0.15094, F1P: 83\n",
      "[[28432     0]\n",
      " [   45     4]]\n",
      "71.796875\n",
      "831 [D loss: 0.304054, acc: 74.22%, op_acc: 56.25%] [G loss: 0.782786]\n",
      "832 [D loss: 0.301103, acc: 74.22%, op_acc: 56.25%] [G loss: 0.818484]\n",
      "833 [D loss: 0.307772, acc: 75.00%, op_acc: 57.81%] [G loss: 0.823568]\n",
      "834 [D loss: 0.307444, acc: 70.31%, op_acc: 51.56%] [G loss: 0.843522]\n",
      "835 [D loss: 0.315375, acc: 70.31%, op_acc: 52.34%] [G loss: 0.803443]\n",
      "836 [D loss: 0.310012, acc: 73.44%, op_acc: 50.00%] [G loss: 0.778269]\n",
      "837 [D loss: 0.307905, acc: 76.56%, op_acc: 57.03%] [G loss: 0.847232]\n",
      "838 [D loss: 0.304935, acc: 73.44%, op_acc: 63.28%] [G loss: 0.823336]\n",
      "839 [D loss: 0.316257, acc: 67.19%, op_acc: 58.59%] [G loss: 0.814384]\n",
      "840 [D loss: 0.304812, acc: 73.44%, op_acc: 58.59%] [G loss: 0.779674]\n",
      "Epoch: 840, F1: 0.15094, F1P: 84\n",
      "[[28432     0]\n",
      " [   45     4]]\n",
      "72.8125\n",
      "841 [D loss: 0.301356, acc: 75.00%, op_acc: 58.59%] [G loss: 0.802710]\n",
      "842 [D loss: 0.315381, acc: 72.66%, op_acc: 58.59%] [G loss: 0.817460]\n",
      "843 [D loss: 0.303684, acc: 75.78%, op_acc: 53.12%] [G loss: 0.835337]\n",
      "844 [D loss: 0.332925, acc: 63.28%, op_acc: 57.81%] [G loss: 0.827847]\n",
      "845 [D loss: 0.316985, acc: 73.44%, op_acc: 53.12%] [G loss: 0.787864]\n",
      "846 [D loss: 0.313035, acc: 71.09%, op_acc: 58.59%] [G loss: 0.803871]\n",
      "847 [D loss: 0.311852, acc: 71.88%, op_acc: 65.62%] [G loss: 0.809001]\n",
      "848 [D loss: 0.319985, acc: 68.75%, op_acc: 60.16%] [G loss: 0.837008]\n",
      "849 [D loss: 0.319481, acc: 68.75%, op_acc: 50.00%] [G loss: 0.801085]\n",
      "850 [D loss: 0.314038, acc: 72.66%, op_acc: 57.81%] [G loss: 0.805494]\n",
      "Epoch: 850, F1: 0.11538, F1P: 85\n",
      "[[28432     0]\n",
      " [   46     3]]\n",
      "71.328125\n",
      "851 [D loss: 0.318185, acc: 67.97%, op_acc: 56.25%] [G loss: 0.831391]\n",
      "852 [D loss: 0.318444, acc: 71.09%, op_acc: 57.03%] [G loss: 0.826929]\n",
      "853 [D loss: 0.328702, acc: 62.50%, op_acc: 50.00%] [G loss: 0.838048]\n",
      "854 [D loss: 0.313242, acc: 66.41%, op_acc: 50.78%] [G loss: 0.825065]\n",
      "855 [D loss: 0.324217, acc: 63.28%, op_acc: 60.16%] [G loss: 0.786733]\n",
      "856 [D loss: 0.322016, acc: 63.28%, op_acc: 47.66%] [G loss: 0.825643]\n",
      "857 [D loss: 0.313157, acc: 72.66%, op_acc: 55.47%] [G loss: 0.793383]\n",
      "858 [D loss: 0.319684, acc: 60.94%, op_acc: 51.56%] [G loss: 0.824776]\n",
      "859 [D loss: 0.305826, acc: 73.44%, op_acc: 57.81%] [G loss: 0.836075]\n",
      "860 [D loss: 0.318343, acc: 68.75%, op_acc: 52.34%] [G loss: 0.807373]\n",
      "Epoch: 860, F1: 0.11538, F1P: 86\n",
      "[[28432     0]\n",
      " [   46     3]]\n",
      "67.03125\n",
      "861 [D loss: 0.319453, acc: 67.19%, op_acc: 57.81%] [G loss: 0.822271]\n",
      "862 [D loss: 0.311990, acc: 73.44%, op_acc: 56.25%] [G loss: 0.850836]\n",
      "863 [D loss: 0.317316, acc: 69.53%, op_acc: 55.47%] [G loss: 0.821008]\n",
      "864 [D loss: 0.329331, acc: 68.75%, op_acc: 54.69%] [G loss: 0.830856]\n",
      "865 [D loss: 0.300166, acc: 81.25%, op_acc: 55.47%] [G loss: 0.800225]\n",
      "866 [D loss: 0.324567, acc: 68.75%, op_acc: 54.69%] [G loss: 0.807449]\n",
      "867 [D loss: 0.309113, acc: 71.88%, op_acc: 53.91%] [G loss: 0.853335]\n",
      "868 [D loss: 0.310716, acc: 71.88%, op_acc: 55.47%] [G loss: 0.834081]\n",
      "869 [D loss: 0.326779, acc: 69.53%, op_acc: 58.59%] [G loss: 0.795949]\n",
      "870 [D loss: 0.310850, acc: 71.09%, op_acc: 55.47%] [G loss: 0.805558]\n",
      "Epoch: 870, F1: 0.11538, F1P: 87\n",
      "[[28432     0]\n",
      " [   46     3]]\n",
      "71.328125\n",
      "871 [D loss: 0.306974, acc: 76.56%, op_acc: 53.91%] [G loss: 0.824872]\n",
      "872 [D loss: 0.302244, acc: 78.12%, op_acc: 63.28%] [G loss: 0.816998]\n",
      "873 [D loss: 0.321072, acc: 73.44%, op_acc: 56.25%] [G loss: 0.852811]\n",
      "874 [D loss: 0.308177, acc: 77.34%, op_acc: 53.91%] [G loss: 0.815435]\n",
      "875 [D loss: 0.308862, acc: 72.66%, op_acc: 59.38%] [G loss: 0.790736]\n",
      "876 [D loss: 0.320154, acc: 67.97%, op_acc: 57.81%] [G loss: 0.849439]\n",
      "877 [D loss: 0.312741, acc: 71.88%, op_acc: 53.91%] [G loss: 0.813709]\n",
      "878 [D loss: 0.295499, acc: 75.78%, op_acc: 47.66%] [G loss: 0.830107]\n",
      "879 [D loss: 0.313721, acc: 71.09%, op_acc: 52.34%] [G loss: 0.824615]\n",
      "880 [D loss: 0.314247, acc: 71.88%, op_acc: 53.91%] [G loss: 0.810401]\n",
      "Epoch: 880, F1: 0.11538, F1P: 88\n",
      "[[28432     0]\n",
      " [   46     3]]\n",
      "73.671875\n",
      "881 [D loss: 0.314452, acc: 75.78%, op_acc: 60.16%] [G loss: 0.816704]\n",
      "882 [D loss: 0.303164, acc: 73.44%, op_acc: 53.91%] [G loss: 0.811277]\n",
      "883 [D loss: 0.312153, acc: 65.62%, op_acc: 53.91%] [G loss: 0.787795]\n",
      "884 [D loss: 0.314052, acc: 72.66%, op_acc: 56.25%] [G loss: 0.801901]\n",
      "885 [D loss: 0.309754, acc: 72.66%, op_acc: 54.69%] [G loss: 0.833090]\n",
      "886 [D loss: 0.301907, acc: 76.56%, op_acc: 57.03%] [G loss: 0.793293]\n",
      "887 [D loss: 0.316601, acc: 69.53%, op_acc: 59.38%] [G loss: 0.815289]\n",
      "888 [D loss: 0.317596, acc: 64.06%, op_acc: 49.22%] [G loss: 0.827715]\n",
      "889 [D loss: 0.310011, acc: 76.56%, op_acc: 53.91%] [G loss: 0.823474]\n",
      "890 [D loss: 0.306259, acc: 74.22%, op_acc: 56.25%] [G loss: 0.825214]\n",
      "Epoch: 890, F1: 0.11538, F1P: 89\n",
      "[[28432     0]\n",
      " [   46     3]]\n",
      "72.109375\n",
      "891 [D loss: 0.318052, acc: 66.41%, op_acc: 54.69%] [G loss: 0.826752]\n",
      "892 [D loss: 0.311451, acc: 76.56%, op_acc: 52.34%] [G loss: 0.834475]\n",
      "893 [D loss: 0.318094, acc: 71.09%, op_acc: 56.25%] [G loss: 0.775381]\n",
      "894 [D loss: 0.320574, acc: 68.75%, op_acc: 58.59%] [G loss: 0.806110]\n",
      "895 [D loss: 0.319671, acc: 72.66%, op_acc: 55.47%] [G loss: 0.802775]\n",
      "896 [D loss: 0.316064, acc: 74.22%, op_acc: 48.44%] [G loss: 0.835413]\n",
      "897 [D loss: 0.306914, acc: 75.78%, op_acc: 58.59%] [G loss: 0.793494]\n",
      "898 [D loss: 0.322637, acc: 70.31%, op_acc: 57.03%] [G loss: 0.807094]\n",
      "899 [D loss: 0.313927, acc: 70.31%, op_acc: 53.12%] [G loss: 0.851166]\n",
      "900 [D loss: 0.310486, acc: 71.09%, op_acc: 55.47%] [G loss: 0.774542]\n",
      "Epoch: 900, F1: 0.11538, F1P: 90\n",
      "[[28432     0]\n",
      " [   46     3]]\n",
      "71.71875\n",
      "901 [D loss: 0.321624, acc: 70.31%, op_acc: 53.91%] [G loss: 0.833744]\n",
      "902 [D loss: 0.317964, acc: 67.97%, op_acc: 60.94%] [G loss: 0.790153]\n",
      "903 [D loss: 0.308059, acc: 73.44%, op_acc: 54.69%] [G loss: 0.807275]\n",
      "904 [D loss: 0.312701, acc: 67.97%, op_acc: 56.25%] [G loss: 0.831018]\n",
      "905 [D loss: 0.300297, acc: 75.78%, op_acc: 53.91%] [G loss: 0.829676]\n",
      "906 [D loss: 0.319755, acc: 73.44%, op_acc: 54.69%] [G loss: 0.815714]\n",
      "907 [D loss: 0.303380, acc: 72.66%, op_acc: 50.78%] [G loss: 0.845692]\n",
      "908 [D loss: 0.302214, acc: 73.44%, op_acc: 57.81%] [G loss: 0.842683]\n",
      "909 [D loss: 0.305828, acc: 74.22%, op_acc: 55.47%] [G loss: 0.815103]\n",
      "910 [D loss: 0.324251, acc: 66.41%, op_acc: 55.47%] [G loss: 0.763294]\n",
      "Epoch: 910, F1: 0.15094, F1P: 91\n",
      "[[28432     0]\n",
      " [   45     4]]\n",
      "71.5625\n",
      "911 [D loss: 0.314263, acc: 69.53%, op_acc: 59.38%] [G loss: 0.843099]\n",
      "912 [D loss: 0.305598, acc: 71.88%, op_acc: 58.59%] [G loss: 0.786873]\n",
      "913 [D loss: 0.308864, acc: 76.56%, op_acc: 55.47%] [G loss: 0.821775]\n",
      "914 [D loss: 0.319379, acc: 69.53%, op_acc: 56.25%] [G loss: 0.803632]\n",
      "915 [D loss: 0.317148, acc: 71.88%, op_acc: 53.12%] [G loss: 0.821462]\n",
      "916 [D loss: 0.311112, acc: 75.00%, op_acc: 57.81%] [G loss: 0.812456]\n",
      "917 [D loss: 0.317557, acc: 65.62%, op_acc: 54.69%] [G loss: 0.815643]\n",
      "918 [D loss: 0.322344, acc: 69.53%, op_acc: 46.88%] [G loss: 0.811504]\n",
      "919 [D loss: 0.299881, acc: 75.78%, op_acc: 60.16%] [G loss: 0.773669]\n",
      "920 [D loss: 0.306451, acc: 71.09%, op_acc: 59.38%] [G loss: 0.790023]\n",
      "Epoch: 920, F1: 0.14815, F1P: 92\n",
      "[[28431     1]\n",
      " [   45     4]]\n",
      "71.640625\n",
      "921 [D loss: 0.316106, acc: 70.31%, op_acc: 56.25%] [G loss: 0.815482]\n",
      "922 [D loss: 0.328059, acc: 67.97%, op_acc: 55.47%] [G loss: 0.799897]\n",
      "923 [D loss: 0.316837, acc: 72.66%, op_acc: 53.91%] [G loss: 0.816357]\n",
      "924 [D loss: 0.330615, acc: 64.06%, op_acc: 56.25%] [G loss: 0.862247]\n",
      "925 [D loss: 0.319836, acc: 65.62%, op_acc: 53.12%] [G loss: 0.835649]\n",
      "926 [D loss: 0.306893, acc: 67.19%, op_acc: 58.59%] [G loss: 0.839644]\n",
      "927 [D loss: 0.328120, acc: 65.62%, op_acc: 54.69%] [G loss: 0.813416]\n",
      "928 [D loss: 0.314333, acc: 70.31%, op_acc: 60.16%] [G loss: 0.828589]\n",
      "929 [D loss: 0.331954, acc: 60.16%, op_acc: 49.22%] [G loss: 0.822882]\n",
      "930 [D loss: 0.313556, acc: 67.97%, op_acc: 53.12%] [G loss: 0.789649]\n",
      "Epoch: 930, F1: 0.14815, F1P: 93\n",
      "[[28431     1]\n",
      " [   45     4]]\n",
      "67.1875\n",
      "931 [D loss: 0.312871, acc: 71.09%, op_acc: 57.81%] [G loss: 0.827353]\n",
      "932 [D loss: 0.313121, acc: 73.44%, op_acc: 57.03%] [G loss: 0.850438]\n",
      "933 [D loss: 0.300878, acc: 76.56%, op_acc: 57.81%] [G loss: 0.816905]\n",
      "934 [D loss: 0.313374, acc: 68.75%, op_acc: 57.03%] [G loss: 0.814602]\n",
      "935 [D loss: 0.317156, acc: 71.09%, op_acc: 57.03%] [G loss: 0.795631]\n",
      "936 [D loss: 0.309386, acc: 77.34%, op_acc: 58.59%] [G loss: 0.813803]\n",
      "937 [D loss: 0.319248, acc: 64.84%, op_acc: 50.00%] [G loss: 0.811645]\n",
      "938 [D loss: 0.307260, acc: 75.00%, op_acc: 52.34%] [G loss: 0.846649]\n",
      "939 [D loss: 0.310309, acc: 72.66%, op_acc: 65.62%] [G loss: 0.852558]\n",
      "940 [D loss: 0.309301, acc: 71.88%, op_acc: 51.56%] [G loss: 0.838618]\n",
      "Epoch: 940, F1: 0.21053, F1P: 94\n",
      "[[28430     2]\n",
      " [   43     6]]\n",
      "72.265625\n",
      "941 [D loss: 0.322102, acc: 67.19%, op_acc: 54.69%] [G loss: 0.840417]\n",
      "942 [D loss: 0.311485, acc: 72.66%, op_acc: 54.69%] [G loss: 0.801017]\n",
      "943 [D loss: 0.325481, acc: 67.97%, op_acc: 52.34%] [G loss: 0.831478]\n",
      "944 [D loss: 0.312233, acc: 75.00%, op_acc: 58.59%] [G loss: 0.854103]\n",
      "945 [D loss: 0.322611, acc: 64.84%, op_acc: 52.34%] [G loss: 0.835077]\n",
      "946 [D loss: 0.305407, acc: 69.53%, op_acc: 55.47%] [G loss: 0.826677]\n",
      "947 [D loss: 0.300089, acc: 78.91%, op_acc: 50.78%] [G loss: 0.817714]\n",
      "948 [D loss: 0.312069, acc: 71.88%, op_acc: 54.69%] [G loss: 0.846030]\n",
      "949 [D loss: 0.301436, acc: 78.91%, op_acc: 58.59%] [G loss: 0.822510]\n",
      "950 [D loss: 0.325414, acc: 69.53%, op_acc: 55.47%] [G loss: 0.828546]\n",
      "Epoch: 950, F1: 0.21053, F1P: 95\n",
      "[[28430     2]\n",
      " [   43     6]]\n",
      "71.640625\n",
      "951 [D loss: 0.313658, acc: 75.00%, op_acc: 58.59%] [G loss: 0.847835]\n",
      "952 [D loss: 0.301815, acc: 77.34%, op_acc: 58.59%] [G loss: 0.835282]\n",
      "953 [D loss: 0.327688, acc: 67.97%, op_acc: 50.78%] [G loss: 0.820462]\n",
      "954 [D loss: 0.317522, acc: 65.62%, op_acc: 50.78%] [G loss: 0.823797]\n",
      "955 [D loss: 0.325059, acc: 64.06%, op_acc: 50.00%] [G loss: 0.842245]\n",
      "956 [D loss: 0.308796, acc: 68.75%, op_acc: 62.50%] [G loss: 0.818026]\n",
      "957 [D loss: 0.312360, acc: 70.31%, op_acc: 57.81%] [G loss: 0.835968]\n",
      "958 [D loss: 0.304249, acc: 76.56%, op_acc: 58.59%] [G loss: 0.849207]\n",
      "959 [D loss: 0.318359, acc: 71.09%, op_acc: 54.69%] [G loss: 0.832225]\n",
      "960 [D loss: 0.309279, acc: 75.78%, op_acc: 53.91%] [G loss: 0.829362]\n",
      "Epoch: 960, F1: 0.26667, F1P: 96\n",
      "[[28429     3]\n",
      " [   41     8]]\n",
      "71.25\n",
      "961 [D loss: 0.303636, acc: 76.56%, op_acc: 61.72%] [G loss: 0.823595]\n",
      "962 [D loss: 0.323411, acc: 65.62%, op_acc: 56.25%] [G loss: 0.834556]\n",
      "963 [D loss: 0.328535, acc: 63.28%, op_acc: 60.16%] [G loss: 0.849462]\n",
      "964 [D loss: 0.314339, acc: 72.66%, op_acc: 60.94%] [G loss: 0.802571]\n",
      "965 [D loss: 0.315370, acc: 72.66%, op_acc: 53.91%] [G loss: 0.887789]\n",
      "966 [D loss: 0.301794, acc: 74.22%, op_acc: 59.38%] [G loss: 0.780427]\n",
      "967 [D loss: 0.314337, acc: 71.88%, op_acc: 55.47%] [G loss: 0.831084]\n",
      "968 [D loss: 0.313642, acc: 68.75%, op_acc: 59.38%] [G loss: 0.803792]\n",
      "969 [D loss: 0.313012, acc: 70.31%, op_acc: 50.00%] [G loss: 0.868138]\n",
      "970 [D loss: 0.325124, acc: 69.53%, op_acc: 52.34%] [G loss: 0.839918]\n",
      "Epoch: 970, F1: 0.26230, F1P: 97\n",
      "[[28428     4]\n",
      " [   41     8]]\n",
      "70.546875\n",
      "971 [D loss: 0.318678, acc: 66.41%, op_acc: 55.47%] [G loss: 0.828943]\n",
      "972 [D loss: 0.330771, acc: 64.06%, op_acc: 46.88%] [G loss: 0.816238]\n",
      "973 [D loss: 0.315723, acc: 71.88%, op_acc: 51.56%] [G loss: 0.868647]\n",
      "974 [D loss: 0.313222, acc: 65.62%, op_acc: 50.00%] [G loss: 0.811700]\n",
      "975 [D loss: 0.305771, acc: 75.78%, op_acc: 57.81%] [G loss: 0.829627]\n",
      "976 [D loss: 0.316175, acc: 71.09%, op_acc: 54.69%] [G loss: 0.848135]\n",
      "977 [D loss: 0.323409, acc: 67.97%, op_acc: 46.88%] [G loss: 0.837848]\n",
      "978 [D loss: 0.315257, acc: 74.22%, op_acc: 61.72%] [G loss: 0.839124]\n",
      "979 [D loss: 0.309790, acc: 70.31%, op_acc: 57.03%] [G loss: 0.847680]\n",
      "980 [D loss: 0.304904, acc: 69.53%, op_acc: 53.91%] [G loss: 0.867138]\n",
      "Epoch: 980, F1: 0.26230, F1P: 98\n",
      "[[28428     4]\n",
      " [   41     8]]\n",
      "69.6875\n",
      "981 [D loss: 0.312546, acc: 75.00%, op_acc: 52.34%] [G loss: 0.852581]\n",
      "982 [D loss: 0.307042, acc: 79.69%, op_acc: 64.06%] [G loss: 0.827026]\n",
      "983 [D loss: 0.302020, acc: 73.44%, op_acc: 53.91%] [G loss: 0.843134]\n",
      "984 [D loss: 0.318866, acc: 67.97%, op_acc: 58.59%] [G loss: 0.861943]\n",
      "985 [D loss: 0.316696, acc: 66.41%, op_acc: 58.59%] [G loss: 0.848302]\n",
      "986 [D loss: 0.315158, acc: 72.66%, op_acc: 49.22%] [G loss: 0.838701]\n",
      "987 [D loss: 0.311679, acc: 78.12%, op_acc: 50.78%] [G loss: 0.871611]\n",
      "988 [D loss: 0.312332, acc: 75.00%, op_acc: 50.00%] [G loss: 0.814072]\n",
      "989 [D loss: 0.311894, acc: 70.31%, op_acc: 52.34%] [G loss: 0.840494]\n",
      "990 [D loss: 0.306058, acc: 74.22%, op_acc: 52.34%] [G loss: 0.823783]\n",
      "Epoch: 990, F1: 0.26230, F1P: 99\n",
      "[[28428     4]\n",
      " [   41     8]]\n",
      "73.28125\n",
      "991 [D loss: 0.313270, acc: 74.22%, op_acc: 54.69%] [G loss: 0.818864]\n",
      "992 [D loss: 0.307292, acc: 75.00%, op_acc: 53.91%] [G loss: 0.839909]\n",
      "993 [D loss: 0.300710, acc: 74.22%, op_acc: 60.16%] [G loss: 0.858519]\n",
      "994 [D loss: 0.314646, acc: 73.44%, op_acc: 58.59%] [G loss: 0.896657]\n",
      "995 [D loss: 0.299802, acc: 77.34%, op_acc: 62.50%] [G loss: 0.860689]\n",
      "996 [D loss: 0.289286, acc: 82.81%, op_acc: 64.06%] [G loss: 0.862844]\n",
      "997 [D loss: 0.308454, acc: 69.53%, op_acc: 53.91%] [G loss: 0.848091]\n",
      "998 [D loss: 0.295481, acc: 75.78%, op_acc: 56.25%] [G loss: 0.861314]\n",
      "999 [D loss: 0.311154, acc: 76.56%, op_acc: 57.81%] [G loss: 0.812377]\n",
      "1000 [D loss: 0.301943, acc: 75.00%, op_acc: 57.03%] [G loss: 0.843653]\n",
      "Epoch: 1000, F1: 0.25806, F1P: 100\n",
      "[[28427     5]\n",
      " [   41     8]]\n",
      "75.390625\n",
      "1001 [D loss: 0.313004, acc: 67.97%, op_acc: 57.03%] [G loss: 0.832169]\n",
      "1002 [D loss: 0.311085, acc: 68.75%, op_acc: 62.50%] [G loss: 0.870313]\n",
      "1003 [D loss: 0.304066, acc: 73.44%, op_acc: 57.81%] [G loss: 0.886977]\n",
      "1004 [D loss: 0.321614, acc: 63.28%, op_acc: 54.69%] [G loss: 0.831372]\n",
      "1005 [D loss: 0.313655, acc: 69.53%, op_acc: 55.47%] [G loss: 0.851420]\n",
      "1006 [D loss: 0.332101, acc: 62.50%, op_acc: 58.59%] [G loss: 0.869184]\n",
      "1007 [D loss: 0.316486, acc: 71.09%, op_acc: 48.44%] [G loss: 0.863304]\n",
      "1008 [D loss: 0.330475, acc: 65.62%, op_acc: 53.12%] [G loss: 0.833065]\n",
      "1009 [D loss: 0.305163, acc: 74.22%, op_acc: 55.47%] [G loss: 0.838010]\n",
      "1010 [D loss: 0.301675, acc: 72.66%, op_acc: 57.81%] [G loss: 0.861912]\n",
      "Epoch: 1010, F1: 0.25806, F1P: 101\n",
      "[[28427     5]\n",
      " [   41     8]]\n",
      "68.90625\n",
      "1011 [D loss: 0.317124, acc: 71.09%, op_acc: 50.78%] [G loss: 0.792198]\n",
      "1012 [D loss: 0.306534, acc: 73.44%, op_acc: 54.69%] [G loss: 0.848659]\n",
      "1013 [D loss: 0.305164, acc: 72.66%, op_acc: 51.56%] [G loss: 0.840249]\n",
      "1014 [D loss: 0.315992, acc: 67.97%, op_acc: 58.59%] [G loss: 0.852036]\n",
      "1015 [D loss: 0.307461, acc: 75.78%, op_acc: 50.78%] [G loss: 0.869364]\n",
      "1016 [D loss: 0.312319, acc: 70.31%, op_acc: 64.84%] [G loss: 0.865647]\n",
      "1017 [D loss: 0.306808, acc: 74.22%, op_acc: 53.91%] [G loss: 0.834641]\n",
      "1018 [D loss: 0.304882, acc: 75.00%, op_acc: 54.69%] [G loss: 0.874216]\n",
      "1019 [D loss: 0.304780, acc: 75.00%, op_acc: 57.81%] [G loss: 0.820419]\n",
      "1020 [D loss: 0.300427, acc: 80.47%, op_acc: 54.69%] [G loss: 0.874023]\n",
      "Epoch: 1020, F1: 0.25806, F1P: 102\n",
      "[[28427     5]\n",
      " [   41     8]]\n",
      "73.59375\n",
      "1021 [D loss: 0.299293, acc: 78.12%, op_acc: 57.03%] [G loss: 0.832419]\n",
      "1022 [D loss: 0.317782, acc: 74.22%, op_acc: 57.03%] [G loss: 0.830511]\n",
      "1023 [D loss: 0.304530, acc: 78.12%, op_acc: 61.72%] [G loss: 0.852583]\n",
      "1024 [D loss: 0.313544, acc: 72.66%, op_acc: 55.47%] [G loss: 0.859803]\n",
      "1025 [D loss: 0.325456, acc: 68.75%, op_acc: 52.34%] [G loss: 0.894674]\n",
      "1026 [D loss: 0.300938, acc: 79.69%, op_acc: 53.91%] [G loss: 0.834669]\n",
      "1027 [D loss: 0.314726, acc: 73.44%, op_acc: 51.56%] [G loss: 0.829448]\n",
      "1028 [D loss: 0.309671, acc: 75.78%, op_acc: 65.62%] [G loss: 0.851031]\n",
      "1029 [D loss: 0.297688, acc: 76.56%, op_acc: 54.69%] [G loss: 0.828912]\n",
      "1030 [D loss: 0.304377, acc: 76.56%, op_acc: 56.25%] [G loss: 0.820231]\n",
      "Epoch: 1030, F1: 0.28571, F1P: 103\n",
      "[[28427     5]\n",
      " [   40     9]]\n",
      "75.390625\n",
      "1031 [D loss: 0.304071, acc: 80.47%, op_acc: 60.16%] [G loss: 0.851123]\n",
      "1032 [D loss: 0.329520, acc: 65.62%, op_acc: 59.38%] [G loss: 0.863520]\n",
      "1033 [D loss: 0.303727, acc: 75.78%, op_acc: 61.72%] [G loss: 0.864507]\n",
      "1034 [D loss: 0.313108, acc: 71.09%, op_acc: 53.91%] [G loss: 0.870527]\n",
      "1035 [D loss: 0.310307, acc: 71.88%, op_acc: 61.72%] [G loss: 0.846435]\n",
      "1036 [D loss: 0.308295, acc: 72.66%, op_acc: 64.06%] [G loss: 0.874049]\n",
      "1037 [D loss: 0.307019, acc: 71.88%, op_acc: 50.78%] [G loss: 0.907981]\n",
      "1038 [D loss: 0.308031, acc: 69.53%, op_acc: 60.16%] [G loss: 0.860434]\n",
      "1039 [D loss: 0.301402, acc: 75.78%, op_acc: 61.72%] [G loss: 0.852564]\n",
      "1040 [D loss: 0.318680, acc: 67.97%, op_acc: 51.56%] [G loss: 0.854347]\n",
      "Epoch: 1040, F1: 0.28571, F1P: 104\n",
      "[[28427     5]\n",
      " [   40     9]]\n",
      "72.265625\n",
      "1041 [D loss: 0.307827, acc: 73.44%, op_acc: 57.81%] [G loss: 0.840323]\n",
      "1042 [D loss: 0.304400, acc: 73.44%, op_acc: 62.50%] [G loss: 0.859680]\n",
      "1043 [D loss: 0.310096, acc: 71.88%, op_acc: 57.81%] [G loss: 0.856515]\n",
      "1044 [D loss: 0.311432, acc: 72.66%, op_acc: 54.69%] [G loss: 0.833180]\n",
      "1045 [D loss: 0.318381, acc: 69.53%, op_acc: 52.34%] [G loss: 0.845877]\n",
      "1046 [D loss: 0.292177, acc: 78.12%, op_acc: 64.06%] [G loss: 0.885399]\n",
      "1047 [D loss: 0.314936, acc: 68.75%, op_acc: 50.00%] [G loss: 0.896072]\n",
      "1048 [D loss: 0.300080, acc: 75.78%, op_acc: 57.03%] [G loss: 0.888856]\n",
      "1049 [D loss: 0.317542, acc: 71.88%, op_acc: 51.56%] [G loss: 0.904770]\n",
      "1050 [D loss: 0.317744, acc: 67.19%, op_acc: 60.94%] [G loss: 0.853294]\n",
      "Epoch: 1050, F1: 0.28571, F1P: 105\n",
      "[[28427     5]\n",
      " [   40     9]]\n",
      "72.265625\n",
      "1051 [D loss: 0.301855, acc: 75.78%, op_acc: 53.91%] [G loss: 0.909724]\n",
      "1052 [D loss: 0.303754, acc: 75.78%, op_acc: 55.47%] [G loss: 0.913534]\n",
      "1053 [D loss: 0.310424, acc: 74.22%, op_acc: 61.72%] [G loss: 0.875896]\n",
      "1054 [D loss: 0.304105, acc: 72.66%, op_acc: 56.25%] [G loss: 0.887149]\n",
      "1055 [D loss: 0.307355, acc: 72.66%, op_acc: 55.47%] [G loss: 0.878073]\n",
      "1056 [D loss: 0.309317, acc: 73.44%, op_acc: 53.91%] [G loss: 0.870733]\n",
      "1057 [D loss: 0.299280, acc: 78.12%, op_acc: 55.47%] [G loss: 0.925649]\n",
      "1058 [D loss: 0.313951, acc: 72.66%, op_acc: 51.56%] [G loss: 0.868999]\n",
      "1059 [D loss: 0.320408, acc: 67.19%, op_acc: 53.91%] [G loss: 0.866059]\n",
      "1060 [D loss: 0.302930, acc: 74.22%, op_acc: 53.12%] [G loss: 0.858718]\n",
      "Epoch: 1060, F1: 0.28571, F1P: 106\n",
      "[[28427     5]\n",
      " [   40     9]]\n",
      "73.671875\n",
      "1061 [D loss: 0.309078, acc: 71.09%, op_acc: 53.12%] [G loss: 0.875008]\n",
      "1062 [D loss: 0.312926, acc: 71.88%, op_acc: 57.81%] [G loss: 0.880717]\n",
      "1063 [D loss: 0.303101, acc: 71.88%, op_acc: 50.00%] [G loss: 0.893422]\n",
      "1064 [D loss: 0.307325, acc: 70.31%, op_acc: 56.25%] [G loss: 0.892349]\n",
      "1065 [D loss: 0.306249, acc: 69.53%, op_acc: 53.12%] [G loss: 0.886483]\n",
      "1066 [D loss: 0.301235, acc: 79.69%, op_acc: 56.25%] [G loss: 0.855373]\n",
      "1067 [D loss: 0.310851, acc: 71.09%, op_acc: 53.12%] [G loss: 0.882900]\n",
      "1068 [D loss: 0.302141, acc: 72.66%, op_acc: 64.06%] [G loss: 0.860477]\n",
      "1069 [D loss: 0.300682, acc: 75.78%, op_acc: 58.59%] [G loss: 0.901649]\n",
      "1070 [D loss: 0.314887, acc: 75.78%, op_acc: 56.25%] [G loss: 0.929579]\n",
      "Epoch: 1070, F1: 0.28571, F1P: 107\n",
      "[[28427     5]\n",
      " [   40     9]]\n",
      "72.96875\n",
      "1071 [D loss: 0.298444, acc: 73.44%, op_acc: 51.56%] [G loss: 0.875917]\n",
      "1072 [D loss: 0.302786, acc: 78.91%, op_acc: 56.25%] [G loss: 0.905922]\n",
      "1073 [D loss: 0.314230, acc: 71.09%, op_acc: 57.81%] [G loss: 0.929788]\n",
      "1074 [D loss: 0.305902, acc: 71.88%, op_acc: 59.38%] [G loss: 0.918905]\n",
      "1075 [D loss: 0.301147, acc: 75.00%, op_acc: 53.91%] [G loss: 0.898671]\n",
      "1076 [D loss: 0.323836, acc: 73.44%, op_acc: 55.47%] [G loss: 0.874300]\n",
      "1077 [D loss: 0.299858, acc: 80.47%, op_acc: 58.59%] [G loss: 0.869927]\n",
      "1078 [D loss: 0.308312, acc: 75.00%, op_acc: 54.69%] [G loss: 0.867999]\n",
      "1079 [D loss: 0.300426, acc: 76.56%, op_acc: 56.25%] [G loss: 0.862592]\n",
      "1080 [D loss: 0.308801, acc: 71.88%, op_acc: 58.59%] [G loss: 0.878974]\n",
      "Epoch: 1080, F1: 0.36364, F1P: 108\n",
      "[[28427     5]\n",
      " [   37    12]]\n",
      "74.765625\n",
      "1081 [D loss: 0.294486, acc: 78.91%, op_acc: 56.25%] [G loss: 0.870581]\n",
      "1082 [D loss: 0.301012, acc: 79.69%, op_acc: 58.59%] [G loss: 0.847951]\n",
      "1083 [D loss: 0.303739, acc: 72.66%, op_acc: 58.59%] [G loss: 0.903954]\n",
      "1084 [D loss: 0.302020, acc: 71.88%, op_acc: 58.59%] [G loss: 0.874926]\n",
      "1085 [D loss: 0.320996, acc: 67.97%, op_acc: 57.03%] [G loss: 0.893695]\n",
      "1086 [D loss: 0.305470, acc: 72.66%, op_acc: 55.47%] [G loss: 0.899393]\n",
      "1087 [D loss: 0.315436, acc: 70.31%, op_acc: 53.12%] [G loss: 0.893153]\n",
      "1088 [D loss: 0.311437, acc: 68.75%, op_acc: 58.59%] [G loss: 0.900338]\n",
      "1089 [D loss: 0.287310, acc: 83.59%, op_acc: 62.50%] [G loss: 0.896735]\n",
      "1090 [D loss: 0.306386, acc: 75.78%, op_acc: 51.56%] [G loss: 0.901154]\n",
      "Epoch: 1090, F1: 0.36364, F1P: 109\n",
      "[[28427     5]\n",
      " [   37    12]]\n",
      "74.21875\n",
      "1091 [D loss: 0.297804, acc: 76.56%, op_acc: 62.50%] [G loss: 0.904975]\n",
      "1092 [D loss: 0.294401, acc: 79.69%, op_acc: 57.03%] [G loss: 0.884593]\n",
      "1093 [D loss: 0.309062, acc: 74.22%, op_acc: 55.47%] [G loss: 0.910069]\n",
      "1094 [D loss: 0.298961, acc: 78.91%, op_acc: 57.81%] [G loss: 0.879146]\n",
      "1095 [D loss: 0.315791, acc: 71.09%, op_acc: 56.25%] [G loss: 0.897001]\n",
      "1096 [D loss: 0.297118, acc: 77.34%, op_acc: 54.69%] [G loss: 0.889684]\n",
      "1097 [D loss: 0.293591, acc: 81.25%, op_acc: 59.38%] [G loss: 0.860124]\n",
      "1098 [D loss: 0.313089, acc: 68.75%, op_acc: 57.03%] [G loss: 0.898442]\n",
      "1099 [D loss: 0.305885, acc: 71.09%, op_acc: 57.03%] [G loss: 0.895210]\n",
      "1100 [D loss: 0.317266, acc: 67.97%, op_acc: 59.38%] [G loss: 0.878112]\n",
      "Epoch: 1100, F1: 0.36364, F1P: 110\n",
      "[[28427     5]\n",
      " [   37    12]]\n",
      "74.6875\n",
      "1101 [D loss: 0.301229, acc: 78.12%, op_acc: 56.25%] [G loss: 0.902144]\n",
      "1102 [D loss: 0.296873, acc: 75.00%, op_acc: 57.03%] [G loss: 0.901984]\n",
      "1103 [D loss: 0.297067, acc: 75.78%, op_acc: 60.94%] [G loss: 0.895440]\n",
      "1104 [D loss: 0.308129, acc: 73.44%, op_acc: 59.38%] [G loss: 0.866518]\n",
      "1105 [D loss: 0.302075, acc: 77.34%, op_acc: 57.03%] [G loss: 0.887001]\n",
      "1106 [D loss: 0.284784, acc: 78.91%, op_acc: 58.59%] [G loss: 0.894659]\n",
      "1107 [D loss: 0.296402, acc: 72.66%, op_acc: 67.19%] [G loss: 0.922549]\n",
      "1108 [D loss: 0.316607, acc: 66.41%, op_acc: 52.34%] [G loss: 0.906097]\n",
      "1109 [D loss: 0.301321, acc: 74.22%, op_acc: 58.59%] [G loss: 0.891851]\n",
      "1110 [D loss: 0.301659, acc: 76.56%, op_acc: 56.25%] [G loss: 0.848116]\n",
      "Epoch: 1110, F1: 0.38806, F1P: 111\n",
      "[[28427     5]\n",
      " [   36    13]]\n",
      "74.84375\n",
      "1111 [D loss: 0.303170, acc: 73.44%, op_acc: 63.28%] [G loss: 0.915517]\n",
      "1112 [D loss: 0.303970, acc: 75.00%, op_acc: 54.69%] [G loss: 0.881107]\n",
      "1113 [D loss: 0.290770, acc: 81.25%, op_acc: 60.16%] [G loss: 0.909448]\n",
      "1114 [D loss: 0.309016, acc: 75.78%, op_acc: 60.94%] [G loss: 0.873992]\n",
      "1115 [D loss: 0.295271, acc: 75.78%, op_acc: 63.28%] [G loss: 0.921079]\n",
      "1116 [D loss: 0.297726, acc: 79.69%, op_acc: 58.59%] [G loss: 0.875800]\n",
      "1117 [D loss: 0.314904, acc: 70.31%, op_acc: 54.69%] [G loss: 0.898600]\n",
      "1118 [D loss: 0.306448, acc: 77.34%, op_acc: 53.91%] [G loss: 0.920668]\n",
      "1119 [D loss: 0.302108, acc: 80.47%, op_acc: 57.03%] [G loss: 0.895597]\n",
      "1120 [D loss: 0.288968, acc: 78.91%, op_acc: 60.16%] [G loss: 0.860748]\n",
      "Epoch: 1120, F1: 0.38806, F1P: 112\n",
      "[[28427     5]\n",
      " [   36    13]]\n",
      "76.796875\n",
      "1121 [D loss: 0.296710, acc: 77.34%, op_acc: 57.81%] [G loss: 0.902284]\n",
      "1122 [D loss: 0.292017, acc: 80.47%, op_acc: 59.38%] [G loss: 0.860923]\n",
      "1123 [D loss: 0.299178, acc: 77.34%, op_acc: 52.34%] [G loss: 0.898439]\n",
      "1124 [D loss: 0.303526, acc: 73.44%, op_acc: 59.38%] [G loss: 0.874872]\n",
      "1125 [D loss: 0.306010, acc: 76.56%, op_acc: 57.81%] [G loss: 0.921835]\n",
      "1126 [D loss: 0.291346, acc: 80.47%, op_acc: 59.38%] [G loss: 0.914284]\n",
      "1127 [D loss: 0.301510, acc: 75.78%, op_acc: 60.16%] [G loss: 0.928847]\n",
      "1128 [D loss: 0.300973, acc: 80.47%, op_acc: 58.59%] [G loss: 0.897910]\n",
      "1129 [D loss: 0.287204, acc: 79.69%, op_acc: 64.06%] [G loss: 0.904407]\n",
      "1130 [D loss: 0.303647, acc: 73.44%, op_acc: 58.59%] [G loss: 0.915865]\n",
      "Epoch: 1130, F1: 0.38806, F1P: 113\n",
      "[[28427     5]\n",
      " [   36    13]]\n",
      "77.5\n",
      "1131 [D loss: 0.300485, acc: 78.12%, op_acc: 59.38%] [G loss: 0.902807]\n",
      "1132 [D loss: 0.314132, acc: 69.53%, op_acc: 53.12%] [G loss: 0.904273]\n",
      "1133 [D loss: 0.308608, acc: 71.09%, op_acc: 64.84%] [G loss: 0.879673]\n",
      "1134 [D loss: 0.292504, acc: 79.69%, op_acc: 57.03%] [G loss: 0.847350]\n",
      "1135 [D loss: 0.298762, acc: 74.22%, op_acc: 50.78%] [G loss: 0.884996]\n",
      "1136 [D loss: 0.297574, acc: 76.56%, op_acc: 56.25%] [G loss: 0.881691]\n",
      "1137 [D loss: 0.289740, acc: 79.69%, op_acc: 60.16%] [G loss: 0.921334]\n",
      "1138 [D loss: 0.305267, acc: 73.44%, op_acc: 57.81%] [G loss: 0.879902]\n",
      "1139 [D loss: 0.310960, acc: 75.78%, op_acc: 64.84%] [G loss: 0.859008]\n",
      "1140 [D loss: 0.304002, acc: 75.78%, op_acc: 60.16%] [G loss: 0.852080]\n",
      "Epoch: 1140, F1: 0.38806, F1P: 114\n",
      "[[28427     5]\n",
      " [   36    13]]\n",
      "75.390625\n",
      "1141 [D loss: 0.285791, acc: 79.69%, op_acc: 62.50%] [G loss: 0.900910]\n",
      "1142 [D loss: 0.299361, acc: 76.56%, op_acc: 55.47%] [G loss: 0.894146]\n",
      "1143 [D loss: 0.303097, acc: 79.69%, op_acc: 57.81%] [G loss: 0.891534]\n",
      "1144 [D loss: 0.296200, acc: 74.22%, op_acc: 62.50%] [G loss: 0.919206]\n",
      "1145 [D loss: 0.300362, acc: 77.34%, op_acc: 51.56%] [G loss: 0.911444]\n",
      "1146 [D loss: 0.306614, acc: 72.66%, op_acc: 50.00%] [G loss: 0.933189]\n",
      "1147 [D loss: 0.308054, acc: 74.22%, op_acc: 58.59%] [G loss: 0.899880]\n",
      "1148 [D loss: 0.304024, acc: 70.31%, op_acc: 57.81%] [G loss: 0.871128]\n",
      "1149 [D loss: 0.289104, acc: 78.91%, op_acc: 60.16%] [G loss: 0.879431]\n",
      "1150 [D loss: 0.296837, acc: 77.34%, op_acc: 54.69%] [G loss: 0.845343]\n",
      "Epoch: 1150, F1: 0.38806, F1P: 115\n",
      "[[28427     5]\n",
      " [   36    13]]\n",
      "76.09375\n",
      "1151 [D loss: 0.298963, acc: 77.34%, op_acc: 55.47%] [G loss: 0.910654]\n",
      "1152 [D loss: 0.319142, acc: 73.44%, op_acc: 64.06%] [G loss: 0.891436]\n",
      "1153 [D loss: 0.301976, acc: 72.66%, op_acc: 63.28%] [G loss: 0.926491]\n",
      "1154 [D loss: 0.297800, acc: 78.91%, op_acc: 56.25%] [G loss: 0.849926]\n",
      "1155 [D loss: 0.303866, acc: 69.53%, op_acc: 51.56%] [G loss: 0.887005]\n",
      "1156 [D loss: 0.307710, acc: 75.00%, op_acc: 61.72%] [G loss: 0.905379]\n",
      "1157 [D loss: 0.298898, acc: 73.44%, op_acc: 57.81%] [G loss: 0.890634]\n",
      "1158 [D loss: 0.296928, acc: 74.22%, op_acc: 56.25%] [G loss: 0.870300]\n",
      "1159 [D loss: 0.297270, acc: 75.00%, op_acc: 54.69%] [G loss: 0.908601]\n",
      "1160 [D loss: 0.297366, acc: 79.69%, op_acc: 64.84%] [G loss: 0.867753]\n",
      "Epoch: 1160, F1: 0.38806, F1P: 116\n",
      "[[28427     5]\n",
      " [   36    13]]\n",
      "74.921875\n",
      "1161 [D loss: 0.307217, acc: 72.66%, op_acc: 65.62%] [G loss: 0.897921]\n",
      "1162 [D loss: 0.302452, acc: 76.56%, op_acc: 57.81%] [G loss: 0.895078]\n",
      "1163 [D loss: 0.296012, acc: 77.34%, op_acc: 53.91%] [G loss: 0.909500]\n",
      "1164 [D loss: 0.290223, acc: 79.69%, op_acc: 59.38%] [G loss: 0.928065]\n",
      "1165 [D loss: 0.299089, acc: 81.25%, op_acc: 56.25%] [G loss: 0.895044]\n",
      "1166 [D loss: 0.294636, acc: 78.12%, op_acc: 55.47%] [G loss: 0.916270]\n",
      "1167 [D loss: 0.313061, acc: 67.97%, op_acc: 55.47%] [G loss: 0.852350]\n",
      "1168 [D loss: 0.302786, acc: 76.56%, op_acc: 58.59%] [G loss: 0.921404]\n",
      "1169 [D loss: 0.307532, acc: 74.22%, op_acc: 63.28%] [G loss: 0.883055]\n",
      "1170 [D loss: 0.298680, acc: 78.12%, op_acc: 57.81%] [G loss: 0.961593]\n",
      "Epoch: 1170, F1: 0.43478, F1P: 117\n",
      "[[28427     5]\n",
      " [   34    15]]\n",
      "76.25\n",
      "1171 [D loss: 0.291735, acc: 79.69%, op_acc: 66.41%] [G loss: 0.894009]\n",
      "1172 [D loss: 0.294998, acc: 75.78%, op_acc: 63.28%] [G loss: 0.905129]\n",
      "1173 [D loss: 0.307544, acc: 73.44%, op_acc: 64.06%] [G loss: 0.913709]\n",
      "1174 [D loss: 0.297578, acc: 80.47%, op_acc: 61.72%] [G loss: 0.939938]\n",
      "1175 [D loss: 0.301401, acc: 78.12%, op_acc: 61.72%] [G loss: 0.903494]\n",
      "1176 [D loss: 0.308568, acc: 67.19%, op_acc: 56.25%] [G loss: 0.881295]\n",
      "1177 [D loss: 0.289021, acc: 75.78%, op_acc: 64.06%] [G loss: 0.919283]\n",
      "1178 [D loss: 0.295037, acc: 77.34%, op_acc: 63.28%] [G loss: 0.872064]\n",
      "1179 [D loss: 0.309384, acc: 70.31%, op_acc: 56.25%] [G loss: 0.916589]\n",
      "1180 [D loss: 0.290771, acc: 81.25%, op_acc: 63.28%] [G loss: 0.903193]\n",
      "Epoch: 1180, F1: 0.43478, F1P: 118\n",
      "[[28427     5]\n",
      " [   34    15]]\n",
      "75.9375\n",
      "1181 [D loss: 0.304586, acc: 72.66%, op_acc: 54.69%] [G loss: 0.911890]\n",
      "1182 [D loss: 0.295199, acc: 78.12%, op_acc: 64.06%] [G loss: 0.912890]\n",
      "1183 [D loss: 0.301004, acc: 78.91%, op_acc: 58.59%] [G loss: 0.903218]\n",
      "1184 [D loss: 0.303849, acc: 78.12%, op_acc: 60.16%] [G loss: 0.925363]\n",
      "1185 [D loss: 0.293309, acc: 77.34%, op_acc: 59.38%] [G loss: 0.934268]\n",
      "1186 [D loss: 0.307558, acc: 69.53%, op_acc: 52.34%] [G loss: 0.866650]\n",
      "1187 [D loss: 0.296502, acc: 76.56%, op_acc: 54.69%] [G loss: 0.910192]\n",
      "1188 [D loss: 0.294777, acc: 78.91%, op_acc: 57.81%] [G loss: 0.926556]\n",
      "1189 [D loss: 0.287316, acc: 81.25%, op_acc: 66.41%] [G loss: 0.895237]\n",
      "1190 [D loss: 0.298438, acc: 70.31%, op_acc: 62.50%] [G loss: 0.923228]\n",
      "Epoch: 1190, F1: 0.43478, F1P: 119\n",
      "[[28427     5]\n",
      " [   34    15]]\n",
      "76.171875\n",
      "1191 [D loss: 0.299542, acc: 75.00%, op_acc: 60.94%] [G loss: 0.904363]\n",
      "1192 [D loss: 0.288873, acc: 80.47%, op_acc: 57.81%] [G loss: 0.899148]\n",
      "1193 [D loss: 0.292513, acc: 78.91%, op_acc: 53.12%] [G loss: 0.943663]\n",
      "1194 [D loss: 0.303730, acc: 74.22%, op_acc: 63.28%] [G loss: 0.945021]\n",
      "1195 [D loss: 0.301125, acc: 77.34%, op_acc: 61.72%] [G loss: 0.923211]\n",
      "1196 [D loss: 0.305431, acc: 75.00%, op_acc: 56.25%] [G loss: 0.881854]\n",
      "1197 [D loss: 0.296623, acc: 76.56%, op_acc: 52.34%] [G loss: 0.906775]\n",
      "1198 [D loss: 0.306676, acc: 75.78%, op_acc: 53.91%] [G loss: 0.923154]\n",
      "1199 [D loss: 0.298694, acc: 72.66%, op_acc: 69.53%] [G loss: 0.910152]\n",
      "1200 [D loss: 0.292237, acc: 75.00%, op_acc: 60.94%] [G loss: 0.934083]\n",
      "Epoch: 1200, F1: 0.43478, F1P: 120\n",
      "[[28427     5]\n",
      " [   34    15]]\n",
      "76.09375\n",
      "1201 [D loss: 0.297953, acc: 82.81%, op_acc: 67.19%] [G loss: 0.879675]\n",
      "1202 [D loss: 0.304640, acc: 75.78%, op_acc: 60.94%] [G loss: 0.916442]\n",
      "1203 [D loss: 0.308055, acc: 72.66%, op_acc: 57.03%] [G loss: 0.900490]\n",
      "1204 [D loss: 0.304431, acc: 73.44%, op_acc: 61.72%] [G loss: 0.899328]\n",
      "1205 [D loss: 0.283473, acc: 78.12%, op_acc: 64.06%] [G loss: 0.916756]\n",
      "1206 [D loss: 0.297932, acc: 77.34%, op_acc: 55.47%] [G loss: 0.986878]\n",
      "1207 [D loss: 0.296547, acc: 79.69%, op_acc: 64.84%] [G loss: 0.925311]\n",
      "1208 [D loss: 0.290018, acc: 77.34%, op_acc: 64.84%] [G loss: 0.944490]\n",
      "1209 [D loss: 0.286593, acc: 84.38%, op_acc: 66.41%] [G loss: 0.944953]\n",
      "1210 [D loss: 0.293543, acc: 80.47%, op_acc: 60.16%] [G loss: 0.877540]\n",
      "Epoch: 1210, F1: 0.43478, F1P: 121\n",
      "[[28427     5]\n",
      " [   34    15]]\n",
      "78.203125\n",
      "1211 [D loss: 0.294819, acc: 78.91%, op_acc: 59.38%] [G loss: 0.931391]\n",
      "1212 [D loss: 0.299879, acc: 73.44%, op_acc: 57.81%] [G loss: 0.929874]\n",
      "1213 [D loss: 0.300063, acc: 78.12%, op_acc: 59.38%] [G loss: 0.926736]\n",
      "1214 [D loss: 0.293350, acc: 80.47%, op_acc: 57.03%] [G loss: 0.899212]\n",
      "1215 [D loss: 0.290133, acc: 78.91%, op_acc: 54.69%] [G loss: 0.900906]\n",
      "1216 [D loss: 0.302949, acc: 79.69%, op_acc: 60.94%] [G loss: 0.907879]\n",
      "1217 [D loss: 0.285506, acc: 83.59%, op_acc: 67.19%] [G loss: 0.900062]\n",
      "1218 [D loss: 0.308586, acc: 70.31%, op_acc: 57.03%] [G loss: 0.955756]\n",
      "1219 [D loss: 0.290368, acc: 77.34%, op_acc: 58.59%] [G loss: 0.931521]\n",
      "1220 [D loss: 0.291083, acc: 76.56%, op_acc: 65.62%] [G loss: 0.939928]\n",
      "Epoch: 1220, F1: 0.47887, F1P: 122\n",
      "[[28427     5]\n",
      " [   32    17]]\n",
      "77.734375\n",
      "1221 [D loss: 0.279098, acc: 80.47%, op_acc: 62.50%] [G loss: 0.916835]\n",
      "1222 [D loss: 0.286641, acc: 78.12%, op_acc: 57.81%] [G loss: 0.899351]\n",
      "1223 [D loss: 0.285679, acc: 79.69%, op_acc: 57.81%] [G loss: 0.948308]\n",
      "1224 [D loss: 0.291749, acc: 82.81%, op_acc: 64.84%] [G loss: 0.934762]\n",
      "1225 [D loss: 0.285384, acc: 81.25%, op_acc: 57.03%] [G loss: 0.940930]\n",
      "1226 [D loss: 0.282712, acc: 79.69%, op_acc: 64.84%] [G loss: 0.916213]\n",
      "1227 [D loss: 0.286068, acc: 76.56%, op_acc: 55.47%] [G loss: 0.890238]\n",
      "1228 [D loss: 0.295748, acc: 79.69%, op_acc: 59.38%] [G loss: 0.942719]\n",
      "1229 [D loss: 0.282051, acc: 84.38%, op_acc: 57.03%] [G loss: 0.940305]\n",
      "1230 [D loss: 0.286588, acc: 78.12%, op_acc: 71.09%] [G loss: 0.928883]\n",
      "Epoch: 1230, F1: 0.57895, F1P: 123\n",
      "[[28427     5]\n",
      " [   27    22]]\n",
      "80.078125\n",
      "1231 [D loss: 0.292337, acc: 75.78%, op_acc: 57.81%] [G loss: 0.913117]\n",
      "1232 [D loss: 0.281349, acc: 86.72%, op_acc: 62.50%] [G loss: 0.921717]\n",
      "1233 [D loss: 0.299659, acc: 76.56%, op_acc: 54.69%] [G loss: 0.890426]\n",
      "1234 [D loss: 0.281706, acc: 80.47%, op_acc: 61.72%] [G loss: 0.917475]\n",
      "1235 [D loss: 0.298949, acc: 71.88%, op_acc: 61.72%] [G loss: 0.950641]\n",
      "1236 [D loss: 0.300354, acc: 80.47%, op_acc: 60.16%] [G loss: 0.932598]\n",
      "1237 [D loss: 0.278125, acc: 76.56%, op_acc: 71.09%] [G loss: 0.931564]\n",
      "1238 [D loss: 0.280690, acc: 83.59%, op_acc: 59.38%] [G loss: 0.907536]\n",
      "1239 [D loss: 0.291277, acc: 76.56%, op_acc: 62.50%] [G loss: 0.953025]\n",
      "1240 [D loss: 0.286195, acc: 78.91%, op_acc: 66.41%] [G loss: 0.901810]\n",
      "Epoch: 1240, F1: 0.50000, F1P: 124\n",
      "[[28427     5]\n",
      " [   31    18]]\n",
      "78.75\n",
      "1241 [D loss: 0.284885, acc: 75.78%, op_acc: 64.06%] [G loss: 0.921344]\n",
      "1242 [D loss: 0.301168, acc: 81.25%, op_acc: 66.41%] [G loss: 0.887097]\n",
      "1243 [D loss: 0.283393, acc: 80.47%, op_acc: 63.28%] [G loss: 0.934255]\n",
      "1244 [D loss: 0.287842, acc: 82.81%, op_acc: 64.84%] [G loss: 0.956794]\n",
      "1245 [D loss: 0.284840, acc: 82.03%, op_acc: 57.81%] [G loss: 0.941348]\n",
      "1246 [D loss: 0.297917, acc: 75.00%, op_acc: 66.41%] [G loss: 0.964097]\n",
      "1247 [D loss: 0.284297, acc: 81.25%, op_acc: 59.38%] [G loss: 0.917981]\n",
      "1248 [D loss: 0.281328, acc: 81.25%, op_acc: 67.97%] [G loss: 0.925538]\n",
      "1249 [D loss: 0.284802, acc: 77.34%, op_acc: 64.06%] [G loss: 0.915395]\n",
      "1250 [D loss: 0.298721, acc: 78.91%, op_acc: 58.59%] [G loss: 0.950291]\n",
      "Epoch: 1250, F1: 0.54054, F1P: 125\n",
      "[[28427     5]\n",
      " [   29    20]]\n",
      "79.609375\n",
      "1251 [D loss: 0.295982, acc: 78.91%, op_acc: 60.94%] [G loss: 0.962749]\n",
      "1252 [D loss: 0.291466, acc: 81.25%, op_acc: 65.62%] [G loss: 0.946371]\n",
      "1253 [D loss: 0.272786, acc: 87.50%, op_acc: 63.28%] [G loss: 0.937671]\n",
      "1254 [D loss: 0.275864, acc: 81.25%, op_acc: 64.84%] [G loss: 0.926353]\n",
      "1255 [D loss: 0.286931, acc: 82.81%, op_acc: 71.09%] [G loss: 0.903055]\n",
      "1256 [D loss: 0.278986, acc: 82.03%, op_acc: 67.19%] [G loss: 0.940686]\n",
      "1257 [D loss: 0.287458, acc: 82.03%, op_acc: 62.50%] [G loss: 0.948686]\n",
      "1258 [D loss: 0.284568, acc: 75.00%, op_acc: 63.28%] [G loss: 0.952679]\n",
      "1259 [D loss: 0.291948, acc: 76.56%, op_acc: 66.41%] [G loss: 0.936720]\n",
      "1260 [D loss: 0.284623, acc: 87.50%, op_acc: 68.75%] [G loss: 0.921632]\n",
      "Epoch: 1260, F1: 0.59740, F1P: 126\n",
      "[[28427     5]\n",
      " [   26    23]]\n",
      "81.484375\n",
      "1261 [D loss: 0.275971, acc: 82.81%, op_acc: 60.94%] [G loss: 0.969999]\n",
      "1262 [D loss: 0.270986, acc: 85.16%, op_acc: 66.41%] [G loss: 0.959975]\n",
      "1263 [D loss: 0.288996, acc: 82.81%, op_acc: 59.38%] [G loss: 0.934105]\n",
      "1264 [D loss: 0.281318, acc: 83.59%, op_acc: 53.91%] [G loss: 0.900291]\n",
      "1265 [D loss: 0.286600, acc: 73.44%, op_acc: 66.41%] [G loss: 0.944352]\n",
      "1266 [D loss: 0.285210, acc: 79.69%, op_acc: 50.78%] [G loss: 0.965044]\n",
      "1267 [D loss: 0.286917, acc: 82.81%, op_acc: 64.06%] [G loss: 0.914629]\n",
      "1268 [D loss: 0.280935, acc: 82.81%, op_acc: 55.47%] [G loss: 0.923853]\n",
      "1269 [D loss: 0.272453, acc: 85.16%, op_acc: 62.50%] [G loss: 0.946611]\n",
      "1270 [D loss: 0.284698, acc: 79.69%, op_acc: 62.50%] [G loss: 0.914322]\n",
      "Epoch: 1270, F1: 0.58974, F1P: 127\n",
      "[[28426     6]\n",
      " [   26    23]]\n",
      "81.796875\n",
      "1271 [D loss: 0.287795, acc: 82.03%, op_acc: 60.94%] [G loss: 0.952037]\n",
      "1272 [D loss: 0.276389, acc: 84.38%, op_acc: 58.59%] [G loss: 0.923125]\n",
      "1273 [D loss: 0.272200, acc: 85.94%, op_acc: 71.09%] [G loss: 0.904875]\n",
      "1274 [D loss: 0.292671, acc: 78.12%, op_acc: 55.47%] [G loss: 1.003761]\n",
      "1275 [D loss: 0.285129, acc: 84.38%, op_acc: 56.25%] [G loss: 0.964750]\n",
      "1276 [D loss: 0.276846, acc: 85.94%, op_acc: 64.06%] [G loss: 0.919904]\n",
      "1277 [D loss: 0.288322, acc: 78.12%, op_acc: 60.16%] [G loss: 0.902509]\n",
      "1278 [D loss: 0.277235, acc: 85.94%, op_acc: 61.72%] [G loss: 0.930412]\n",
      "1279 [D loss: 0.275875, acc: 84.38%, op_acc: 58.59%] [G loss: 0.935846]\n",
      "1280 [D loss: 0.276256, acc: 78.12%, op_acc: 63.28%] [G loss: 0.979668]\n",
      "Epoch: 1280, F1: 0.59740, F1P: 128\n",
      "[[28427     5]\n",
      " [   26    23]]\n",
      "82.734375\n",
      "1281 [D loss: 0.278470, acc: 81.25%, op_acc: 61.72%] [G loss: 0.959163]\n",
      "1282 [D loss: 0.279860, acc: 79.69%, op_acc: 67.19%] [G loss: 0.927095]\n",
      "1283 [D loss: 0.270026, acc: 86.72%, op_acc: 63.28%] [G loss: 0.971974]\n",
      "1284 [D loss: 0.281766, acc: 83.59%, op_acc: 67.19%] [G loss: 0.944649]\n",
      "1285 [D loss: 0.276114, acc: 87.50%, op_acc: 67.97%] [G loss: 0.951213]\n",
      "1286 [D loss: 0.280424, acc: 84.38%, op_acc: 61.72%] [G loss: 0.901011]\n",
      "1287 [D loss: 0.281355, acc: 82.03%, op_acc: 66.41%] [G loss: 0.984937]\n",
      "1288 [D loss: 0.284631, acc: 80.47%, op_acc: 66.41%] [G loss: 1.000696]\n",
      "1289 [D loss: 0.288450, acc: 84.38%, op_acc: 64.84%] [G loss: 0.946019]\n",
      "1290 [D loss: 0.287128, acc: 83.59%, op_acc: 61.72%] [G loss: 0.967093]\n",
      "Epoch: 1290, F1: 0.61538, F1P: 129\n",
      "[[28427     5]\n",
      " [   25    24]]\n",
      "83.359375\n",
      "1291 [D loss: 0.286467, acc: 81.25%, op_acc: 54.69%] [G loss: 0.941836]\n",
      "1292 [D loss: 0.288546, acc: 73.44%, op_acc: 60.16%] [G loss: 0.993833]\n",
      "1293 [D loss: 0.263015, acc: 85.16%, op_acc: 68.75%] [G loss: 0.968392]\n",
      "1294 [D loss: 0.291683, acc: 76.56%, op_acc: 65.62%] [G loss: 0.969660]\n",
      "1295 [D loss: 0.285146, acc: 81.25%, op_acc: 57.81%] [G loss: 0.991718]\n",
      "1296 [D loss: 0.272782, acc: 82.81%, op_acc: 65.62%] [G loss: 0.937484]\n",
      "1297 [D loss: 0.272114, acc: 81.25%, op_acc: 62.50%] [G loss: 0.953307]\n",
      "1298 [D loss: 0.279720, acc: 82.81%, op_acc: 62.50%] [G loss: 0.990615]\n",
      "1299 [D loss: 0.288397, acc: 83.59%, op_acc: 66.41%] [G loss: 0.973071]\n",
      "1300 [D loss: 0.288424, acc: 81.25%, op_acc: 65.62%] [G loss: 0.994639]\n",
      "Epoch: 1300, F1: 0.60759, F1P: 130\n",
      "[[28426     6]\n",
      " [   25    24]]\n",
      "80.9375\n",
      "1301 [D loss: 0.267700, acc: 82.81%, op_acc: 62.50%] [G loss: 0.926087]\n",
      "1302 [D loss: 0.284800, acc: 78.12%, op_acc: 61.72%] [G loss: 1.015889]\n",
      "1303 [D loss: 0.288004, acc: 76.56%, op_acc: 61.72%] [G loss: 0.930174]\n",
      "1304 [D loss: 0.267619, acc: 85.16%, op_acc: 70.31%] [G loss: 0.940079]\n",
      "1305 [D loss: 0.279141, acc: 80.47%, op_acc: 68.75%] [G loss: 1.016899]\n",
      "1306 [D loss: 0.287818, acc: 78.12%, op_acc: 65.62%] [G loss: 0.960396]\n",
      "1307 [D loss: 0.284887, acc: 83.59%, op_acc: 64.06%] [G loss: 0.966763]\n",
      "1308 [D loss: 0.290883, acc: 80.47%, op_acc: 64.84%] [G loss: 0.979198]\n",
      "1309 [D loss: 0.271834, acc: 90.62%, op_acc: 64.84%] [G loss: 0.945689]\n",
      "1310 [D loss: 0.279086, acc: 81.25%, op_acc: 67.19%] [G loss: 0.964658]\n",
      "Epoch: 1310, F1: 0.59740, F1P: 131\n",
      "[[28427     5]\n",
      " [   26    23]]\n",
      "81.71875\n",
      "1311 [D loss: 0.276710, acc: 80.47%, op_acc: 60.16%] [G loss: 0.918087]\n",
      "1312 [D loss: 0.281131, acc: 83.59%, op_acc: 62.50%] [G loss: 1.006344]\n",
      "1313 [D loss: 0.274156, acc: 82.81%, op_acc: 60.94%] [G loss: 0.987692]\n",
      "1314 [D loss: 0.287221, acc: 83.59%, op_acc: 69.53%] [G loss: 0.937839]\n",
      "1315 [D loss: 0.286804, acc: 80.47%, op_acc: 69.53%] [G loss: 0.971307]\n",
      "1316 [D loss: 0.279921, acc: 84.38%, op_acc: 61.72%] [G loss: 0.984871]\n",
      "1317 [D loss: 0.278489, acc: 81.25%, op_acc: 60.94%] [G loss: 0.910644]\n",
      "1318 [D loss: 0.298345, acc: 77.34%, op_acc: 62.50%] [G loss: 0.983492]\n",
      "1319 [D loss: 0.275106, acc: 83.59%, op_acc: 62.50%] [G loss: 0.947581]\n",
      "1320 [D loss: 0.289394, acc: 75.78%, op_acc: 62.50%] [G loss: 0.948856]\n",
      "Epoch: 1320, F1: 0.61538, F1P: 132\n",
      "[[28427     5]\n",
      " [   25    24]]\n",
      "81.328125\n",
      "1321 [D loss: 0.293182, acc: 78.12%, op_acc: 60.94%] [G loss: 0.969104]\n",
      "1322 [D loss: 0.283053, acc: 81.25%, op_acc: 57.03%] [G loss: 1.005494]\n",
      "1323 [D loss: 0.277615, acc: 83.59%, op_acc: 67.19%] [G loss: 1.007623]\n",
      "1324 [D loss: 0.272055, acc: 86.72%, op_acc: 71.09%] [G loss: 0.993711]\n",
      "1325 [D loss: 0.286193, acc: 81.25%, op_acc: 67.97%] [G loss: 0.979298]\n",
      "1326 [D loss: 0.267511, acc: 83.59%, op_acc: 64.06%] [G loss: 0.951775]\n",
      "1327 [D loss: 0.269649, acc: 82.03%, op_acc: 66.41%] [G loss: 0.967676]\n",
      "1328 [D loss: 0.270600, acc: 82.81%, op_acc: 60.94%] [G loss: 0.997357]\n",
      "1329 [D loss: 0.291938, acc: 77.34%, op_acc: 68.75%] [G loss: 0.996186]\n",
      "1330 [D loss: 0.266839, acc: 83.59%, op_acc: 69.53%] [G loss: 0.978753]\n",
      "Epoch: 1330, F1: 0.60759, F1P: 133\n",
      "[[28426     6]\n",
      " [   25    24]]\n",
      "82.03125\n",
      "1331 [D loss: 0.278996, acc: 83.59%, op_acc: 66.41%] [G loss: 1.018940]\n",
      "1332 [D loss: 0.274716, acc: 85.16%, op_acc: 66.41%] [G loss: 0.957092]\n",
      "1333 [D loss: 0.276641, acc: 84.38%, op_acc: 71.09%] [G loss: 0.989143]\n",
      "1334 [D loss: 0.260057, acc: 88.28%, op_acc: 64.84%] [G loss: 0.983309]\n",
      "1335 [D loss: 0.281015, acc: 82.03%, op_acc: 57.81%] [G loss: 0.979727]\n",
      "1336 [D loss: 0.276713, acc: 80.47%, op_acc: 63.28%] [G loss: 0.992920]\n",
      "1337 [D loss: 0.283465, acc: 78.91%, op_acc: 70.31%] [G loss: 0.994998]\n",
      "1338 [D loss: 0.282921, acc: 82.81%, op_acc: 71.88%] [G loss: 0.963083]\n",
      "1339 [D loss: 0.272284, acc: 85.94%, op_acc: 67.97%] [G loss: 0.976825]\n",
      "1340 [D loss: 0.274520, acc: 85.16%, op_acc: 64.06%] [G loss: 1.018884]\n",
      "Epoch: 1340, F1: 0.60759, F1P: 134\n",
      "[[28426     6]\n",
      " [   25    24]]\n",
      "83.671875\n",
      "1341 [D loss: 0.267321, acc: 84.38%, op_acc: 64.06%] [G loss: 0.942804]\n",
      "1342 [D loss: 0.266159, acc: 81.25%, op_acc: 67.97%] [G loss: 1.007525]\n",
      "1343 [D loss: 0.271131, acc: 85.94%, op_acc: 64.84%] [G loss: 0.996272]\n",
      "1344 [D loss: 0.277739, acc: 78.91%, op_acc: 63.28%] [G loss: 0.980066]\n",
      "1345 [D loss: 0.274552, acc: 81.25%, op_acc: 64.84%] [G loss: 0.985843]\n",
      "1346 [D loss: 0.274941, acc: 86.72%, op_acc: 69.53%] [G loss: 0.938528]\n",
      "1347 [D loss: 0.293823, acc: 74.22%, op_acc: 59.38%] [G loss: 0.954190]\n",
      "1348 [D loss: 0.272785, acc: 79.69%, op_acc: 62.50%] [G loss: 1.016203]\n",
      "1349 [D loss: 0.273283, acc: 78.91%, op_acc: 71.09%] [G loss: 0.998881]\n",
      "1350 [D loss: 0.291565, acc: 74.22%, op_acc: 64.84%] [G loss: 0.982937]\n",
      "Epoch: 1350, F1: 0.60759, F1P: 135\n",
      "[[28426     6]\n",
      " [   25    24]]\n",
      "80.546875\n",
      "1351 [D loss: 0.276377, acc: 80.47%, op_acc: 68.75%] [G loss: 0.997701]\n",
      "1352 [D loss: 0.282173, acc: 78.91%, op_acc: 64.84%] [G loss: 1.005846]\n",
      "1353 [D loss: 0.265809, acc: 85.94%, op_acc: 65.62%] [G loss: 0.975553]\n",
      "1354 [D loss: 0.260762, acc: 83.59%, op_acc: 70.31%] [G loss: 1.000936]\n",
      "1355 [D loss: 0.263699, acc: 85.94%, op_acc: 60.16%] [G loss: 0.990479]\n",
      "1356 [D loss: 0.273474, acc: 84.38%, op_acc: 69.53%] [G loss: 0.946864]\n",
      "1357 [D loss: 0.261259, acc: 87.50%, op_acc: 70.31%] [G loss: 1.036375]\n",
      "1358 [D loss: 0.271936, acc: 82.81%, op_acc: 67.97%] [G loss: 0.990413]\n",
      "1359 [D loss: 0.266935, acc: 85.94%, op_acc: 66.41%] [G loss: 0.967578]\n",
      "1360 [D loss: 0.266823, acc: 85.16%, op_acc: 60.16%] [G loss: 0.978064]\n",
      "Epoch: 1360, F1: 0.60759, F1P: 136\n",
      "[[28426     6]\n",
      " [   25    24]]\n",
      "84.0625\n",
      "1361 [D loss: 0.277715, acc: 81.25%, op_acc: 64.84%] [G loss: 0.971430]\n",
      "1362 [D loss: 0.263242, acc: 87.50%, op_acc: 70.31%] [G loss: 1.025286]\n",
      "1363 [D loss: 0.265273, acc: 81.25%, op_acc: 67.97%] [G loss: 1.000541]\n",
      "1364 [D loss: 0.276431, acc: 81.25%, op_acc: 71.09%] [G loss: 0.961326]\n",
      "1365 [D loss: 0.269363, acc: 80.47%, op_acc: 58.59%] [G loss: 0.965291]\n",
      "1366 [D loss: 0.277616, acc: 78.91%, op_acc: 58.59%] [G loss: 0.978280]\n",
      "1367 [D loss: 0.268782, acc: 82.03%, op_acc: 59.38%] [G loss: 0.987714]\n",
      "1368 [D loss: 0.282048, acc: 79.69%, op_acc: 58.59%] [G loss: 1.031540]\n",
      "1369 [D loss: 0.282209, acc: 80.47%, op_acc: 64.84%] [G loss: 0.971979]\n",
      "1370 [D loss: 0.277391, acc: 81.25%, op_acc: 59.38%] [G loss: 1.015718]\n",
      "Epoch: 1370, F1: 0.61538, F1P: 137\n",
      "[[28427     5]\n",
      " [   25    24]]\n",
      "81.40625\n",
      "1371 [D loss: 0.264718, acc: 80.47%, op_acc: 64.84%] [G loss: 1.003861]\n",
      "1372 [D loss: 0.268626, acc: 85.94%, op_acc: 67.97%] [G loss: 0.976089]\n",
      "1373 [D loss: 0.271360, acc: 88.28%, op_acc: 74.22%] [G loss: 0.989126]\n",
      "1374 [D loss: 0.272917, acc: 85.16%, op_acc: 60.16%] [G loss: 0.965787]\n",
      "1375 [D loss: 0.263096, acc: 88.28%, op_acc: 67.97%] [G loss: 1.028052]\n",
      "1376 [D loss: 0.266732, acc: 82.03%, op_acc: 59.38%] [G loss: 0.978650]\n",
      "1377 [D loss: 0.259255, acc: 82.03%, op_acc: 62.50%] [G loss: 0.978566]\n",
      "1378 [D loss: 0.281581, acc: 76.56%, op_acc: 65.62%] [G loss: 0.964737]\n",
      "1379 [D loss: 0.276169, acc: 81.25%, op_acc: 62.50%] [G loss: 1.001274]\n",
      "1380 [D loss: 0.265293, acc: 82.81%, op_acc: 66.41%] [G loss: 1.003388]\n",
      "Epoch: 1380, F1: 0.61538, F1P: 138\n",
      "[[28427     5]\n",
      " [   25    24]]\n",
      "83.28125\n",
      "1381 [D loss: 0.275314, acc: 84.38%, op_acc: 71.88%] [G loss: 1.018396]\n",
      "1382 [D loss: 0.269541, acc: 85.16%, op_acc: 64.06%] [G loss: 0.992050]\n",
      "1383 [D loss: 0.261478, acc: 85.94%, op_acc: 64.06%] [G loss: 0.998832]\n",
      "1384 [D loss: 0.272336, acc: 82.03%, op_acc: 71.09%] [G loss: 1.013208]\n",
      "1385 [D loss: 0.269305, acc: 83.59%, op_acc: 65.62%] [G loss: 1.007781]\n",
      "1386 [D loss: 0.265939, acc: 85.16%, op_acc: 71.09%] [G loss: 0.988507]\n",
      "1387 [D loss: 0.272704, acc: 80.47%, op_acc: 62.50%] [G loss: 1.015784]\n",
      "1388 [D loss: 0.263564, acc: 85.16%, op_acc: 63.28%] [G loss: 0.996418]\n",
      "1389 [D loss: 0.270107, acc: 88.28%, op_acc: 75.78%] [G loss: 1.003962]\n",
      "1390 [D loss: 0.266810, acc: 85.16%, op_acc: 57.81%] [G loss: 0.988222]\n",
      "Epoch: 1390, F1: 0.60759, F1P: 139\n",
      "[[28426     6]\n",
      " [   25    24]]\n",
      "84.53125\n",
      "1391 [D loss: 0.281537, acc: 76.56%, op_acc: 58.59%] [G loss: 1.018897]\n",
      "1392 [D loss: 0.277164, acc: 85.94%, op_acc: 67.97%] [G loss: 1.003039]\n",
      "1393 [D loss: 0.274425, acc: 81.25%, op_acc: 67.97%] [G loss: 1.000190]\n",
      "1394 [D loss: 0.271359, acc: 87.50%, op_acc: 66.41%] [G loss: 1.039511]\n",
      "1395 [D loss: 0.267842, acc: 82.03%, op_acc: 67.19%] [G loss: 1.018780]\n",
      "1396 [D loss: 0.269243, acc: 86.72%, op_acc: 67.19%] [G loss: 0.971223]\n",
      "1397 [D loss: 0.273502, acc: 82.03%, op_acc: 58.59%] [G loss: 0.984256]\n",
      "1398 [D loss: 0.260140, acc: 86.72%, op_acc: 70.31%] [G loss: 1.007322]\n",
      "1399 [D loss: 0.272792, acc: 82.81%, op_acc: 64.06%] [G loss: 1.002627]\n",
      "1400 [D loss: 0.261939, acc: 88.28%, op_acc: 68.75%] [G loss: 1.009835]\n",
      "Epoch: 1400, F1: 0.60759, F1P: 140\n",
      "[[28426     6]\n",
      " [   25    24]]\n",
      "83.984375\n",
      "1401 [D loss: 0.273297, acc: 85.94%, op_acc: 66.41%] [G loss: 1.041142]\n",
      "1402 [D loss: 0.275911, acc: 76.56%, op_acc: 64.84%] [G loss: 1.010593]\n",
      "1403 [D loss: 0.292019, acc: 82.81%, op_acc: 64.06%] [G loss: 0.982335]\n",
      "1404 [D loss: 0.271946, acc: 82.03%, op_acc: 64.84%] [G loss: 0.960086]\n",
      "1405 [D loss: 0.273117, acc: 85.16%, op_acc: 67.19%] [G loss: 0.980154]\n",
      "1406 [D loss: 0.262374, acc: 85.94%, op_acc: 66.41%] [G loss: 1.053016]\n",
      "1407 [D loss: 0.259546, acc: 85.16%, op_acc: 70.31%] [G loss: 0.994198]\n",
      "1408 [D loss: 0.279081, acc: 79.69%, op_acc: 66.41%] [G loss: 0.972641]\n",
      "1409 [D loss: 0.262321, acc: 84.38%, op_acc: 66.41%] [G loss: 0.944368]\n",
      "1410 [D loss: 0.276945, acc: 82.03%, op_acc: 63.28%] [G loss: 1.032392]\n",
      "Epoch: 1410, F1: 0.60759, F1P: 141\n",
      "[[28426     6]\n",
      " [   25    24]]\n",
      "82.96875\n",
      "1411 [D loss: 0.274393, acc: 85.16%, op_acc: 65.62%] [G loss: 0.998943]\n",
      "1412 [D loss: 0.260268, acc: 85.94%, op_acc: 64.84%] [G loss: 1.015934]\n",
      "1413 [D loss: 0.270547, acc: 85.16%, op_acc: 71.88%] [G loss: 0.981386]\n",
      "1414 [D loss: 0.279941, acc: 75.78%, op_acc: 58.59%] [G loss: 1.007289]\n",
      "1415 [D loss: 0.275305, acc: 85.94%, op_acc: 64.84%] [G loss: 1.037992]\n",
      "1416 [D loss: 0.263597, acc: 85.94%, op_acc: 64.06%] [G loss: 0.999666]\n",
      "1417 [D loss: 0.268192, acc: 85.94%, op_acc: 68.75%] [G loss: 0.985379]\n",
      "1418 [D loss: 0.263953, acc: 82.81%, op_acc: 66.41%] [G loss: 1.035839]\n",
      "1419 [D loss: 0.262278, acc: 85.94%, op_acc: 66.41%] [G loss: 1.071712]\n",
      "1420 [D loss: 0.268854, acc: 85.16%, op_acc: 64.06%] [G loss: 1.028886]\n",
      "Epoch: 1420, F1: 0.60000, F1P: 142\n",
      "[[28425     7]\n",
      " [   25    24]]\n",
      "84.375\n",
      "1421 [D loss: 0.267619, acc: 83.59%, op_acc: 71.09%] [G loss: 0.991163]\n",
      "1422 [D loss: 0.281762, acc: 82.03%, op_acc: 64.06%] [G loss: 1.064837]\n",
      "1423 [D loss: 0.276844, acc: 79.69%, op_acc: 64.84%] [G loss: 1.019389]\n",
      "1424 [D loss: 0.253466, acc: 88.28%, op_acc: 64.84%] [G loss: 1.062388]\n",
      "1425 [D loss: 0.271068, acc: 85.16%, op_acc: 60.16%] [G loss: 1.011169]\n",
      "1426 [D loss: 0.276157, acc: 81.25%, op_acc: 65.62%] [G loss: 1.006326]\n",
      "1427 [D loss: 0.261333, acc: 86.72%, op_acc: 60.94%] [G loss: 1.028940]\n",
      "1428 [D loss: 0.255220, acc: 85.16%, op_acc: 67.19%] [G loss: 1.018664]\n",
      "1429 [D loss: 0.267778, acc: 82.03%, op_acc: 67.97%] [G loss: 1.010146]\n",
      "1430 [D loss: 0.266298, acc: 83.59%, op_acc: 60.94%] [G loss: 1.046821]\n",
      "Epoch: 1430, F1: 0.61728, F1P: 143\n",
      "[[28425     7]\n",
      " [   24    25]]\n",
      "83.75\n",
      "1431 [D loss: 0.274989, acc: 80.47%, op_acc: 68.75%] [G loss: 1.066013]\n",
      "1432 [D loss: 0.264878, acc: 81.25%, op_acc: 66.41%] [G loss: 1.037185]\n",
      "1433 [D loss: 0.276583, acc: 78.91%, op_acc: 63.28%] [G loss: 1.011786]\n",
      "1434 [D loss: 0.275116, acc: 78.12%, op_acc: 61.72%] [G loss: 0.993121]\n",
      "1435 [D loss: 0.261877, acc: 85.16%, op_acc: 67.19%] [G loss: 1.053441]\n",
      "1436 [D loss: 0.261558, acc: 81.25%, op_acc: 66.41%] [G loss: 0.999801]\n",
      "1437 [D loss: 0.281515, acc: 85.16%, op_acc: 64.84%] [G loss: 1.064551]\n",
      "1438 [D loss: 0.253641, acc: 89.84%, op_acc: 71.09%] [G loss: 0.989508]\n",
      "1439 [D loss: 0.267959, acc: 82.81%, op_acc: 73.44%] [G loss: 1.028301]\n",
      "1440 [D loss: 0.266359, acc: 80.47%, op_acc: 59.38%] [G loss: 0.985309]\n",
      "Epoch: 1440, F1: 0.61728, F1P: 144\n",
      "[[28425     7]\n",
      " [   24    25]]\n",
      "82.34375\n",
      "1441 [D loss: 0.265188, acc: 87.50%, op_acc: 67.97%] [G loss: 1.010222]\n",
      "1442 [D loss: 0.276207, acc: 82.81%, op_acc: 63.28%] [G loss: 1.021263]\n",
      "1443 [D loss: 0.273218, acc: 83.59%, op_acc: 71.09%] [G loss: 1.043777]\n",
      "1444 [D loss: 0.262474, acc: 92.97%, op_acc: 64.84%] [G loss: 1.017694]\n",
      "1445 [D loss: 0.280674, acc: 82.81%, op_acc: 55.47%] [G loss: 0.996214]\n",
      "1446 [D loss: 0.266146, acc: 85.16%, op_acc: 65.62%] [G loss: 1.059046]\n",
      "1447 [D loss: 0.263592, acc: 86.72%, op_acc: 58.59%] [G loss: 1.013238]\n",
      "1448 [D loss: 0.266976, acc: 85.16%, op_acc: 67.97%] [G loss: 1.003911]\n",
      "1449 [D loss: 0.288115, acc: 78.91%, op_acc: 60.16%] [G loss: 1.032910]\n",
      "1450 [D loss: 0.279574, acc: 79.69%, op_acc: 62.50%] [G loss: 1.047706]\n",
      "Epoch: 1450, F1: 0.60759, F1P: 145\n",
      "[[28426     6]\n",
      " [   25    24]]\n",
      "84.53125\n",
      "1451 [D loss: 0.246731, acc: 90.62%, op_acc: 67.19%] [G loss: 1.065029]\n",
      "1452 [D loss: 0.250248, acc: 91.41%, op_acc: 67.97%] [G loss: 1.010218]\n",
      "1453 [D loss: 0.252522, acc: 85.94%, op_acc: 61.72%] [G loss: 1.003923]\n",
      "1454 [D loss: 0.247679, acc: 89.84%, op_acc: 65.62%] [G loss: 0.967689]\n",
      "1455 [D loss: 0.262448, acc: 81.25%, op_acc: 63.28%] [G loss: 1.029163]\n",
      "1456 [D loss: 0.276391, acc: 84.38%, op_acc: 67.19%] [G loss: 1.008625]\n",
      "1457 [D loss: 0.262398, acc: 79.69%, op_acc: 59.38%] [G loss: 1.070239]\n",
      "1458 [D loss: 0.283901, acc: 76.56%, op_acc: 60.94%] [G loss: 0.989291]\n",
      "1459 [D loss: 0.265178, acc: 84.38%, op_acc: 69.53%] [G loss: 1.054314]\n",
      "1460 [D loss: 0.255890, acc: 88.28%, op_acc: 65.62%] [G loss: 0.992048]\n",
      "Epoch: 1460, F1: 0.61728, F1P: 146\n",
      "[[28425     7]\n",
      " [   24    25]]\n",
      "85.234375\n",
      "1461 [D loss: 0.273944, acc: 82.81%, op_acc: 63.28%] [G loss: 1.056662]\n",
      "1462 [D loss: 0.268977, acc: 84.38%, op_acc: 58.59%] [G loss: 1.018412]\n",
      "1463 [D loss: 0.257717, acc: 88.28%, op_acc: 66.41%] [G loss: 1.029360]\n",
      "1464 [D loss: 0.258323, acc: 84.38%, op_acc: 57.81%] [G loss: 1.054600]\n",
      "1465 [D loss: 0.266716, acc: 80.47%, op_acc: 64.06%] [G loss: 1.041586]\n",
      "1466 [D loss: 0.252691, acc: 87.50%, op_acc: 67.97%] [G loss: 1.003160]\n",
      "1467 [D loss: 0.267738, acc: 85.94%, op_acc: 66.41%] [G loss: 1.028046]\n",
      "1468 [D loss: 0.276406, acc: 82.03%, op_acc: 57.81%] [G loss: 1.021086]\n",
      "1469 [D loss: 0.256870, acc: 85.94%, op_acc: 66.41%] [G loss: 1.028603]\n",
      "1470 [D loss: 0.266648, acc: 83.59%, op_acc: 65.62%] [G loss: 1.021521]\n",
      "Epoch: 1470, F1: 0.60000, F1P: 147\n",
      "[[28425     7]\n",
      " [   25    24]]\n",
      "84.53125\n",
      "1471 [D loss: 0.278426, acc: 78.91%, op_acc: 63.28%] [G loss: 1.074655]\n",
      "1472 [D loss: 0.252710, acc: 84.38%, op_acc: 58.59%] [G loss: 1.052241]\n",
      "1473 [D loss: 0.274995, acc: 77.34%, op_acc: 60.94%] [G loss: 1.069792]\n",
      "1474 [D loss: 0.264919, acc: 85.94%, op_acc: 61.72%] [G loss: 0.963565]\n",
      "1475 [D loss: 0.266054, acc: 87.50%, op_acc: 64.06%] [G loss: 1.048931]\n",
      "1476 [D loss: 0.263263, acc: 81.25%, op_acc: 69.53%] [G loss: 1.012151]\n",
      "1477 [D loss: 0.254046, acc: 88.28%, op_acc: 65.62%] [G loss: 1.047520]\n",
      "1478 [D loss: 0.258802, acc: 89.06%, op_acc: 70.31%] [G loss: 1.024229]\n",
      "1479 [D loss: 0.260673, acc: 85.94%, op_acc: 64.06%] [G loss: 1.051052]\n",
      "1480 [D loss: 0.259442, acc: 86.72%, op_acc: 68.75%] [G loss: 1.070389]\n",
      "Epoch: 1480, F1: 0.60759, F1P: 148\n",
      "[[28426     6]\n",
      " [   25    24]]\n",
      "84.53125\n",
      "1481 [D loss: 0.281540, acc: 76.56%, op_acc: 60.94%] [G loss: 1.038765]\n",
      "1482 [D loss: 0.253641, acc: 91.41%, op_acc: 60.94%] [G loss: 1.050578]\n",
      "1483 [D loss: 0.259142, acc: 85.16%, op_acc: 64.06%] [G loss: 1.028284]\n",
      "1484 [D loss: 0.269689, acc: 83.59%, op_acc: 58.59%] [G loss: 1.034954]\n",
      "1485 [D loss: 0.264062, acc: 84.38%, op_acc: 65.62%] [G loss: 1.057356]\n",
      "1486 [D loss: 0.246660, acc: 92.19%, op_acc: 66.41%] [G loss: 1.034590]\n",
      "1487 [D loss: 0.269624, acc: 81.25%, op_acc: 64.84%] [G loss: 1.050973]\n",
      "1488 [D loss: 0.266089, acc: 82.03%, op_acc: 64.06%] [G loss: 1.049229]\n",
      "1489 [D loss: 0.261345, acc: 84.38%, op_acc: 57.81%] [G loss: 1.048196]\n",
      "1490 [D loss: 0.263936, acc: 82.81%, op_acc: 64.84%] [G loss: 1.072504]\n",
      "Epoch: 1490, F1: 0.60000, F1P: 149\n",
      "[[28425     7]\n",
      " [   25    24]]\n",
      "84.375\n",
      "1491 [D loss: 0.271446, acc: 84.38%, op_acc: 71.09%] [G loss: 1.061612]\n",
      "1492 [D loss: 0.258570, acc: 81.25%, op_acc: 61.72%] [G loss: 1.014964]\n",
      "1493 [D loss: 0.271358, acc: 82.03%, op_acc: 61.72%] [G loss: 1.022228]\n",
      "1494 [D loss: 0.262194, acc: 85.16%, op_acc: 61.72%] [G loss: 1.046585]\n",
      "1495 [D loss: 0.247872, acc: 89.06%, op_acc: 65.62%] [G loss: 1.076295]\n",
      "1496 [D loss: 0.277018, acc: 80.47%, op_acc: 57.81%] [G loss: 1.071260]\n",
      "1497 [D loss: 0.279289, acc: 78.91%, op_acc: 60.16%] [G loss: 1.050911]\n",
      "1498 [D loss: 0.263539, acc: 82.81%, op_acc: 57.81%] [G loss: 1.041035]\n",
      "1499 [D loss: 0.261085, acc: 86.72%, op_acc: 70.31%] [G loss: 1.067760]\n",
      "1500 [D loss: 0.262239, acc: 84.38%, op_acc: 64.06%] [G loss: 1.045530]\n",
      "Epoch: 1500, F1: 0.60000, F1P: 150\n",
      "[[28425     7]\n",
      " [   25    24]]\n",
      "83.515625\n",
      "1501 [D loss: 0.268872, acc: 80.47%, op_acc: 64.84%] [G loss: 1.056123]\n",
      "1502 [D loss: 0.280427, acc: 75.00%, op_acc: 61.72%] [G loss: 1.087538]\n",
      "1503 [D loss: 0.246479, acc: 87.50%, op_acc: 71.88%] [G loss: 1.078692]\n",
      "1504 [D loss: 0.257833, acc: 85.94%, op_acc: 64.84%] [G loss: 1.083529]\n",
      "1505 [D loss: 0.267975, acc: 82.03%, op_acc: 57.03%] [G loss: 1.056675]\n",
      "1506 [D loss: 0.258310, acc: 84.38%, op_acc: 65.62%] [G loss: 1.051117]\n",
      "1507 [D loss: 0.270800, acc: 84.38%, op_acc: 59.38%] [G loss: 1.057914]\n",
      "1508 [D loss: 0.262091, acc: 81.25%, op_acc: 67.19%] [G loss: 1.129076]\n",
      "1509 [D loss: 0.270210, acc: 79.69%, op_acc: 66.41%] [G loss: 1.073132]\n",
      "1510 [D loss: 0.266529, acc: 81.25%, op_acc: 67.19%] [G loss: 1.068340]\n",
      "Epoch: 1510, F1: 0.61728, F1P: 151\n",
      "[[28425     7]\n",
      " [   24    25]]\n",
      "82.1875\n",
      "1511 [D loss: 0.272204, acc: 82.03%, op_acc: 67.97%] [G loss: 1.043573]\n",
      "1512 [D loss: 0.241657, acc: 92.97%, op_acc: 64.06%] [G loss: 1.095002]\n",
      "1513 [D loss: 0.256715, acc: 84.38%, op_acc: 61.72%] [G loss: 1.048146]\n",
      "1514 [D loss: 0.249818, acc: 89.84%, op_acc: 62.50%] [G loss: 1.060455]\n",
      "1515 [D loss: 0.260393, acc: 88.28%, op_acc: 68.75%] [G loss: 1.038371]\n",
      "1516 [D loss: 0.276625, acc: 82.81%, op_acc: 62.50%] [G loss: 1.042816]\n",
      "1517 [D loss: 0.266837, acc: 86.72%, op_acc: 67.19%] [G loss: 1.097460]\n",
      "1518 [D loss: 0.249053, acc: 88.28%, op_acc: 59.38%] [G loss: 1.124902]\n",
      "1519 [D loss: 0.258701, acc: 88.28%, op_acc: 57.81%] [G loss: 1.063141]\n",
      "1520 [D loss: 0.240804, acc: 89.06%, op_acc: 66.41%] [G loss: 1.095264]\n",
      "Epoch: 1520, F1: 0.61728, F1P: 152\n",
      "[[28425     7]\n",
      " [   24    25]]\n",
      "87.265625\n",
      "1521 [D loss: 0.268311, acc: 83.59%, op_acc: 61.72%] [G loss: 1.054659]\n",
      "1522 [D loss: 0.253876, acc: 86.72%, op_acc: 66.41%] [G loss: 1.025837]\n",
      "1523 [D loss: 0.270539, acc: 83.59%, op_acc: 61.72%] [G loss: 1.060916]\n",
      "1524 [D loss: 0.257119, acc: 84.38%, op_acc: 63.28%] [G loss: 1.097833]\n",
      "1525 [D loss: 0.265696, acc: 82.03%, op_acc: 58.59%] [G loss: 1.128832]\n",
      "1526 [D loss: 0.251685, acc: 85.94%, op_acc: 64.84%] [G loss: 1.098877]\n",
      "1527 [D loss: 0.254522, acc: 82.81%, op_acc: 62.50%] [G loss: 1.078103]\n",
      "1528 [D loss: 0.259506, acc: 85.94%, op_acc: 66.41%] [G loss: 1.164131]\n",
      "1529 [D loss: 0.253873, acc: 90.62%, op_acc: 68.75%] [G loss: 1.121026]\n",
      "1530 [D loss: 0.243248, acc: 89.84%, op_acc: 64.84%] [G loss: 1.047851]\n",
      "Epoch: 1530, F1: 0.61728, F1P: 153\n",
      "[[28425     7]\n",
      " [   24    25]]\n",
      "85.546875\n",
      "1531 [D loss: 0.246191, acc: 88.28%, op_acc: 57.81%] [G loss: 1.097773]\n",
      "1532 [D loss: 0.248758, acc: 89.06%, op_acc: 66.41%] [G loss: 1.110134]\n",
      "1533 [D loss: 0.255338, acc: 88.28%, op_acc: 62.50%] [G loss: 1.124033]\n",
      "1534 [D loss: 0.232383, acc: 92.19%, op_acc: 70.31%] [G loss: 1.126037]\n",
      "1535 [D loss: 0.259882, acc: 85.16%, op_acc: 69.53%] [G loss: 1.055161]\n",
      "1536 [D loss: 0.243879, acc: 92.19%, op_acc: 66.41%] [G loss: 1.113013]\n",
      "1537 [D loss: 0.244189, acc: 90.62%, op_acc: 69.53%] [G loss: 1.074291]\n",
      "1538 [D loss: 0.246004, acc: 89.06%, op_acc: 60.94%] [G loss: 1.101570]\n",
      "1539 [D loss: 0.249075, acc: 87.50%, op_acc: 66.41%] [G loss: 1.115921]\n",
      "1540 [D loss: 0.255020, acc: 86.72%, op_acc: 61.72%] [G loss: 1.090042]\n",
      "Epoch: 1540, F1: 0.61728, F1P: 154\n",
      "[[28425     7]\n",
      " [   24    25]]\n",
      "88.90625\n",
      "1541 [D loss: 0.253183, acc: 86.72%, op_acc: 68.75%] [G loss: 1.088522]\n",
      "1542 [D loss: 0.249933, acc: 89.84%, op_acc: 69.53%] [G loss: 1.154568]\n",
      "1543 [D loss: 0.241232, acc: 86.72%, op_acc: 63.28%] [G loss: 1.190749]\n",
      "1544 [D loss: 0.260549, acc: 87.50%, op_acc: 61.72%] [G loss: 1.074060]\n",
      "1545 [D loss: 0.252737, acc: 86.72%, op_acc: 67.97%] [G loss: 1.136132]\n",
      "1546 [D loss: 0.257985, acc: 87.50%, op_acc: 62.50%] [G loss: 1.097455]\n",
      "1547 [D loss: 0.254844, acc: 85.94%, op_acc: 68.75%] [G loss: 1.080916]\n",
      "1548 [D loss: 0.246198, acc: 89.84%, op_acc: 68.75%] [G loss: 1.126344]\n",
      "1549 [D loss: 0.240909, acc: 91.41%, op_acc: 68.75%] [G loss: 1.136914]\n",
      "1550 [D loss: 0.253933, acc: 89.84%, op_acc: 72.66%] [G loss: 1.071618]\n",
      "Epoch: 1550, F1: 0.61728, F1P: 155\n",
      "[[28425     7]\n",
      " [   24    25]]\n",
      "88.203125\n",
      "1551 [D loss: 0.246860, acc: 87.50%, op_acc: 63.28%] [G loss: 1.085976]\n",
      "1552 [D loss: 0.249804, acc: 88.28%, op_acc: 67.19%] [G loss: 1.047766]\n",
      "1553 [D loss: 0.253016, acc: 86.72%, op_acc: 65.62%] [G loss: 1.093038]\n",
      "1554 [D loss: 0.262848, acc: 85.16%, op_acc: 62.50%] [G loss: 1.062276]\n",
      "1555 [D loss: 0.271725, acc: 86.72%, op_acc: 67.97%] [G loss: 1.103784]\n",
      "1556 [D loss: 0.247610, acc: 84.38%, op_acc: 62.50%] [G loss: 1.162301]\n",
      "1557 [D loss: 0.261759, acc: 86.72%, op_acc: 67.97%] [G loss: 1.131208]\n",
      "1558 [D loss: 0.251015, acc: 85.94%, op_acc: 72.66%] [G loss: 1.127211]\n",
      "1559 [D loss: 0.250210, acc: 86.72%, op_acc: 62.50%] [G loss: 1.136129]\n",
      "1560 [D loss: 0.240637, acc: 89.84%, op_acc: 60.16%] [G loss: 1.091491]\n",
      "Epoch: 1560, F1: 0.61728, F1P: 156\n",
      "[[28425     7]\n",
      " [   24    25]]\n",
      "86.796875\n",
      "1561 [D loss: 0.242480, acc: 89.84%, op_acc: 64.06%] [G loss: 1.063723]\n",
      "1562 [D loss: 0.239671, acc: 90.62%, op_acc: 64.84%] [G loss: 1.113445]\n",
      "1563 [D loss: 0.251368, acc: 85.16%, op_acc: 64.84%] [G loss: 1.113189]\n",
      "1564 [D loss: 0.248203, acc: 85.94%, op_acc: 67.97%] [G loss: 1.078119]\n",
      "1565 [D loss: 0.241200, acc: 91.41%, op_acc: 72.66%] [G loss: 1.171387]\n",
      "1566 [D loss: 0.255737, acc: 88.28%, op_acc: 71.09%] [G loss: 1.153107]\n",
      "1567 [D loss: 0.250373, acc: 85.94%, op_acc: 75.78%] [G loss: 1.134838]\n",
      "1568 [D loss: 0.264625, acc: 82.81%, op_acc: 63.28%] [G loss: 1.132682]\n",
      "1569 [D loss: 0.247012, acc: 89.84%, op_acc: 66.41%] [G loss: 1.137581]\n",
      "1570 [D loss: 0.239601, acc: 89.06%, op_acc: 68.75%] [G loss: 1.069718]\n",
      "Epoch: 1570, F1: 0.61728, F1P: 157\n",
      "[[28425     7]\n",
      " [   24    25]]\n",
      "87.890625\n",
      "1571 [D loss: 0.248430, acc: 84.38%, op_acc: 75.00%] [G loss: 1.084380]\n",
      "1572 [D loss: 0.236513, acc: 92.19%, op_acc: 67.97%] [G loss: 1.086429]\n",
      "1573 [D loss: 0.257805, acc: 81.25%, op_acc: 59.38%] [G loss: 1.161687]\n",
      "1574 [D loss: 0.244616, acc: 92.97%, op_acc: 69.53%] [G loss: 1.143684]\n",
      "1575 [D loss: 0.257819, acc: 88.28%, op_acc: 71.88%] [G loss: 1.119861]\n",
      "1576 [D loss: 0.242692, acc: 88.28%, op_acc: 71.88%] [G loss: 1.106504]\n",
      "1577 [D loss: 0.244043, acc: 88.28%, op_acc: 69.53%] [G loss: 1.140237]\n",
      "1578 [D loss: 0.256848, acc: 86.72%, op_acc: 65.62%] [G loss: 1.126053]\n",
      "1579 [D loss: 0.256174, acc: 83.59%, op_acc: 67.19%] [G loss: 1.178934]\n",
      "1580 [D loss: 0.245867, acc: 88.28%, op_acc: 66.41%] [G loss: 1.091758]\n",
      "Epoch: 1580, F1: 0.60000, F1P: 158\n",
      "[[28425     7]\n",
      " [   25    24]]\n",
      "87.421875\n",
      "1581 [D loss: 0.253074, acc: 83.59%, op_acc: 67.19%] [G loss: 1.145321]\n",
      "1582 [D loss: 0.249442, acc: 85.94%, op_acc: 69.53%] [G loss: 1.146847]\n",
      "1583 [D loss: 0.252206, acc: 83.59%, op_acc: 64.06%] [G loss: 1.070137]\n",
      "1584 [D loss: 0.253495, acc: 87.50%, op_acc: 73.44%] [G loss: 1.111794]\n",
      "1585 [D loss: 0.255413, acc: 82.03%, op_acc: 67.19%] [G loss: 1.142350]\n",
      "1586 [D loss: 0.223904, acc: 95.31%, op_acc: 66.41%] [G loss: 1.133245]\n",
      "1587 [D loss: 0.252075, acc: 87.50%, op_acc: 66.41%] [G loss: 1.159406]\n",
      "1588 [D loss: 0.234233, acc: 93.75%, op_acc: 73.44%] [G loss: 1.089194]\n",
      "1589 [D loss: 0.255435, acc: 85.16%, op_acc: 63.28%] [G loss: 1.098458]\n",
      "1590 [D loss: 0.248978, acc: 89.06%, op_acc: 67.19%] [G loss: 1.085055]\n",
      "Epoch: 1590, F1: 0.60000, F1P: 159\n",
      "[[28425     7]\n",
      " [   25    24]]\n",
      "87.34375\n",
      "1591 [D loss: 0.249194, acc: 85.94%, op_acc: 71.88%] [G loss: 1.168977]\n",
      "1592 [D loss: 0.241021, acc: 89.06%, op_acc: 67.97%] [G loss: 1.121662]\n",
      "1593 [D loss: 0.250645, acc: 89.84%, op_acc: 66.41%] [G loss: 1.131041]\n",
      "1594 [D loss: 0.250286, acc: 91.41%, op_acc: 67.97%] [G loss: 1.120570]\n",
      "1595 [D loss: 0.242646, acc: 89.06%, op_acc: 66.41%] [G loss: 1.049911]\n",
      "1596 [D loss: 0.237402, acc: 94.53%, op_acc: 77.34%] [G loss: 1.171573]\n",
      "1597 [D loss: 0.247052, acc: 88.28%, op_acc: 64.06%] [G loss: 1.152631]\n",
      "1598 [D loss: 0.232414, acc: 90.62%, op_acc: 70.31%] [G loss: 1.162259]\n",
      "1599 [D loss: 0.245447, acc: 88.28%, op_acc: 75.78%] [G loss: 1.163541]\n",
      "1600 [D loss: 0.248479, acc: 85.16%, op_acc: 71.09%] [G loss: 1.160657]\n",
      "Epoch: 1600, F1: 0.61728, F1P: 160\n",
      "[[28425     7]\n",
      " [   24    25]]\n",
      "89.21875\n",
      "1601 [D loss: 0.248378, acc: 86.72%, op_acc: 71.88%] [G loss: 1.144320]\n",
      "1602 [D loss: 0.238956, acc: 85.94%, op_acc: 64.84%] [G loss: 1.200071]\n",
      "1603 [D loss: 0.244032, acc: 85.94%, op_acc: 65.62%] [G loss: 1.172033]\n",
      "1604 [D loss: 0.243601, acc: 88.28%, op_acc: 73.44%] [G loss: 1.131991]\n",
      "1605 [D loss: 0.241140, acc: 88.28%, op_acc: 66.41%] [G loss: 1.117230]\n",
      "1606 [D loss: 0.238474, acc: 88.28%, op_acc: 71.88%] [G loss: 1.177793]\n",
      "1607 [D loss: 0.242068, acc: 90.62%, op_acc: 67.19%] [G loss: 1.172790]\n",
      "1608 [D loss: 0.237121, acc: 92.19%, op_acc: 67.19%] [G loss: 1.195668]\n",
      "1609 [D loss: 0.254913, acc: 87.50%, op_acc: 69.53%] [G loss: 1.177703]\n",
      "1610 [D loss: 0.244478, acc: 89.84%, op_acc: 74.22%] [G loss: 1.056946]\n",
      "Epoch: 1610, F1: 0.61728, F1P: 161\n",
      "[[28425     7]\n",
      " [   24    25]]\n",
      "88.359375\n",
      "1611 [D loss: 0.243786, acc: 87.50%, op_acc: 63.28%] [G loss: 1.211175]\n",
      "1612 [D loss: 0.234265, acc: 90.62%, op_acc: 70.31%] [G loss: 1.175120]\n",
      "1613 [D loss: 0.253286, acc: 84.38%, op_acc: 66.41%] [G loss: 1.104427]\n",
      "1614 [D loss: 0.246568, acc: 89.06%, op_acc: 69.53%] [G loss: 1.165640]\n",
      "1615 [D loss: 0.244280, acc: 90.62%, op_acc: 72.66%] [G loss: 1.128026]\n",
      "1616 [D loss: 0.231364, acc: 91.41%, op_acc: 69.53%] [G loss: 1.134041]\n",
      "1617 [D loss: 0.245937, acc: 82.03%, op_acc: 65.62%] [G loss: 1.087363]\n",
      "1618 [D loss: 0.239497, acc: 86.72%, op_acc: 63.28%] [G loss: 1.127244]\n",
      "1619 [D loss: 0.234320, acc: 90.62%, op_acc: 67.19%] [G loss: 1.172328]\n",
      "1620 [D loss: 0.244909, acc: 88.28%, op_acc: 62.50%] [G loss: 1.178939]\n",
      "Epoch: 1620, F1: 0.60000, F1P: 162\n",
      "[[28425     7]\n",
      " [   25    24]]\n",
      "88.125\n",
      "1621 [D loss: 0.250291, acc: 83.59%, op_acc: 67.97%] [G loss: 1.087791]\n",
      "1622 [D loss: 0.255491, acc: 87.50%, op_acc: 63.28%] [G loss: 1.148570]\n",
      "1623 [D loss: 0.249212, acc: 85.94%, op_acc: 61.72%] [G loss: 1.187216]\n",
      "1624 [D loss: 0.228259, acc: 93.75%, op_acc: 74.22%] [G loss: 1.130150]\n",
      "1625 [D loss: 0.240230, acc: 89.84%, op_acc: 69.53%] [G loss: 1.178532]\n",
      "1626 [D loss: 0.236429, acc: 89.84%, op_acc: 70.31%] [G loss: 1.159301]\n",
      "1627 [D loss: 0.243976, acc: 89.84%, op_acc: 68.75%] [G loss: 1.159145]\n",
      "1628 [D loss: 0.234296, acc: 89.06%, op_acc: 72.66%] [G loss: 1.142632]\n",
      "1629 [D loss: 0.249957, acc: 87.50%, op_acc: 71.09%] [G loss: 1.112478]\n",
      "1630 [D loss: 0.238104, acc: 89.06%, op_acc: 73.44%] [G loss: 1.199512]\n",
      "Epoch: 1630, F1: 0.63415, F1P: 163\n",
      "[[28425     7]\n",
      " [   23    26]]\n",
      "88.59375\n",
      "1631 [D loss: 0.247032, acc: 86.72%, op_acc: 62.50%] [G loss: 1.170293]\n",
      "1632 [D loss: 0.257670, acc: 85.94%, op_acc: 62.50%] [G loss: 1.217788]\n",
      "1633 [D loss: 0.223639, acc: 92.19%, op_acc: 74.22%] [G loss: 1.168856]\n",
      "1634 [D loss: 0.247129, acc: 85.94%, op_acc: 62.50%] [G loss: 1.112524]\n",
      "1635 [D loss: 0.225673, acc: 91.41%, op_acc: 74.22%] [G loss: 1.126823]\n",
      "1636 [D loss: 0.241443, acc: 88.28%, op_acc: 69.53%] [G loss: 1.143836]\n",
      "1637 [D loss: 0.237449, acc: 89.84%, op_acc: 67.19%] [G loss: 1.169323]\n",
      "1638 [D loss: 0.243720, acc: 85.16%, op_acc: 67.19%] [G loss: 1.200842]\n",
      "1639 [D loss: 0.251267, acc: 87.50%, op_acc: 73.44%] [G loss: 1.250822]\n",
      "1640 [D loss: 0.236549, acc: 89.84%, op_acc: 64.84%] [G loss: 1.247920]\n",
      "Epoch: 1640, F1: 0.63529, F1P: 164\n",
      "[[28423     9]\n",
      " [   22    27]]\n",
      "88.28125\n",
      "1641 [D loss: 0.246183, acc: 83.59%, op_acc: 68.75%] [G loss: 1.137344]\n",
      "1642 [D loss: 0.241937, acc: 89.06%, op_acc: 77.34%] [G loss: 1.190808]\n",
      "1643 [D loss: 0.227969, acc: 90.62%, op_acc: 72.66%] [G loss: 1.117968]\n",
      "1644 [D loss: 0.248658, acc: 85.94%, op_acc: 75.00%] [G loss: 1.191648]\n",
      "1645 [D loss: 0.237529, acc: 89.84%, op_acc: 76.56%] [G loss: 1.193708]\n",
      "1646 [D loss: 0.217376, acc: 94.53%, op_acc: 69.53%] [G loss: 1.205199]\n",
      "1647 [D loss: 0.231412, acc: 89.06%, op_acc: 71.88%] [G loss: 1.185970]\n",
      "1648 [D loss: 0.232303, acc: 89.06%, op_acc: 77.34%] [G loss: 1.201854]\n",
      "1649 [D loss: 0.236275, acc: 89.84%, op_acc: 77.34%] [G loss: 1.188393]\n",
      "1650 [D loss: 0.235984, acc: 87.50%, op_acc: 73.44%] [G loss: 1.173514]\n",
      "Epoch: 1650, F1: 0.63529, F1P: 165\n",
      "[[28423     9]\n",
      " [   22    27]]\n",
      "88.90625\n",
      "1651 [D loss: 0.224017, acc: 93.75%, op_acc: 77.34%] [G loss: 1.188392]\n",
      "1652 [D loss: 0.226158, acc: 95.31%, op_acc: 80.47%] [G loss: 1.141511]\n",
      "1653 [D loss: 0.242757, acc: 87.50%, op_acc: 79.69%] [G loss: 1.194447]\n",
      "1654 [D loss: 0.235598, acc: 85.16%, op_acc: 68.75%] [G loss: 1.172076]\n",
      "1655 [D loss: 0.232194, acc: 87.50%, op_acc: 74.22%] [G loss: 1.202822]\n",
      "1656 [D loss: 0.231829, acc: 88.28%, op_acc: 70.31%] [G loss: 1.196086]\n",
      "1657 [D loss: 0.232487, acc: 91.41%, op_acc: 67.19%] [G loss: 1.210329]\n",
      "1658 [D loss: 0.237827, acc: 88.28%, op_acc: 78.12%] [G loss: 1.209889]\n",
      "1659 [D loss: 0.229895, acc: 89.06%, op_acc: 73.44%] [G loss: 1.098348]\n",
      "1660 [D loss: 0.244612, acc: 83.59%, op_acc: 71.88%] [G loss: 1.157175]\n",
      "Epoch: 1660, F1: 0.64286, F1P: 166\n",
      "[[28424     8]\n",
      " [   22    27]]\n",
      "88.984375\n",
      "1661 [D loss: 0.226857, acc: 92.19%, op_acc: 75.00%] [G loss: 1.210381]\n",
      "1662 [D loss: 0.237899, acc: 92.97%, op_acc: 71.09%] [G loss: 1.223010]\n",
      "1663 [D loss: 0.234389, acc: 90.62%, op_acc: 77.34%] [G loss: 1.146175]\n",
      "1664 [D loss: 0.222726, acc: 91.41%, op_acc: 76.56%] [G loss: 1.157629]\n",
      "1665 [D loss: 0.233170, acc: 89.06%, op_acc: 69.53%] [G loss: 1.185353]\n",
      "1666 [D loss: 0.238493, acc: 92.19%, op_acc: 74.22%] [G loss: 1.153644]\n",
      "1667 [D loss: 0.244707, acc: 89.06%, op_acc: 75.00%] [G loss: 1.216994]\n",
      "1668 [D loss: 0.228502, acc: 89.06%, op_acc: 72.66%] [G loss: 1.184011]\n",
      "1669 [D loss: 0.233421, acc: 88.28%, op_acc: 75.00%] [G loss: 1.161890]\n",
      "1670 [D loss: 0.229944, acc: 89.84%, op_acc: 72.66%] [G loss: 1.232262]\n",
      "Epoch: 1670, F1: 0.63529, F1P: 167\n",
      "[[28423     9]\n",
      " [   22    27]]\n",
      "90.46875\n",
      "1671 [D loss: 0.221200, acc: 90.62%, op_acc: 71.88%] [G loss: 1.172543]\n",
      "1672 [D loss: 0.236411, acc: 87.50%, op_acc: 72.66%] [G loss: 1.140302]\n",
      "1673 [D loss: 0.233220, acc: 92.97%, op_acc: 70.31%] [G loss: 1.218509]\n",
      "1674 [D loss: 0.244632, acc: 89.06%, op_acc: 71.09%] [G loss: 1.126774]\n",
      "1675 [D loss: 0.235216, acc: 92.19%, op_acc: 78.12%] [G loss: 1.224220]\n",
      "1676 [D loss: 0.236832, acc: 89.84%, op_acc: 71.88%] [G loss: 1.184999]\n",
      "1677 [D loss: 0.226562, acc: 94.53%, op_acc: 81.25%] [G loss: 1.230739]\n",
      "1678 [D loss: 0.226233, acc: 89.06%, op_acc: 63.28%] [G loss: 1.266964]\n",
      "1679 [D loss: 0.215052, acc: 92.19%, op_acc: 71.09%] [G loss: 1.245434]\n",
      "1680 [D loss: 0.248746, acc: 89.06%, op_acc: 71.09%] [G loss: 1.195156]\n",
      "Epoch: 1680, F1: 0.63529, F1P: 168\n",
      "[[28423     9]\n",
      " [   22    27]]\n",
      "90.703125\n",
      "1681 [D loss: 0.231246, acc: 89.84%, op_acc: 71.09%] [G loss: 1.241694]\n",
      "1682 [D loss: 0.235194, acc: 89.06%, op_acc: 73.44%] [G loss: 1.153325]\n",
      "1683 [D loss: 0.235067, acc: 92.97%, op_acc: 73.44%] [G loss: 1.246479]\n",
      "1684 [D loss: 0.214101, acc: 92.19%, op_acc: 70.31%] [G loss: 1.118129]\n",
      "1685 [D loss: 0.240462, acc: 85.16%, op_acc: 66.41%] [G loss: 1.192904]\n",
      "1686 [D loss: 0.228624, acc: 88.28%, op_acc: 70.31%] [G loss: 1.226127]\n",
      "1687 [D loss: 0.235540, acc: 91.41%, op_acc: 75.00%] [G loss: 1.298006]\n",
      "1688 [D loss: 0.219259, acc: 92.97%, op_acc: 76.56%] [G loss: 1.196971]\n",
      "1689 [D loss: 0.232493, acc: 90.62%, op_acc: 73.44%] [G loss: 1.202172]\n",
      "1690 [D loss: 0.236232, acc: 88.28%, op_acc: 71.09%] [G loss: 1.221747]\n",
      "Epoch: 1690, F1: 0.63529, F1P: 169\n",
      "[[28423     9]\n",
      " [   22    27]]\n",
      "90.078125\n",
      "1691 [D loss: 0.226829, acc: 90.62%, op_acc: 66.41%] [G loss: 1.234279]\n",
      "1692 [D loss: 0.223030, acc: 86.72%, op_acc: 71.88%] [G loss: 1.175448]\n",
      "1693 [D loss: 0.221474, acc: 92.19%, op_acc: 75.78%] [G loss: 1.202750]\n",
      "1694 [D loss: 0.239890, acc: 89.06%, op_acc: 73.44%] [G loss: 1.247740]\n",
      "1695 [D loss: 0.214175, acc: 91.41%, op_acc: 68.75%] [G loss: 1.215048]\n",
      "1696 [D loss: 0.223397, acc: 88.28%, op_acc: 67.19%] [G loss: 1.255036]\n",
      "1697 [D loss: 0.218708, acc: 89.06%, op_acc: 76.56%] [G loss: 1.254017]\n",
      "1698 [D loss: 0.220365, acc: 91.41%, op_acc: 77.34%] [G loss: 1.183823]\n",
      "1699 [D loss: 0.228560, acc: 90.62%, op_acc: 75.78%] [G loss: 1.211828]\n",
      "1700 [D loss: 0.243766, acc: 85.16%, op_acc: 75.00%] [G loss: 1.206329]\n",
      "Epoch: 1700, F1: 0.63529, F1P: 170\n",
      "[[28423     9]\n",
      " [   22    27]]\n",
      "89.453125\n",
      "1701 [D loss: 0.237229, acc: 89.06%, op_acc: 71.09%] [G loss: 1.244045]\n",
      "1702 [D loss: 0.215197, acc: 90.62%, op_acc: 78.12%] [G loss: 1.239233]\n",
      "1703 [D loss: 0.217065, acc: 91.41%, op_acc: 71.88%] [G loss: 1.194148]\n",
      "1704 [D loss: 0.243112, acc: 88.28%, op_acc: 74.22%] [G loss: 1.272223]\n",
      "1705 [D loss: 0.234981, acc: 88.28%, op_acc: 76.56%] [G loss: 1.253126]\n",
      "1706 [D loss: 0.214621, acc: 93.75%, op_acc: 78.12%] [G loss: 1.182840]\n",
      "1707 [D loss: 0.207703, acc: 96.88%, op_acc: 76.56%] [G loss: 1.261878]\n",
      "1708 [D loss: 0.218993, acc: 94.53%, op_acc: 78.12%] [G loss: 1.242253]\n",
      "1709 [D loss: 0.221002, acc: 92.97%, op_acc: 70.31%] [G loss: 1.294875]\n",
      "1710 [D loss: 0.224952, acc: 92.97%, op_acc: 75.00%] [G loss: 1.269891]\n",
      "Epoch: 1710, F1: 0.63529, F1P: 171\n",
      "[[28423     9]\n",
      " [   22    27]]\n",
      "91.875\n",
      "1711 [D loss: 0.210561, acc: 92.97%, op_acc: 73.44%] [G loss: 1.273411]\n",
      "1712 [D loss: 0.227864, acc: 91.41%, op_acc: 77.34%] [G loss: 1.304603]\n",
      "1713 [D loss: 0.212178, acc: 92.97%, op_acc: 74.22%] [G loss: 1.225013]\n",
      "1714 [D loss: 0.226171, acc: 92.19%, op_acc: 74.22%] [G loss: 1.205814]\n",
      "1715 [D loss: 0.220086, acc: 92.19%, op_acc: 76.56%] [G loss: 1.230170]\n",
      "1716 [D loss: 0.211737, acc: 92.97%, op_acc: 75.00%] [G loss: 1.322908]\n",
      "1717 [D loss: 0.217475, acc: 91.41%, op_acc: 75.78%] [G loss: 1.291138]\n",
      "1718 [D loss: 0.231757, acc: 91.41%, op_acc: 72.66%] [G loss: 1.258029]\n",
      "1719 [D loss: 0.217059, acc: 92.19%, op_acc: 75.00%] [G loss: 1.226080]\n",
      "1720 [D loss: 0.212678, acc: 89.84%, op_acc: 73.44%] [G loss: 1.295422]\n",
      "Epoch: 1720, F1: 0.63529, F1P: 172\n",
      "[[28423     9]\n",
      " [   22    27]]\n",
      "91.953125\n",
      "1721 [D loss: 0.230803, acc: 89.06%, op_acc: 69.53%] [G loss: 1.212195]\n",
      "1722 [D loss: 0.230636, acc: 93.75%, op_acc: 73.44%] [G loss: 1.298322]\n",
      "1723 [D loss: 0.218328, acc: 92.19%, op_acc: 75.78%] [G loss: 1.233512]\n",
      "1724 [D loss: 0.213714, acc: 93.75%, op_acc: 72.66%] [G loss: 1.246515]\n",
      "1725 [D loss: 0.225942, acc: 93.75%, op_acc: 81.25%] [G loss: 1.287919]\n",
      "1726 [D loss: 0.228230, acc: 89.84%, op_acc: 75.78%] [G loss: 1.257000]\n",
      "1727 [D loss: 0.233598, acc: 89.06%, op_acc: 71.09%] [G loss: 1.274710]\n",
      "1728 [D loss: 0.224880, acc: 89.84%, op_acc: 71.09%] [G loss: 1.205348]\n",
      "1729 [D loss: 0.221091, acc: 91.41%, op_acc: 75.00%] [G loss: 1.207307]\n",
      "1730 [D loss: 0.229149, acc: 89.84%, op_acc: 71.88%] [G loss: 1.292755]\n",
      "Epoch: 1730, F1: 0.63529, F1P: 173\n",
      "[[28423     9]\n",
      " [   22    27]]\n",
      "91.25\n",
      "1731 [D loss: 0.219698, acc: 87.50%, op_acc: 70.31%] [G loss: 1.269018]\n",
      "1732 [D loss: 0.219028, acc: 89.06%, op_acc: 70.31%] [G loss: 1.247419]\n",
      "1733 [D loss: 0.229771, acc: 90.62%, op_acc: 75.78%] [G loss: 1.229915]\n",
      "1734 [D loss: 0.227629, acc: 89.84%, op_acc: 75.00%] [G loss: 1.337520]\n",
      "1735 [D loss: 0.209991, acc: 92.97%, op_acc: 71.88%] [G loss: 1.267176]\n",
      "1736 [D loss: 0.223963, acc: 89.84%, op_acc: 71.88%] [G loss: 1.204799]\n",
      "1737 [D loss: 0.230550, acc: 89.84%, op_acc: 71.88%] [G loss: 1.348737]\n",
      "1738 [D loss: 0.222712, acc: 90.62%, op_acc: 74.22%] [G loss: 1.283327]\n",
      "1739 [D loss: 0.216482, acc: 88.28%, op_acc: 69.53%] [G loss: 1.241137]\n",
      "1740 [D loss: 0.211227, acc: 93.75%, op_acc: 73.44%] [G loss: 1.204965]\n",
      "Epoch: 1740, F1: 0.65116, F1P: 174\n",
      "[[28423     9]\n",
      " [   21    28]]\n",
      "90.234375\n",
      "1741 [D loss: 0.214142, acc: 93.75%, op_acc: 83.59%] [G loss: 1.219252]\n",
      "1742 [D loss: 0.218212, acc: 90.62%, op_acc: 75.00%] [G loss: 1.288838]\n",
      "1743 [D loss: 0.210830, acc: 94.53%, op_acc: 79.69%] [G loss: 1.288374]\n",
      "1744 [D loss: 0.242153, acc: 84.38%, op_acc: 69.53%] [G loss: 1.273161]\n",
      "1745 [D loss: 0.206132, acc: 92.97%, op_acc: 73.44%] [G loss: 1.294750]\n",
      "1746 [D loss: 0.226930, acc: 89.84%, op_acc: 75.78%] [G loss: 1.258818]\n",
      "1747 [D loss: 0.206846, acc: 92.19%, op_acc: 76.56%] [G loss: 1.242420]\n",
      "1748 [D loss: 0.226460, acc: 89.84%, op_acc: 80.47%] [G loss: 1.290406]\n",
      "1749 [D loss: 0.219659, acc: 89.06%, op_acc: 80.47%] [G loss: 1.261625]\n",
      "1750 [D loss: 0.227802, acc: 93.75%, op_acc: 77.34%] [G loss: 1.352422]\n",
      "Epoch: 1750, F1: 0.65116, F1P: 175\n",
      "[[28423     9]\n",
      " [   21    28]]\n",
      "91.09375\n",
      "1751 [D loss: 0.215939, acc: 89.84%, op_acc: 78.91%] [G loss: 1.338952]\n",
      "1752 [D loss: 0.224796, acc: 87.50%, op_acc: 78.12%] [G loss: 1.308180]\n",
      "1753 [D loss: 0.217063, acc: 93.75%, op_acc: 78.91%] [G loss: 1.262398]\n",
      "1754 [D loss: 0.227877, acc: 93.75%, op_acc: 73.44%] [G loss: 1.335494]\n",
      "1755 [D loss: 0.206601, acc: 94.53%, op_acc: 82.81%] [G loss: 1.205738]\n",
      "1756 [D loss: 0.217363, acc: 91.41%, op_acc: 78.91%] [G loss: 1.316604]\n",
      "1757 [D loss: 0.212840, acc: 93.75%, op_acc: 74.22%] [G loss: 1.312686]\n",
      "1758 [D loss: 0.214883, acc: 92.19%, op_acc: 78.12%] [G loss: 1.286506]\n",
      "1759 [D loss: 0.233739, acc: 90.62%, op_acc: 76.56%] [G loss: 1.277663]\n",
      "1760 [D loss: 0.217749, acc: 91.41%, op_acc: 81.25%] [G loss: 1.285353]\n",
      "Epoch: 1760, F1: 0.65116, F1P: 176\n",
      "[[28423     9]\n",
      " [   21    28]]\n",
      "91.875\n",
      "1761 [D loss: 0.226002, acc: 89.84%, op_acc: 74.22%] [G loss: 1.284921]\n",
      "1762 [D loss: 0.215360, acc: 90.62%, op_acc: 74.22%] [G loss: 1.346732]\n",
      "1763 [D loss: 0.215674, acc: 91.41%, op_acc: 75.00%] [G loss: 1.294577]\n",
      "1764 [D loss: 0.238177, acc: 86.72%, op_acc: 72.66%] [G loss: 1.319661]\n",
      "1765 [D loss: 0.211695, acc: 96.09%, op_acc: 78.91%] [G loss: 1.295948]\n",
      "1766 [D loss: 0.217216, acc: 94.53%, op_acc: 82.03%] [G loss: 1.271178]\n",
      "1767 [D loss: 0.209657, acc: 89.84%, op_acc: 77.34%] [G loss: 1.307144]\n",
      "1768 [D loss: 0.229080, acc: 89.06%, op_acc: 68.75%] [G loss: 1.274561]\n",
      "1769 [D loss: 0.219706, acc: 88.28%, op_acc: 74.22%] [G loss: 1.275908]\n",
      "1770 [D loss: 0.211723, acc: 92.97%, op_acc: 75.00%] [G loss: 1.344338]\n",
      "Epoch: 1770, F1: 0.62791, F1P: 177\n",
      "[[28422    10]\n",
      " [   22    27]]\n",
      "90.9375\n",
      "1771 [D loss: 0.221618, acc: 94.53%, op_acc: 79.69%] [G loss: 1.287658]\n",
      "1772 [D loss: 0.224820, acc: 91.41%, op_acc: 78.12%] [G loss: 1.338207]\n",
      "1773 [D loss: 0.250805, acc: 83.59%, op_acc: 67.97%] [G loss: 1.336848]\n",
      "1774 [D loss: 0.218035, acc: 91.41%, op_acc: 81.25%] [G loss: 1.280647]\n",
      "1775 [D loss: 0.204074, acc: 93.75%, op_acc: 75.78%] [G loss: 1.286095]\n",
      "1776 [D loss: 0.230739, acc: 88.28%, op_acc: 75.00%] [G loss: 1.305319]\n",
      "1777 [D loss: 0.209940, acc: 91.41%, op_acc: 80.47%] [G loss: 1.269440]\n",
      "1778 [D loss: 0.209140, acc: 92.97%, op_acc: 71.09%] [G loss: 1.307573]\n",
      "1779 [D loss: 0.222591, acc: 87.50%, op_acc: 75.78%] [G loss: 1.287197]\n",
      "1780 [D loss: 0.230398, acc: 88.28%, op_acc: 77.34%] [G loss: 1.302137]\n",
      "Epoch: 1780, F1: 0.63529, F1P: 178\n",
      "[[28423     9]\n",
      " [   22    27]]\n",
      "90.3125\n",
      "1781 [D loss: 0.217074, acc: 91.41%, op_acc: 75.00%] [G loss: 1.336523]\n",
      "1782 [D loss: 0.212347, acc: 89.06%, op_acc: 75.78%] [G loss: 1.329952]\n",
      "1783 [D loss: 0.214117, acc: 91.41%, op_acc: 78.91%] [G loss: 1.323438]\n",
      "1784 [D loss: 0.229514, acc: 89.06%, op_acc: 74.22%] [G loss: 1.321409]\n",
      "1785 [D loss: 0.224367, acc: 92.19%, op_acc: 78.12%] [G loss: 1.296116]\n",
      "1786 [D loss: 0.208126, acc: 94.53%, op_acc: 76.56%] [G loss: 1.253880]\n",
      "1787 [D loss: 0.211865, acc: 92.19%, op_acc: 71.09%] [G loss: 1.269647]\n",
      "1788 [D loss: 0.219007, acc: 87.50%, op_acc: 70.31%] [G loss: 1.238094]\n",
      "1789 [D loss: 0.214696, acc: 89.84%, op_acc: 71.09%] [G loss: 1.233430]\n",
      "1790 [D loss: 0.219277, acc: 89.84%, op_acc: 75.78%] [G loss: 1.272889]\n",
      "Epoch: 1790, F1: 0.63529, F1P: 179\n",
      "[[28423     9]\n",
      " [   22    27]]\n",
      "90.703125\n",
      "1791 [D loss: 0.218286, acc: 91.41%, op_acc: 75.00%] [G loss: 1.245250]\n",
      "1792 [D loss: 0.233373, acc: 89.06%, op_acc: 71.09%] [G loss: 1.303596]\n",
      "1793 [D loss: 0.208981, acc: 92.19%, op_acc: 75.00%] [G loss: 1.305608]\n",
      "1794 [D loss: 0.223457, acc: 90.62%, op_acc: 74.22%] [G loss: 1.305431]\n",
      "1795 [D loss: 0.213724, acc: 89.84%, op_acc: 70.31%] [G loss: 1.274701]\n",
      "1796 [D loss: 0.215572, acc: 89.84%, op_acc: 78.12%] [G loss: 1.271422]\n",
      "1797 [D loss: 0.229171, acc: 89.06%, op_acc: 77.34%] [G loss: 1.322714]\n",
      "1798 [D loss: 0.208919, acc: 92.19%, op_acc: 73.44%] [G loss: 1.309757]\n",
      "1799 [D loss: 0.220580, acc: 90.62%, op_acc: 71.88%] [G loss: 1.323079]\n",
      "1800 [D loss: 0.210663, acc: 92.19%, op_acc: 77.34%] [G loss: 1.293003]\n",
      "Epoch: 1800, F1: 0.63529, F1P: 180\n",
      "[[28423     9]\n",
      " [   22    27]]\n",
      "90.703125\n",
      "1801 [D loss: 0.243560, acc: 82.03%, op_acc: 70.31%] [G loss: 1.229445]\n",
      "1802 [D loss: 0.226113, acc: 90.62%, op_acc: 67.97%] [G loss: 1.337818]\n",
      "1803 [D loss: 0.225687, acc: 90.62%, op_acc: 75.78%] [G loss: 1.264729]\n",
      "1804 [D loss: 0.223204, acc: 90.62%, op_acc: 70.31%] [G loss: 1.229507]\n",
      "1805 [D loss: 0.219394, acc: 88.28%, op_acc: 67.97%] [G loss: 1.340718]\n",
      "1806 [D loss: 0.231823, acc: 85.94%, op_acc: 72.66%] [G loss: 1.282144]\n",
      "1807 [D loss: 0.246183, acc: 89.06%, op_acc: 76.56%] [G loss: 1.288044]\n",
      "1808 [D loss: 0.227451, acc: 92.19%, op_acc: 72.66%] [G loss: 1.280281]\n",
      "1809 [D loss: 0.203544, acc: 91.41%, op_acc: 71.88%] [G loss: 1.209061]\n",
      "1810 [D loss: 0.227001, acc: 89.84%, op_acc: 81.25%] [G loss: 1.226390]\n",
      "Epoch: 1810, F1: 0.63529, F1P: 181\n",
      "[[28423     9]\n",
      " [   22    27]]\n",
      "89.0625\n",
      "1811 [D loss: 0.222934, acc: 90.62%, op_acc: 71.88%] [G loss: 1.255283]\n",
      "1812 [D loss: 0.227420, acc: 89.84%, op_acc: 66.41%] [G loss: 1.207656]\n",
      "1813 [D loss: 0.212206, acc: 92.97%, op_acc: 71.88%] [G loss: 1.257159]\n",
      "1814 [D loss: 0.229369, acc: 85.94%, op_acc: 64.84%] [G loss: 1.231131]\n",
      "1815 [D loss: 0.214682, acc: 90.62%, op_acc: 78.91%] [G loss: 1.330515]\n",
      "1816 [D loss: 0.236617, acc: 85.94%, op_acc: 70.31%] [G loss: 1.166318]\n",
      "1817 [D loss: 0.243369, acc: 85.94%, op_acc: 67.97%] [G loss: 1.219133]\n",
      "1818 [D loss: 0.236291, acc: 87.50%, op_acc: 63.28%] [G loss: 1.198126]\n",
      "1819 [D loss: 0.236337, acc: 87.50%, op_acc: 71.09%] [G loss: 1.219121]\n",
      "1820 [D loss: 0.215278, acc: 88.28%, op_acc: 68.75%] [G loss: 1.271748]\n",
      "Epoch: 1820, F1: 0.63529, F1P: 182\n",
      "[[28423     9]\n",
      " [   22    27]]\n",
      "88.515625\n",
      "1821 [D loss: 0.237886, acc: 85.94%, op_acc: 69.53%] [G loss: 1.256641]\n",
      "1822 [D loss: 0.231390, acc: 85.16%, op_acc: 64.84%] [G loss: 1.305674]\n",
      "1823 [D loss: 0.201573, acc: 96.09%, op_acc: 71.88%] [G loss: 1.236223]\n",
      "1824 [D loss: 0.229847, acc: 88.28%, op_acc: 63.28%] [G loss: 1.311112]\n",
      "1825 [D loss: 0.241183, acc: 83.59%, op_acc: 64.06%] [G loss: 1.296440]\n",
      "1826 [D loss: 0.210405, acc: 92.19%, op_acc: 72.66%] [G loss: 1.241034]\n",
      "1827 [D loss: 0.239872, acc: 82.81%, op_acc: 65.62%] [G loss: 1.173653]\n",
      "1828 [D loss: 0.203356, acc: 90.62%, op_acc: 68.75%] [G loss: 1.332326]\n",
      "1829 [D loss: 0.230496, acc: 85.94%, op_acc: 69.53%] [G loss: 1.339540]\n",
      "1830 [D loss: 0.227024, acc: 89.84%, op_acc: 71.09%] [G loss: 1.284178]\n",
      "Epoch: 1830, F1: 0.63529, F1P: 183\n",
      "[[28423     9]\n",
      " [   22    27]]\n",
      "88.046875\n",
      "1831 [D loss: 0.237909, acc: 83.59%, op_acc: 67.97%] [G loss: 1.307971]\n",
      "1832 [D loss: 0.217556, acc: 91.41%, op_acc: 75.78%] [G loss: 1.230106]\n",
      "1833 [D loss: 0.227977, acc: 89.06%, op_acc: 69.53%] [G loss: 1.236727]\n",
      "1834 [D loss: 0.220870, acc: 89.06%, op_acc: 67.19%] [G loss: 1.301259]\n",
      "1835 [D loss: 0.228810, acc: 87.50%, op_acc: 70.31%] [G loss: 1.310001]\n",
      "1836 [D loss: 0.216392, acc: 94.53%, op_acc: 71.88%] [G loss: 1.262665]\n",
      "1837 [D loss: 0.220225, acc: 89.84%, op_acc: 59.38%] [G loss: 1.259696]\n",
      "1838 [D loss: 0.215049, acc: 91.41%, op_acc: 72.66%] [G loss: 1.391850]\n",
      "1839 [D loss: 0.220225, acc: 87.50%, op_acc: 67.19%] [G loss: 1.380182]\n",
      "1840 [D loss: 0.245177, acc: 84.38%, op_acc: 57.81%] [G loss: 1.306667]\n",
      "Epoch: 1840, F1: 0.62651, F1P: 184\n",
      "[[28424     8]\n",
      " [   23    26]]\n",
      "88.828125\n",
      "1841 [D loss: 0.216439, acc: 88.28%, op_acc: 69.53%] [G loss: 1.269415]\n",
      "1842 [D loss: 0.223586, acc: 89.84%, op_acc: 71.88%] [G loss: 1.334452]\n",
      "1843 [D loss: 0.221452, acc: 92.97%, op_acc: 69.53%] [G loss: 1.356079]\n",
      "1844 [D loss: 0.232966, acc: 88.28%, op_acc: 66.41%] [G loss: 1.345350]\n",
      "1845 [D loss: 0.212302, acc: 90.62%, op_acc: 70.31%] [G loss: 1.358712]\n",
      "1846 [D loss: 0.212830, acc: 89.84%, op_acc: 76.56%] [G loss: 1.409186]\n",
      "1847 [D loss: 0.231606, acc: 89.06%, op_acc: 67.19%] [G loss: 1.361980]\n",
      "1848 [D loss: 0.220777, acc: 86.72%, op_acc: 71.09%] [G loss: 1.416071]\n",
      "1849 [D loss: 0.221186, acc: 88.28%, op_acc: 71.09%] [G loss: 1.287308]\n",
      "1850 [D loss: 0.235432, acc: 86.72%, op_acc: 70.31%] [G loss: 1.367104]\n",
      "Epoch: 1850, F1: 0.61728, F1P: 185\n",
      "[[28425     7]\n",
      " [   24    25]]\n",
      "89.0625\n",
      "1851 [D loss: 0.209248, acc: 89.06%, op_acc: 67.97%] [G loss: 1.347473]\n",
      "1852 [D loss: 0.236900, acc: 84.38%, op_acc: 68.75%] [G loss: 1.335004]\n",
      "1853 [D loss: 0.217778, acc: 91.41%, op_acc: 70.31%] [G loss: 1.485044]\n",
      "1854 [D loss: 0.223498, acc: 89.06%, op_acc: 69.53%] [G loss: 1.390445]\n",
      "1855 [D loss: 0.218118, acc: 92.97%, op_acc: 65.62%] [G loss: 1.375656]\n",
      "1856 [D loss: 0.230201, acc: 89.06%, op_acc: 64.84%] [G loss: 1.460988]\n",
      "1857 [D loss: 0.209253, acc: 89.06%, op_acc: 72.66%] [G loss: 1.479882]\n",
      "1858 [D loss: 0.214639, acc: 92.19%, op_acc: 69.53%] [G loss: 1.407250]\n",
      "1859 [D loss: 0.225715, acc: 89.06%, op_acc: 75.00%] [G loss: 1.337055]\n",
      "1860 [D loss: 0.226399, acc: 88.28%, op_acc: 70.31%] [G loss: 1.385988]\n",
      "Epoch: 1860, F1: 0.61538, F1P: 186\n",
      "[[28427     5]\n",
      " [   25    24]]\n",
      "89.453125\n",
      "1861 [D loss: 0.227293, acc: 87.50%, op_acc: 72.66%] [G loss: 1.374376]\n",
      "1862 [D loss: 0.200190, acc: 93.75%, op_acc: 71.88%] [G loss: 1.484976]\n",
      "1863 [D loss: 0.246040, acc: 83.59%, op_acc: 67.19%] [G loss: 1.362019]\n",
      "1864 [D loss: 0.204482, acc: 92.19%, op_acc: 69.53%] [G loss: 1.439068]\n",
      "1865 [D loss: 0.213122, acc: 91.41%, op_acc: 67.19%] [G loss: 1.432722]\n",
      "1866 [D loss: 0.198373, acc: 92.97%, op_acc: 67.97%] [G loss: 1.453260]\n",
      "1867 [D loss: 0.224064, acc: 89.84%, op_acc: 64.84%] [G loss: 1.361857]\n",
      "1868 [D loss: 0.215888, acc: 90.62%, op_acc: 65.62%] [G loss: 1.351257]\n",
      "1869 [D loss: 0.212859, acc: 91.41%, op_acc: 69.53%] [G loss: 1.302688]\n",
      "1870 [D loss: 0.206594, acc: 95.31%, op_acc: 68.75%] [G loss: 1.480369]\n",
      "Epoch: 1870, F1: 0.59740, F1P: 187\n",
      "[[28427     5]\n",
      " [   26    23]]\n",
      "90.859375\n",
      "1871 [D loss: 0.206291, acc: 92.19%, op_acc: 66.41%] [G loss: 1.401295]\n",
      "1872 [D loss: 0.240248, acc: 87.50%, op_acc: 62.50%] [G loss: 1.481902]\n",
      "1873 [D loss: 0.215953, acc: 92.97%, op_acc: 71.88%] [G loss: 1.315673]\n",
      "1874 [D loss: 0.219092, acc: 89.06%, op_acc: 68.75%] [G loss: 1.365202]\n",
      "1875 [D loss: 0.221160, acc: 92.97%, op_acc: 65.62%] [G loss: 1.365844]\n",
      "1876 [D loss: 0.193650, acc: 95.31%, op_acc: 75.00%] [G loss: 1.422952]\n",
      "1877 [D loss: 0.221959, acc: 87.50%, op_acc: 71.88%] [G loss: 1.388353]\n",
      "1878 [D loss: 0.228275, acc: 90.62%, op_acc: 69.53%] [G loss: 1.283104]\n",
      "1879 [D loss: 0.213658, acc: 89.06%, op_acc: 69.53%] [G loss: 1.376323]\n",
      "1880 [D loss: 0.234353, acc: 84.38%, op_acc: 67.19%] [G loss: 1.390734]\n",
      "Epoch: 1880, F1: 0.57895, F1P: 188\n",
      "[[28427     5]\n",
      " [   27    22]]\n",
      "90.15625\n",
      "1881 [D loss: 0.208856, acc: 92.97%, op_acc: 70.31%] [G loss: 1.355859]\n",
      "1882 [D loss: 0.216517, acc: 91.41%, op_acc: 70.31%] [G loss: 1.437254]\n",
      "1883 [D loss: 0.231362, acc: 87.50%, op_acc: 67.19%] [G loss: 1.318438]\n",
      "1884 [D loss: 0.214141, acc: 88.28%, op_acc: 68.75%] [G loss: 1.424115]\n",
      "1885 [D loss: 0.201102, acc: 90.62%, op_acc: 73.44%] [G loss: 1.353816]\n",
      "1886 [D loss: 0.218807, acc: 88.28%, op_acc: 63.28%] [G loss: 1.366781]\n",
      "1887 [D loss: 0.220638, acc: 89.06%, op_acc: 67.97%] [G loss: 1.321028]\n",
      "1888 [D loss: 0.230164, acc: 89.84%, op_acc: 67.19%] [G loss: 1.451821]\n",
      "1889 [D loss: 0.236570, acc: 88.28%, op_acc: 71.09%] [G loss: 1.460185]\n",
      "1890 [D loss: 0.217441, acc: 92.97%, op_acc: 68.75%] [G loss: 1.445796]\n",
      "Epoch: 1890, F1: 0.57895, F1P: 189\n",
      "[[28427     5]\n",
      " [   27    22]]\n",
      "89.921875\n",
      "1891 [D loss: 0.217541, acc: 92.19%, op_acc: 70.31%] [G loss: 1.359449]\n",
      "1892 [D loss: 0.233426, acc: 85.16%, op_acc: 71.09%] [G loss: 1.358472]\n",
      "1893 [D loss: 0.209528, acc: 93.75%, op_acc: 72.66%] [G loss: 1.423885]\n",
      "1894 [D loss: 0.244584, acc: 83.59%, op_acc: 70.31%] [G loss: 1.373153]\n",
      "1895 [D loss: 0.222690, acc: 89.06%, op_acc: 68.75%] [G loss: 1.273222]\n",
      "1896 [D loss: 0.210058, acc: 92.19%, op_acc: 77.34%] [G loss: 1.257632]\n",
      "1897 [D loss: 0.233552, acc: 89.84%, op_acc: 67.19%] [G loss: 1.332382]\n",
      "1898 [D loss: 0.234307, acc: 84.38%, op_acc: 67.97%] [G loss: 1.459401]\n",
      "1899 [D loss: 0.239915, acc: 83.59%, op_acc: 68.75%] [G loss: 1.262642]\n",
      "1900 [D loss: 0.267402, acc: 85.16%, op_acc: 71.88%] [G loss: 1.340742]\n",
      "Epoch: 1900, F1: 0.57895, F1P: 190\n",
      "[[28427     5]\n",
      " [   27    22]]\n",
      "87.890625\n",
      "1901 [D loss: 0.237324, acc: 89.84%, op_acc: 74.22%] [G loss: 1.421896]\n",
      "1902 [D loss: 0.229598, acc: 88.28%, op_acc: 72.66%] [G loss: 1.400065]\n",
      "1903 [D loss: 0.235453, acc: 88.28%, op_acc: 71.09%] [G loss: 1.410318]\n",
      "1904 [D loss: 0.248621, acc: 78.91%, op_acc: 64.06%] [G loss: 1.319370]\n",
      "1905 [D loss: 0.238818, acc: 84.38%, op_acc: 75.00%] [G loss: 1.332720]\n",
      "1906 [D loss: 0.234711, acc: 86.72%, op_acc: 70.31%] [G loss: 1.380187]\n",
      "1907 [D loss: 0.223087, acc: 92.19%, op_acc: 72.66%] [G loss: 1.390205]\n",
      "1908 [D loss: 0.226265, acc: 92.97%, op_acc: 67.97%] [G loss: 1.283306]\n",
      "1909 [D loss: 0.244471, acc: 80.47%, op_acc: 68.75%] [G loss: 1.307309]\n",
      "1910 [D loss: 0.229750, acc: 85.94%, op_acc: 67.19%] [G loss: 1.265991]\n",
      "Epoch: 1910, F1: 0.57895, F1P: 191\n",
      "[[28427     5]\n",
      " [   27    22]]\n",
      "86.796875\n",
      "1911 [D loss: 0.235712, acc: 87.50%, op_acc: 71.88%] [G loss: 1.266020]\n",
      "1912 [D loss: 0.232702, acc: 89.84%, op_acc: 67.97%] [G loss: 1.288477]\n",
      "1913 [D loss: 0.247493, acc: 81.25%, op_acc: 67.97%] [G loss: 1.254906]\n",
      "1914 [D loss: 0.248793, acc: 85.94%, op_acc: 61.72%] [G loss: 1.368980]\n",
      "1915 [D loss: 0.233717, acc: 82.81%, op_acc: 63.28%] [G loss: 1.243666]\n",
      "1916 [D loss: 0.219330, acc: 85.94%, op_acc: 67.97%] [G loss: 1.416119]\n",
      "1917 [D loss: 0.225225, acc: 88.28%, op_acc: 75.00%] [G loss: 1.366459]\n",
      "1918 [D loss: 0.237482, acc: 85.16%, op_acc: 67.19%] [G loss: 1.285873]\n",
      "1919 [D loss: 0.220337, acc: 89.06%, op_acc: 74.22%] [G loss: 1.437814]\n",
      "1920 [D loss: 0.234028, acc: 82.81%, op_acc: 71.09%] [G loss: 1.453754]\n",
      "Epoch: 1920, F1: 0.57895, F1P: 192\n",
      "[[28427     5]\n",
      " [   27    22]]\n",
      "85.859375\n",
      "1921 [D loss: 0.240646, acc: 83.59%, op_acc: 66.41%] [G loss: 1.349204]\n",
      "1922 [D loss: 0.230144, acc: 83.59%, op_acc: 66.41%] [G loss: 1.350187]\n",
      "1923 [D loss: 0.230502, acc: 89.84%, op_acc: 71.88%] [G loss: 1.364052]\n",
      "1924 [D loss: 0.255884, acc: 80.47%, op_acc: 67.19%] [G loss: 1.355632]\n",
      "1925 [D loss: 0.229638, acc: 88.28%, op_acc: 62.50%] [G loss: 1.364584]\n",
      "1926 [D loss: 0.247029, acc: 84.38%, op_acc: 69.53%] [G loss: 1.351866]\n",
      "1927 [D loss: 0.233165, acc: 84.38%, op_acc: 67.19%] [G loss: 1.285567]\n",
      "1928 [D loss: 0.242265, acc: 85.16%, op_acc: 68.75%] [G loss: 1.248536]\n",
      "1929 [D loss: 0.232160, acc: 82.81%, op_acc: 70.31%] [G loss: 1.338447]\n",
      "1930 [D loss: 0.241616, acc: 85.94%, op_acc: 63.28%] [G loss: 1.335582]\n",
      "Epoch: 1930, F1: 0.59740, F1P: 193\n",
      "[[28427     5]\n",
      " [   26    23]]\n",
      "84.84375\n",
      "1931 [D loss: 0.238630, acc: 83.59%, op_acc: 69.53%] [G loss: 1.267280]\n",
      "1932 [D loss: 0.242512, acc: 82.81%, op_acc: 73.44%] [G loss: 1.367877]\n",
      "1933 [D loss: 0.228729, acc: 86.72%, op_acc: 67.19%] [G loss: 1.336739]\n",
      "1934 [D loss: 0.242565, acc: 82.81%, op_acc: 71.09%] [G loss: 1.383572]\n",
      "1935 [D loss: 0.222834, acc: 86.72%, op_acc: 72.66%] [G loss: 1.420589]\n",
      "1936 [D loss: 0.250790, acc: 82.03%, op_acc: 64.84%] [G loss: 1.436206]\n",
      "1937 [D loss: 0.220034, acc: 89.06%, op_acc: 70.31%] [G loss: 1.388639]\n",
      "1938 [D loss: 0.217802, acc: 90.62%, op_acc: 75.78%] [G loss: 1.253158]\n",
      "1939 [D loss: 0.230699, acc: 87.50%, op_acc: 66.41%] [G loss: 1.450749]\n",
      "1940 [D loss: 0.212148, acc: 88.28%, op_acc: 74.22%] [G loss: 1.301227]\n",
      "Epoch: 1940, F1: 0.58228, F1P: 194\n",
      "[[28425     7]\n",
      " [   26    23]]\n",
      "86.015625\n",
      "1941 [D loss: 0.213959, acc: 90.62%, op_acc: 73.44%] [G loss: 1.346951]\n",
      "1942 [D loss: 0.242699, acc: 86.72%, op_acc: 67.97%] [G loss: 1.278767]\n",
      "1943 [D loss: 0.220647, acc: 90.62%, op_acc: 78.12%] [G loss: 1.301036]\n",
      "1944 [D loss: 0.232120, acc: 89.84%, op_acc: 69.53%] [G loss: 1.366614]\n",
      "1945 [D loss: 0.220327, acc: 90.62%, op_acc: 67.19%] [G loss: 1.354379]\n",
      "1946 [D loss: 0.230345, acc: 89.06%, op_acc: 66.41%] [G loss: 1.272614]\n",
      "1947 [D loss: 0.237315, acc: 86.72%, op_acc: 75.00%] [G loss: 1.329232]\n",
      "1948 [D loss: 0.218347, acc: 92.19%, op_acc: 78.12%] [G loss: 1.264681]\n",
      "1949 [D loss: 0.238146, acc: 84.38%, op_acc: 69.53%] [G loss: 1.403792]\n",
      "1950 [D loss: 0.233051, acc: 86.72%, op_acc: 65.62%] [G loss: 1.362521]\n",
      "Epoch: 1950, F1: 0.59740, F1P: 195\n",
      "[[28427     5]\n",
      " [   26    23]]\n",
      "88.75\n",
      "1951 [D loss: 0.214998, acc: 87.50%, op_acc: 71.88%] [G loss: 1.310302]\n",
      "1952 [D loss: 0.231391, acc: 85.16%, op_acc: 70.31%] [G loss: 1.416755]\n",
      "1953 [D loss: 0.227125, acc: 86.72%, op_acc: 71.09%] [G loss: 1.384712]\n",
      "1954 [D loss: 0.224140, acc: 85.94%, op_acc: 67.19%] [G loss: 1.285614]\n",
      "1955 [D loss: 0.254740, acc: 82.03%, op_acc: 73.44%] [G loss: 1.292562]\n",
      "1956 [D loss: 0.227056, acc: 89.06%, op_acc: 67.19%] [G loss: 1.283643]\n",
      "1957 [D loss: 0.219461, acc: 92.97%, op_acc: 75.78%] [G loss: 1.251912]\n",
      "1958 [D loss: 0.220389, acc: 89.84%, op_acc: 78.12%] [G loss: 1.317057]\n",
      "1959 [D loss: 0.231734, acc: 86.72%, op_acc: 69.53%] [G loss: 1.288695]\n",
      "1960 [D loss: 0.221833, acc: 88.28%, op_acc: 68.75%] [G loss: 1.274174]\n",
      "Epoch: 1960, F1: 0.59740, F1P: 196\n",
      "[[28427     5]\n",
      " [   26    23]]\n",
      "87.421875\n",
      "1961 [D loss: 0.239048, acc: 85.94%, op_acc: 65.62%] [G loss: 1.238870]\n",
      "1962 [D loss: 0.213620, acc: 88.28%, op_acc: 71.88%] [G loss: 1.373442]\n",
      "1963 [D loss: 0.228176, acc: 91.41%, op_acc: 72.66%] [G loss: 1.429999]\n",
      "1964 [D loss: 0.219744, acc: 90.62%, op_acc: 75.00%] [G loss: 1.304331]\n",
      "1965 [D loss: 0.213957, acc: 95.31%, op_acc: 72.66%] [G loss: 1.383340]\n",
      "1966 [D loss: 0.213075, acc: 92.97%, op_acc: 71.09%] [G loss: 1.287893]\n",
      "1967 [D loss: 0.226694, acc: 87.50%, op_acc: 70.31%] [G loss: 1.317097]\n",
      "1968 [D loss: 0.215455, acc: 89.84%, op_acc: 71.88%] [G loss: 1.408555]\n",
      "1969 [D loss: 0.230841, acc: 92.19%, op_acc: 71.88%] [G loss: 1.312990]\n",
      "1970 [D loss: 0.224819, acc: 85.94%, op_acc: 72.66%] [G loss: 1.355915]\n",
      "Epoch: 1970, F1: 0.61538, F1P: 197\n",
      "[[28427     5]\n",
      " [   25    24]]\n",
      "90.0\n",
      "1971 [D loss: 0.219527, acc: 89.06%, op_acc: 76.56%] [G loss: 1.373222]\n",
      "1972 [D loss: 0.212355, acc: 89.84%, op_acc: 70.31%] [G loss: 1.294707]\n",
      "1973 [D loss: 0.219023, acc: 92.19%, op_acc: 74.22%] [G loss: 1.317924]\n",
      "1974 [D loss: 0.226049, acc: 89.06%, op_acc: 69.53%] [G loss: 1.296631]\n",
      "1975 [D loss: 0.220570, acc: 94.53%, op_acc: 66.41%] [G loss: 1.356408]\n",
      "1976 [D loss: 0.212419, acc: 91.41%, op_acc: 71.09%] [G loss: 1.331917]\n",
      "1977 [D loss: 0.230447, acc: 88.28%, op_acc: 72.66%] [G loss: 1.357323]\n",
      "1978 [D loss: 0.235441, acc: 86.72%, op_acc: 66.41%] [G loss: 1.379925]\n",
      "1979 [D loss: 0.210095, acc: 88.28%, op_acc: 75.00%] [G loss: 1.324042]\n",
      "1980 [D loss: 0.210299, acc: 92.19%, op_acc: 71.88%] [G loss: 1.339720]\n",
      "Epoch: 1980, F1: 0.61538, F1P: 198\n",
      "[[28427     5]\n",
      " [   25    24]]\n",
      "90.15625\n",
      "1981 [D loss: 0.210384, acc: 91.41%, op_acc: 71.09%] [G loss: 1.430028]\n",
      "1982 [D loss: 0.214410, acc: 90.62%, op_acc: 71.88%] [G loss: 1.312312]\n",
      "1983 [D loss: 0.209387, acc: 87.50%, op_acc: 68.75%] [G loss: 1.359027]\n",
      "1984 [D loss: 0.216977, acc: 89.84%, op_acc: 68.75%] [G loss: 1.432153]\n",
      "1985 [D loss: 0.221534, acc: 92.19%, op_acc: 74.22%] [G loss: 1.378622]\n",
      "1986 [D loss: 0.220940, acc: 88.28%, op_acc: 72.66%] [G loss: 1.356970]\n",
      "1987 [D loss: 0.212040, acc: 95.31%, op_acc: 78.91%] [G loss: 1.330997]\n",
      "1988 [D loss: 0.204746, acc: 92.19%, op_acc: 76.56%] [G loss: 1.436050]\n",
      "1989 [D loss: 0.195196, acc: 93.75%, op_acc: 72.66%] [G loss: 1.392942]\n",
      "1990 [D loss: 0.192956, acc: 94.53%, op_acc: 74.22%] [G loss: 1.353563]\n",
      "Epoch: 1990, F1: 0.61538, F1P: 199\n",
      "[[28427     5]\n",
      " [   25    24]]\n",
      "91.5625\n",
      "1991 [D loss: 0.204750, acc: 93.75%, op_acc: 75.78%] [G loss: 1.373769]\n",
      "1992 [D loss: 0.220370, acc: 87.50%, op_acc: 75.78%] [G loss: 1.405734]\n",
      "1993 [D loss: 0.212254, acc: 90.62%, op_acc: 67.97%] [G loss: 1.387509]\n",
      "1994 [D loss: 0.215706, acc: 86.72%, op_acc: 68.75%] [G loss: 1.342577]\n",
      "1995 [D loss: 0.207857, acc: 92.19%, op_acc: 74.22%] [G loss: 1.397802]\n",
      "1996 [D loss: 0.234016, acc: 87.50%, op_acc: 68.75%] [G loss: 1.304209]\n",
      "1997 [D loss: 0.202228, acc: 92.97%, op_acc: 80.47%] [G loss: 1.362181]\n",
      "1998 [D loss: 0.222514, acc: 89.84%, op_acc: 64.84%] [G loss: 1.429106]\n",
      "1999 [D loss: 0.206943, acc: 92.19%, op_acc: 71.09%] [G loss: 1.395252]\n"
     ]
    }
   ],
   "source": [
    "f1_p, d_l_p = train(X_res,y_res,\n",
    "             X_test,y_test,\n",
    "             generator,discriminator,\n",
    "             combined,\n",
    "             num_classes=2,\n",
    "             epochs=2000, \n",
    "             batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "275574636046ce8cfe041ab9776628447da970ac",
    "execution": {
     "iopub.execute_input": "2023-12-22T15:58:35.934323Z",
     "iopub.status.busy": "2023-12-22T15:58:35.933976Z",
     "iopub.status.idle": "2023-12-22T15:58:36.163336Z",
     "shell.execute_reply": "2023-12-22T15:58:36.162271Z",
     "shell.execute_reply.started": "2023-12-22T15:58:35.934258Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'F1 Score Validation')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmQAAAGtCAYAAAC4HmhdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzs3Xd4XNWd//HPV6MuW5IlufeCAYNp\nMdXEwAIBUoAUEpJsGknYZEPCpmwWNrtZUn9pm2w2YZOQBtkUQhLIeoGEtgmEbgcMuIB7kYusZo2k\nkTQzmvP7Y+7II1mSR7Jm7pT363nm8cydO3e+16Py0TnnnmPOOQEAAMA/RX4XAAAAUOgIZAAAAD4j\nkAEAAPiMQAYAAOAzAhkAAIDPCGQAAAA+I5ABAAD4jEAGAADgMwIZAACAz4r9LmCsGhoa3IIFC/wu\nAwAA4Kj++te/tjjnph5tv5wLZAsWLNDatWv9LgMAAOCozGxXKvvRZQkAAOAzAhkAAIDPCGQAAAA+\nI5ABAAD4jEAGAADgMwIZAACAzwhkAAAAPiOQAQAA+IxABgAA4DMCGQAAgM8IZAAAAD4jkAEAAPiM\nQAYAAOAzAhkAAIDPiv0uAAAAZF5XX1R723uO2D6ztlzV5SU+VFTYCGQAABSg625fo2d3tB2xffns\nGv3vR8/3oaLCRiADAKDANHf2ac3ONr35jDm6+MRpA9sf2tik36/bq66+qCaVEREyif9tAAAKzJ9e\nPijnpPefv1DLZlUPbK8oCeie5/dqw94Onb2o3scKCw+D+gEAKDAPbWrSrJpynThz8qDty+fUSJJe\nbOzwo6yCRiADACDLtXeH9cm7XtCWps5jPlZvpF+Pb2nRJcumy8wGPdcwqUyzayv0QuOhY34fjA2B\nDACALPfF+zbpd8816pO/eUH9MXdMx3pqW6t6Iv26+MTpwz5/ypwaWsh8QCADACCLPbG1Rb97rlEr\n5k/Ri40duuPJncd0vIc2NamqNKBzFtUN+/wpc2q1uy2k9u7wMb0PxoZABgBAluqN9Ouf73lJC+or\n9fMPnK2Ljp+qbzz4ihrbQ+M6nnNOj2xq0qqlU1VWHBh2n1O9cWQv7aWVLJO4yhIAgCzQ3RfVMzta\n9eyOdm3Y16Fov1N7KKxdrSH98oNnq7wkoC9cfbJe863H9I4fPqPZtRVjfo9If0xNwb4Ruysl6aTZ\niYH9h7Rq6VT96eWD+tHj2xWLje293nH2PL3h1FljrrFQEcgAAMgC192+Rs/saFNxkemEmZNVWVKs\n6vIS3XzFCTpvcYMkac6USv37Nafqp0/uHNdYsiIzXXzCNL3mpJEDWU1FiRY1VOmFxg41BXv1sTuf\n1+SyYs2ZUpny++zr6NE//e5Fnbu4Xg2TysZcZyEikAEA4DPnnDbuC+rq02bp/73pFFWUDt+dKElX\nLJ+pK5bPTGs9p8yp0VPbW/Uvv1+vcDSmX95wjhY0VKX8+u3NXbr0W4/pu/+3VbdceVIaK80fjCED\nAMBnbd1hdfZFdcqc2lHDWKacMqdWTcE+PbSxSZ98zdIxhTFJWjR1kt66Yq5+8cwu7Wkb33i3QkMg\nAwDAZztb46FlQUPq3YLpdIo3sP+UOTW6buXCcR3jxouPU5GZvvnQ5oksLW8RyAAA8Nmu1m5J0vz6\nsbVEpcupc2v1vpUL9K23nabiwPiiwoyacr1v5UL9ft1ebdofnOAK8w+BDAAAn+1sDanIpDlTxn7l\nZDqUBIr0b284SYunTjqm43z4gsWaXFasbzzwygRVlr8IZAAA+GxXa7dm1VaMODdYrqqpLNGHL1yi\nR14+qDU72/wuJ6sRyAAA8NnO1pAWZEl35UR773kLNL26TF/9w8ty7tiWfcpnTHsBAMhZnb0R7T3U\nI0kqLw4ccTVga1ef6qpKj1hEeySxmNP2lm5FxzoLqqe4qEiLGqpUVHTk+/XHnLY3d6nfOZlMCxuq\nVFocbxfZ1dqt16V5Kgu/VJQGdOPFS/XP97ykRzYd1CXLRp4DrZARyAAAKeuPOXX1RlVTWTLs8919\nUQWKTOUlqXe9tXb1qdVbN3F6dblqKoY/9nDe85Nn9dzuQwOPf/TuFQO/8Nfv7dDVtz6hb197ul53\nSmph57fPNerTv30x5fcfztfecoreumLuEdtvf3KnvnDvxsO1nztfn7vqZB0KhXUoFMnbFjJJumbF\nHP3oL9v19794TpedPEPvPHuezllUn7H339/Ro87e6BHbGyaVqa6qNGN1jIZABgBI2U+f2KFvPrRZ\n93/s1cPOTfW2255STUWJfv7+s1Nqldq4L6g3/tcT6ovGW6RqK0v0wD+s0vTq8qO+tqWrT8/tPqS3\nvGqOLj5hmr7yx5f1rYc36+ITp8nM9B8Pb1E05vTgxgMpB7KHNzZpZk25Pvv6ZSntP9Tn792ohzc2\nDRvIHt7YpEUNVfrHy47XT5/cqYc3HdQtVzrt8qa8mF+fHVNepENJoEh3XHeWfvz4Dt39XKP+94V9\nuv19Z+rC46el/b33tIV04Tf+POzKBjddcYI+dMHitNeQCgIZACBlD21sUijcr3/9n/X62XVnDQpd\nBzp6tX5vfHqDe57fqzedMWfUY8ViTp/5/UuaVFasb1xzksLRmP75npf0+Xs36tZ3nHHUWh7f0iJJ\netc583Xq3Fp19kX16d++qEc2HdSMmnI9vKlJFSUB/WVLi2IxN2w3YrJIf0xPbmvVG06dNe6Z8B/b\n0qL/fWGfIv0xlSRNF9HdF9XaXW26buVCXbF8ptpCYX3mnvXa1tytnd6UF2OdfDXXzK2r1C1XnqR/\nuvwErfjiQ3poY1NGAtmfNzerP+b05TcuP6L19fgZk9P+/qliUD8AICWhcFTP7W7X7NoK/WVLi+57\naf+g5x/fGg9Is2sr9KX7NulQKDzq8e5cs0fP7z6kf37tiXrDqbP05lfN0UcuWqL7XtyvRzc3H7We\nxzY3q66qVMu9xbDfePpsza2r0Lcf2aL/fGSLJpcX66YrTlBbd1gb9h19Hqzndx9SV19UFyxtOOq+\nI7lgaYO6+qJ6PqkbVZKe3t6qSL/TqqVTJUmrjps6cA6JFrJ5dfnbQpasojSgcxbV68ltrRl5v8e3\nNGt2bYXeftZcve6UmYNuS6Yd27QeE4lABgBIybM72hTpd/riG0/WybOr9fn/3ajO3sjA809sbVF9\nValue/erdKgnoq/+8WX1RfuHvTUFe/XVP76ssxfW6U1nzB44xt9dsEiLGqr02f9Zr87eyBGvS4jF\nnB7b0qLzlzQMtHyVBIp0w0VL9NLeDj24sUnXrVyo13otXY9tORzwRrrS77HNzQoUmc5bMv5Adt6S\nBgWKTI8NCZSPbW5WRUlAKxZMkRRvLVrUUKXHtjRrZ2u3ZtaUj2ncXa47b0mDdrR0D1yQkS79Macn\nt7Xq/CUNKV/Y4Re6LAEAKXl8S4tKi4t07qJ6fenq5br6v57Qd/9vq25+7YlyzunxrS1auaRBJ82q\n0XUrF+iHf9mhXz27Z8TjlQRMX3rjyYN+UZYVB/TFq0/WO370jJbf8uARr/nA+Qv1L69fpk0Hgmrp\n6htocUp40xlz9J3/26qOUETXrVyomsoSLZtZrUc3N+sjFy3RgY5evfUHT+mDqxbpXefMH/Tax7Y0\n6/S5taouT/2igqGqy0t0+txaPbalWZ+67PikY7fonEV1g+YZW7V0qu5cs1tLpk3K6/FjwznfC71P\nbG0ZdrzdRHlpb4c6e6M6/7jxh+xMSWsgM7PLJX1bUkDSj5xzXxlmn7dKukWSk/SCc+4d6awJADA+\nj29t0Yr5U1ReEtCpc2t11amz9POnd+nDFy5WU7BPzZ19A79oP/ma4zWvrlLBYa5sSzhj3hQtmXbk\nGJ7zljToh+9eoc1NnYO2v9TYoR89vkOXLJuu53a3S5JWDflFWxIo0g/e9Sp19/UPXAm6aulU/egv\n29XZG9Etqzdod1tIX75vky5cOlVzvW7C1q4+vbS3Qx+/ZOn4/4M8q5ZO1bce3qzWrj7VTyrT7taQ\ndrR0693nzh+yX4Nuf3Kn1u8N6toz0xdKstHS6ZPUMKlMT6Y5kD3hdaOftzhzV3SOV9oCmZkFJN0q\n6VJJjZLWmNlq59zGpH2Ok3SzpJXOuXYzS//oPgDAmDV39unlA5369OWHW30+dOFi/X7dPv3sqV2q\nKov/OlnpBaTykoDede6Ccb/fpcum69Ih81X1hPu14T8e1T/f85KmVJbqhBmTNW2YqzFPmlUz6PGq\npQ36/qPb9IV7N+qPGw7ovect0G/W7tG//H69bn/fmTIzPb61Rc7piBa38Vi1dKq++dBmPb61RVed\nNluPet2lQ499zqJ6lQaKFO6PZc0alpliZjpvcb2e2NYq51zauhP/sqVZy2ZWq35SWVqOP5HSOYbs\nLElbnXPbnXNhSXdKumrIPh+UdKtzrl2SnHMH01gPAGCcntwWb2k4P2l81QkzqnXxCdP00yd26OGN\nTVrYUKXZtelbi7GiNKAvXb1c25u79ddd7bogxfC0Yn6dKksDumtto06YMVmfed2J+sfLjtejm5u1\n+oV9kqRHNzertrJk4AKBY7F8do1qK0sGLkx4bHN8UPmiIVdRVpYWD4wpW1BgXZZS/GupubNPWw52\npeX4oXBUz+06lBPdlVJ6A9lsScmDBxq9bcmWSlpqZk+Y2dNeFycAIMv8ZUuLaipKjmh9+vuLFqs9\nFNFT21sHhbV0WbV0qq4+bdbA/VSUFhfpvMX1MpP+35uWqyRQpHedu0Cnzq3VjXeu08Kb79Pdz+3V\n+d6A/GMVKDK9+ripuvu5vVp48316aGOTVi2dOmwrUCJUFloLmSSdtyTejZiYvmSirdnZrnB/LCNf\nlxMhnWPIhvuqHnppS7Gk4yRdKGmOpL+Y2cnOuUHXC5vZ9ZKul6R58+ZNfKUAAEnxqxe/839bdc2K\nOZrltXbFYk5PbG3RyiX1RwSWV82v01kL6vTszjatzNAvvs9ddbLOWlivc8cw0/tNV5yot66Yq9Pn\nxVukAkWm7//tGbprTaP6YzHJTG88fWibwfh94tKlWthQJXndcdesGH5OtneeM19Tqkp14szsmQ8r\nU+ZMqdSC+ko9ua1F152/cMyvb+sO644nd+ojFy0ZWIKqqy+qbzzwikLhqF4+0KnSQJHOXFA30aWn\nRToDWaOk5JF6cyTtG2afp51zEUk7zOwVxQPamuSdnHO3SbpNklasWMHKpACQJttbuvWthzfrmR2t\n+sUH4rPt37V2j/Z39Oqmk2YM+5pPX368vvKHl7VySWYGTtdUlOgdZ4/tj/Ml0yYdMefUzJoK3XjJ\ncRNZ2oCFDVX6xKVHv0BgUllxWge1Z7vzljRo9bp9ivbHVBwYW6fdb/+6R99+ZItOnDlZl58cn97k\n3hf26fYnd2p6dZmKzPS2M+eqojQ3phNJZ5flGknHmdlCMyuVdK2k1UP2+b2kiyTJzBoU78Lcnsaa\nAACjaO3qkyQ9ua1V9zy/V82dffry/Zt01sI6XXnqrGFfs2JBnX774fM0+Rimi0BhWrk4PpHuC40d\nY37tE1vjE8s+sKFpYNsDGw5obl2Fnr75Yj1188X6wtUnT1it6Za2QOaci0q6QdIDkjZJuss5t8HM\nPm9mV3q7PSCp1cw2SvqTpH90zmVm6l4AwBESi3zPqC7XF+/bpJvvfkm9kZi+/MblWT+xJnLPud7Y\nvie3jm0cWTga07M72iRJj2xqUqQ/ps7eiJ7Y2qrLls3Iya/VtM7U75y73zm31Dm32Dn3JW/bZ51z\nq737zjn3CefcMufccufcnemsBwAwukQL2devOUXBnoge3tSkD1+4OKuWmEH+qKsq1bKZ1QPLbqXq\nhcZD6on06y2vmqNgb1RPb2/Vn15pVrg/pstOHr5rPduxdBIAYECihezcRfX69OXH69xF9frwhYt9\nrgr57PwlDXp+9yGFwiNPIjzUE1tbZCb942XHq7I0oAc2HNADGw6oYVKZzvAu3Mg1BDIAwIDWrrBq\nK0tUHCjS9asW61fXn1NQaywi885b0qBwf0xrdran/Jont7Xq5Fk1ml5drguWTtUDG5r055cP6tJl\n0ydk6hI/EMgAAAPausOqryr1uwwUkDMXTFFJwFIeRxYKR/X87vaBecwuO2mGmjv71B3u12UnTT/K\nq7MXi4sDAAa0eOsvAplSWVqsM+ZNSXkc2dqd7Yr0O523OD7v3UUnTFNxkamiJDCwLRfRQgYAGNBK\nCxl8sHJJgzbuD6rNG8M4mie2tagkYDrTW3aqpqJE7zx7nt5z3oKBCWJzES1kAFBgfvL4DpUWF+lv\nz5l/xHNt3WHVTyKQIbNWLmnQNx/arDf91xOqLB09muxpC+n0uVMG7fe5q3JnvrGREMgAoMDc/Xyj\nKkoCRwSy/phTeyisuiq6LJFZp86p0TvPnqemYN9R951VW6F3npN/yygSyACgwIT6+hWJHrkKXXso\nLOekBlrIkGHFgSJ96Y3L/S7DVwQyACgw3eGoAsPMZN7aFR+/U8cYMiDjCGQAUGC6+/qH3Z6Ypb+e\nLksg4whkAFBAnHPqDkflXHzMWPIkmolZ+umyBDIvd68PBQCMWW8kJucNH+vqHbxUTaKFjC5LIPMI\nZABQQLr6DoewYG9k0HNt3WEVmVRbSSADMo1ABgAFJHkB56GBrKU7rCmVpTm7FiCQywhkAFBAkgf0\nB3uO7LJkUljAHwQyACggyS1kncN0WXKFJeAPAhkAFJDBY8iGtpCFVUcLGeALAhkAFJBQ+HCX5dAW\nstbusBq4whLwBYEMAApId3ILWdIYsnA0po6eCOtYAj4hkAFAAUluIUu+yrI9FJ8UlkH9gD8IZABQ\nQBJjyKZUlgzqskysY8ks/YA/CGQAUEBC4aiKi0wNk8oGdVm2didm6afLEvADgQwACkh3X78qSwOq\nrihRZ9/hFrK2brosAT8RyACggITCUVWVFau6vHhQC1mL12VZz1WWgC8IZABQQBItZJPLSwYN6m/r\n7lNxkam6vMTH6oDCRSADgALSHY5qUlmxqiuK1Zk0MWxrV1hTqkpVxDqWgC8IZABQQEJ9/aosLY63\nkPVE5JyTJDV39qlhEgP6Ab8QyACggHT1RVVVFlB1eYmiMafeSEyStPdQj2bXlvtcHVC4CGQAUEAG\nBvVXFEs6PDnsvkM9mlVb4WdpQEEr9rsAAEDmdIcPd1lK8fUsK0sDCvZGNZtABviGQAYABSTUF1VV\naUDV5fEf/x09UfXHeiWJFjLARwQyACgQsZiLt5CVHW4hC/ZGFOyJd1sSyAD/EMgAoED0ROILi08q\nC6jGG0PW2RsdCGRzphDIAL8wqB8ACkR3OD7vWPIYsmBPRHsP9agkYJrKtBeAbwhkAFAgQn3xFrLE\ntBdSvIVs36EezagpZ1JYwEcEMgAoEF19h1vIykuKVBIwBXsj2neohyssAZ8RyACgQITCiTFkxTIz\nTS4vUWdvRHvbmYMM8BuBDAAKxOExZAFJUnV5sdq7IzoQ7KWFDPAZgQwACkS312VZVRa/wnJyeYm2\nHOxUzDHlBeA3AhkAFIjEoP6BFrKKYm1v7pYkWsgAnxHIAKBAJLosJ3ktZIkFxiVayAC/EcgAoEAk\nBvVXlia6LA/PDT6rttyXmgDEEcgAoEB09UVVEjCVFsd/9CfmIqurKh0IaQD8QSADgAIR6osOCl6J\n2fppHQP8l9ZAZmaXm9krZrbVzG4a5vn3mlmzma3zbh9IZz0AUMi6w/0D48ek+KB+SZpVw/gxwG9p\na6M2s4CkWyVdKqlR0hozW+2c2zhk1187525IVx0AgLhQODpwhaV0uIVsNouKA75LZwvZWZK2Oue2\nO+fCku6UdFUa3w8AMIquvn5VJreQeYP6mfIC8F86A9lsSXuSHjd624Z6s5m9aGa/NbO5aawHAApa\nqC+qqqQWsuqKxBgyAhngt3QGMhtmmxvy+H8lLXDOnSLpYUl3DHsgs+vNbK2ZrW1ubp7gMgGgMHSH\n+wdm6Zek0+fV6qN/s0QXLJ3qY1UApPQGskZJyS1ecyTtS97BOdfqnOvzHv5Q0quGO5Bz7jbn3Arn\n3IqpU/nBAQDj0T2khaysOKBPvub4QSENgD/SGcjWSDrOzBaaWamkayWtTt7BzGYmPbxS0qY01gMA\nBS0Ujg4aQwYge6TtO9M5FzWzGyQ9ICkg6SfOuQ1m9nlJa51zqyV9zMyulBSV1CbpvemqBwAKXXdf\n/6AWMgDZI61/Kjnn7pd0/5Btn026f7Okm9NZAwBA6o859UT66Z4EshQz9QNAAQh5C4tXsUQSkJUI\nZABQAAYWFi+jyxLIRgQyACgA3X20kAHZjEAGAAUg0ULGGDIgOxHIAKAAdA20kNFlCWQjAhkAFIDE\noH7mIQOyE4EMAApAe3dEklTjrV8JILsQyACgABwI9kqSZtaU+1wJgOEQyACgAOzv6NGUyhKVlzCG\nDMhGBDIAKAAHOno1o6bC7zIAjIBABgAFYH9Hr2ZUl/ldBoAREMgAoADQQgZkNwIZAOS5vmi/WrvD\nDOgHshiBDADy3MFgnyRpBoEMyFoEMgDIc/s7mPICyHYEMgDIc/s7eiQRyIBsRiADgDx3wGshY1A/\nkL0IZACQ5/Z39GpyWbEmsY4lkLUIZACQ5+JTXtBdCWQzAhkA5Ln9QQIZkO0IZACQ5w509GhGNYEM\nyGYEMgDIY9H+mJo7+7jCEshyBDIAyGPNXX2KOa6wBLIdgQwA8hiTwgK5gUAGAHns8BxkBDIgmxHI\nACCP0UIG5AYCGQDksQMdPSovKVJNRYnfpQAYBYEMAPLY/o5ezaypkJn5XQqAUbCOBgDkoF2t3Wrp\nCh91v+3N3cxBBuQAAhkA5JjO3ogu+eajivS7lPa/9sy5aa4IwLEikAFAjtl3qFeRfqeP/s0SrVhQ\nd9T9T5tbm4GqABwLAhkA5JgDwfiVk6uWTtWZKQQyANmPQf0AkGOavEA2fTJjw4B8QSADgBxz0Atk\n06rLfK4EwEQhkAFAjmkK9qmmokTlJQG/SwEwQQhkAJBjDgR7mcoCyDMEMgDIMQeDvXRXAnmGQAYA\nOaYp2KfptJABeYVABgA5pD/m1NzVR5clkGcIZACQQ1q7+tQfc5pOlyWQVwhkAJBDmoJ9kqRptJAB\neeWoM/Wb2UpJt0ia7+1vkpxzblF6SwMADJWYpZ8xZEB+SWXppB9L+rikv0rqT285AIDRJGbpZwwZ\nkF9SCWQdzrk/pL0SAMBRHQz2ykxqmFTqdykAJlAqY8j+ZGZfN7NzzeyMxC2Vg5vZ5Wb2ipltNbOb\nRtnvLWbmzGxFypUDQAFqCvapYVKZigMMAQbySSotZGd7/yaHJSfpb0Z7kZkFJN0q6VJJjZLWmNlq\n59zGIftNlvQxSc+kWjQAFCpm6Qfy01EDmXPuonEe+yxJW51z2yXJzO6UdJWkjUP2+4Kkr0n61Djf\nBwAKRlOwV3OmVPhdBoAJdtQ2bzOrMbNvmtla7/bvZlaTwrFnS9qT9LjR25Z87NMlzXXO3TumqgGg\nQB3s7GPKCyAPpTII4SeSOiW91bsFJf00hdfZMNvcwJNmRZK+JemTRz2Q2fWJQNjc3JzCWwNA/umL\n9qutO0yXJZCHUhlDttg59+akx58zs3UpvK5R0tykx3Mk7Ut6PFnSyZL+bGaSNEPSajO70jm3NvlA\nzrnbJN0mSStWrHACgAJ00JsUlln6gfyTSgtZj5mdn3jgTRTbk8Lr1kg6zswWmlmppGslrU486Zzr\ncM41OOcWOOcWSHpa0hFhDAAQd7AzPgcZXZZA/kmlhezDku7wxo2ZpDZJ7z3ai5xzUTO7QdIDkgKS\nfuKc22Bmn5e01jm3evQjAACSJZZNmj6ZQAbkm1Suslwn6VQzq/YeB1M9uHPufkn3D9n22RH2vTDV\n4wJAITrQ4c3SX0MgA/LNiIHMzP7WOfdzM/vEkO2SJOfcN9NcGwDkrZ5wv+59cZ/C/bGUX/PYlmaV\nBExTKkvSWBkAP4zWQlbl/Tt5mOcYWA8Ax+Du5xv1mXvWj/l1J8+uHvjDGED+GDGQOed+4N192Dn3\nRPJz3sB+AMA4vdTYoZqKEj348VXDzhE0khpax4C8lMqg/u9IGrp25XDbAAApWr+vQ8tn12g6V0wC\n0OhjyM6VdJ6kqUPGkVUrftUkAGAcwtGYXjnQqevOX+h3KQCyxGgtZKWSJnn7JI8jC0p6SzqLAoB8\ntrmpU5F+p5NnpbIKHYBCMNoYskclPWpmtzvndmWwJgDIa+v3dkiSls8mkAGIS2UMWcjMvi7pJEkD\ngx2cc3+TtqoAII+t39ehyWXFmldX6XcpALJEKksn/ULSy5IWSvqcpJ2KL4sEABiHl/YGtWxWtYqK\nmL4CQFwqgazeOfdjSRHn3KPOuesknZPmugAgL0X6Y9q0P0h3JYBBUumyjHj/7jez10naJ2lO+koC\ngPy1rblL4WhMJxPIACRJJZB90VtY/JOKzz9WLenjaa0KAPLU+r3x5YBPnl3tcyUAskkqi4vf693t\nkHRRessBgPy2fm+HKksDWtgwye9SAGSR0SaG/Y5GWbPSOfextFQEAHniTy8f1K7W7kHbHtvSrGUz\nqxVgQD+AJKO1kK31/l0paZmkX3uPr5H013QWBQC5LhyN6f13rFFsmD9rX3/xrMwXBCCrjTYx7B2S\nZGbvlXSRcy7iPf6+pAczUh0A5Khgb0QxJ/3T5Sfo2jPnDmw3k2oqWCAcwGCpDOqfpfjSSW3e40ne\nNgDACII98QvUZ9SUaUpVqc/VAMh2qQSyr0h63sz+5D2+QNItaasIAPJAZ29UklRdTmsYgKNL5SrL\nn5rZHySd7W26yTl3IL1lAUBuC/bGW8gmE8gApGDEmfrN7ATv3zMU76Lc491medsAACMI9ngtZBWp\ndEQAKHSj/aT4pKQPSvr3YZ5zklhcHABGkGgho8sSQCpGu8ryg96/TAYLAGPUmQhkXFEJIAWjTQz7\nptFe6Jy7e+LLAYD8EOyJqsikqtKA36UAyAGjdVm+YZTnnCQCGQCMINgb0eTyEpkxIz+Aoxuty/J9\nmSwEAPJJsCfCgH4AKUvpp4WZvU7SSZLKE9ucc59PV1EAkOs6e6MM6AeQshGnvUjwlkp6m6SPSjLF\n17Kcn+a6ACCnBXsjBDIAKTuYpt4OAAAgAElEQVRqIJN0nnPu3ZLanXOfk3SupLlHeQ0AFLRgT1ST\ny+myBJCaVAJZj/dvyMxmSYpIWpi+kgAg9wV7I0x5ASBlqfz5dq+Z1Ur6uqTnFL/C8odprQoAchxj\nyACMxWjzkJU45yLOuS94m35nZvdKKnfOdWSmPADIPdH+mLr6olxlCSBlo3VZ7jWzH5rZ35g3kY5z\nro8wBgCj6+rz1rGkhQxAikYLZCdKWivpXyXtMbP/MLOzM1MWAOSuxMLiDOoHkKoRA5lzrtU59wNv\nLcuzJO2Q9B9mts3MvpSxCgEgxwRZxxLAGKVylaWcc/sk/VjS9yR1SvpAOosCgFw2EMjosgSQolED\nmZmVm9k1Zna3pG2SLpZ0s6RZmSgOAHJRosuSQf0AUjXaVZa/lHSJpMck/VLSO5xzvZkqDAByFS1k\nAMZqtD/fHpD0d865zkwVAwD5oLOXqywBjM2Igcw5d0cmCwGAfBHsibeQTeIqSwApSmlQPwAgdcHe\niCaXFStQZH6XAiBHEMgAYIIFe6JMeQFgTI4ayMys0sz+1cx+6D0+zsxen/7SACA3dfZGmBQWwJik\n0kL2U0l9ks71HjdK+mLaKgKAHBfsjTCgH8CYpBLIFjvnviYpIknOuR5JDIwAgBHEuyxpIQOQulQC\nWdjMKiQ5STKzxYq3mAEAhkELGYCxSiWQ/ZukP0qaa2a/kPSIpE+ncnAzu9zMXjGzrWZ20zDPf8jM\nXjKzdWb2uJktG1P1AJCFOnujjCEDMCaj/sQwM5P0sqQ3STpH8a7KG51zLUc7sJkFJN0q6VLFx52t\nMbPVzrmNSbv90jn3fW//KyV9U9Ll4zkRAMgGsZhTZ2+EqywBjMmogcw558zs9865V0m6b4zHPkvS\nVufcdkkyszslXSVpIJA554JJ+1fJ6xYFgFzVHY4q5pilH8DYpNJl+bSZnTmOY8+WtCfpcaO3bRAz\n+4iZbZP0NUkfG+5AZna9ma01s7XNzc3jKAUAMiPYy8LiAMYulUB2kaSnzGybmb3ojfl6MYXXDXcl\n5hEtYM65W51ziyX9k6R/Ge5AzrnbnHMrnHMrpk6dmsJbA4A/OllYHMA4pPIn3BXjPHajpLlJj+dI\n2jfK/ndK+t443wsAskKwJ95CNplABmAMjtpC5pzbJalW0hu8W6237WjWSDrOzBaaWamkayWtTt7B\nzI5Levg6SVtSLRwAslFiYXG6LAGMRSpLJ90o6ReSpnm3n5vZR4/2OudcVNINkh6QtEnSXc65DWb2\nee+KSkm6wcw2mNk6SZ+Q9J5xngcAZIUgXZYAxiGVP+HeL+ls51y3JJnZVyU9Jek7R3uhc+5+SfcP\n2fbZpPs3jqlaAMhynQOD+glkAFKXSiAzSf1Jj/vF0kkACoxzTn3R2FH3a+sOSxITwwIYk1R+YvxU\n0jNmdo/3+GpJP05fSQCQfT5x1wu65/m9Ke1bVRpQSSCVi9gBIO6ogcw5900z+7Ok8xVvGXufc+75\ndBcGANnk8a0tOm1urV5z0vSj7nv89MkZqAhAPjlqIDOzcyRtcM495z2ebGZnO+eeSXt1AJAF2rrD\nau7s0/WvXqQPrlrkdzkA8lAqberfk9SV9LhbzBcGoIC8cqBTknT8DFq+AKRHKoHMnHMDM+w752JK\nbewZAOSFzU0EMgDplUog225mHzOzEu92o6Tt6S4MALLFywc6VVNRommTy/wuBUCeSiWQfUjSeZL2\nerezJV2fzqIAIJtsburU8TMmy4wZfwCkRypXWR5UfNkjACg4zjltPtCpq0+f7XcpAPLYiC1kZvbB\nxFqTFvcTM+swsxfN7IzMlQgA/tnX0avOvijjxwCk1WhdljdK2undf7ukUyUtUnzNyW+ntywAyA6v\nHAhKYkA/gPQaLZBFnXMR7/7rJf3MOdfqnHtYUlX6SwOAY/erZ3frHT98Ws2dfeN6/SsH4rP+LGWy\nVwBpNFogi5nZTDMrl3SxpIeTnqtIb1kAMDGe2NqiJ7e16i3ff1K7W0Njfv3mpk7NrClXDYuFA0ij\n0Qb1f1bSWkkBSaudcxskycwuENNeAMgRrV1hza6tUEdPRG/63pO6bMjSR2bS1afN1ooFdcO+/uUD\nnbSOAUi7EQOZc+5eM5svabJzrj3pqbWS3pb2ygBgArR292n57Bp96rKl+tiv1umBDQcGPd8T7tdd\naxr19WtO0VWnDb6SMtof07aDXVp1XEMmSwZQgEad9sI5F5XUPmRbd1orAoAJ1NoV1pkLSrVk2mTd\nf+Orj3i+IxTR9f+9VjfeuU6vHOjUCTOrk17bp3B/jBYyAGnHEkgA8lZ/zKktFFb9pJFn2K+pLNHP\n3n+WPvWbF/Vff9427D6nzq1NV4kAIIlABiCPtYfCck5qmFQ66n5lxQH957Wn6VOvWapIvxv03KSy\nYs2oKU9nmQAwvkBmZic4516e6GIAYCK1doUlSfVVR1+D0sw0v54ZfQD4I5W1LIfz4IRWAeCYOOfk\nnDv6jgWmtSs+91hd1egtZADgtxFbyMzsP0d6ShIDKoAscvE3H9Xbz5ynD65a5HcpWaWlO95CdrQu\nSwDw22gtZO+TtF7SX4fc1koKp780AKnojfRre3O3bn9yp2IxWsmSJVrIRhvUDwDZYLQxZGskrXfO\nPTn0CTO7JW0VARiT9lD876O9h3r01PZWrVzCnFkJbd1hFZlUyyz7ALLcaC1kb5G0brgnnHML01MO\ngLFq744M3P/N2j0+VpJ9WrrCqqsqU1GR+V0KAIxqtEA2yTk39oXfAGTUIa+F7Lhpk/SH9QcU7I0c\n5RUT52Bnr+5+rjFrLyho7epj/BiAnDBaIPt94o6Z/S4DtQAYh/ZQPIB98NWL1BeN6b4X92fkfTft\nD+rq7z6hT9z1gva09WTkPceqtTusegIZgBww2hiy5DZ+Lt0CslRiDNmFx0/VkmmT9POnd6lhyCD2\nyeXFOnthnczi39axmNPT21vVHe4f13s2d/bpS/dtHJhEtbmrT/PqK4/hLNKjtatPp8zhonAA2W+0\nQOZGuA8giyS6LGsrS3XtmXP1xfs26YM/W3vEflefNktfefMp6o85feKudXpgQ9Mxve9Js6r18UuW\n6gM/WztwNWO2ae0KMwcZgJwwWiA71cyCireUVXj35T12zrnqkV8KIFPaQxFVlQZUWlyk961cqJVL\nGtQ/ZPqLRzYd1Lce3qwdrSH1Rfq1ualTN19xwjFdkbl0+mS1dseDWGt39s2E0xvpV2dflDFkAHLC\niIHMORfIZCEAxqc9FFZtZTx0BIpMJ8488m+lk2fX6ISZk/XxX69ToMj00/edpQuWTj3m9060PrVl\nYSBL1MQcZAByAYuLAznuUCiiKVVHn2frspNm6MGPr1JxUdGELZZdVhzQ5PJitWRhl+XhdSxpIQOQ\n/QhkQI5rD4U1pTK10DFnysQPvK+vKh0IP9kk0Z1KCxmAXDDexcUBZIlDoYhqfJyJvn5S2UD4ySaJ\nkMgYMgC5gEAG5LixtJClAy1kAHDsCGRADuuPOXX0RDSl0t8WspZsDGRdYZUWF6mqlOuTAGQ/AhmQ\nw4I9ETmngass/dAwqVTtobBiseyarrClK6yGqtKByXABIJsRyIAclpilP5WrLNOlvqp0oKUum7R2\n99FdCSBnEMiAHJZYx9LPFrI6L/Rk28D+1i7WsQSQOwhkQA5LLJvk56D+Bm+er2wbR9ba1af6KlrI\nAOQGAhmQwxItZH4P6peUVVdaOufU0h1mygsAOYOJYYEclrywuF8S3YLZ0GUZizm1hcLqCfcrHI3R\nZQkgZxDIgBzWHgorUGSqLvfvW3lKZanMsqPL8jO/X69fPbt74PG0yROzRBQApBuBDMhh7aGIaitK\nfJ3aIVBkqqssVWsWrGe59WCnFk+t0nvPW6DS4iJddtIMv0sCgJQQyIAcdigUVq2P48cS6ieVqq3b\n/xaytu6wTphRrXedu8DvUgBgTNI6qN/MLjezV8xsq5ndNMzznzCzjWb2opk9Ymbz01kPkG/auyO+\nXmGZUJclyye1hyJZEVABYKzSFsjMLCDpVklXSFom6e1mtmzIbs9LWuGcO0XSbyV9LV31APmoPRT2\ndUB/Qv2kMrX4PKg/FnM6FAqrrsr//w8AGKt0tpCdJWmrc267cy4s6U5JVyXv4Jz7k3Mu5D18WtKc\nNNYD5J1DIX/XsUxoyIIWsmBvRDHn75xsADBe6QxksyXtSXrc6G0byfsl/WG4J8zsejNba2Zrm5ub\nJ7BEILe1h8KakgUtQvWTytTRE1E4GvOthsQYNlrIAOSidAay4S77Gnb1YTP7W0krJH19uOedc7c5\n51Y451ZMnTp1AksEcldPuF990VhWjJlKzPeVWFvTD4eXkfL//wMAxiqdgaxR0tykx3Mk7Ru6k5ld\nIukzkq50zvl/3TyQIxLhp7bC/xahxBJFLT5OfdFOCxmAHJbOQLZG0nFmttDMSiVdK2l18g5mdrqk\nHygexg6msRYg7xzKgmWTEhJLFPk59UVbFqzrCQDjlbZA5pyLSrpB0gOSNkm6yzm3wcw+b2ZXert9\nXdIkSb8xs3VmtnqEwwEYIhuWTUpItEr5ObA/0UKWDWPqAGCs0joxrHPufkn3D9n22aT7l6Tz/YF8\nNrCweJX/LWSJBcZ97bIMRVQaKFJVacC3GgBgvNI6MSyA9GnPoi666vJilQRMrT52WbZ3hzWlyt9l\npABgvFg6Ccghzjn9+4Obtb+jV5ubOiVlx1WFZqb6qjJf17NsC4WzIpwCwHgQyIAcsqetR9/901bV\nVZWqoiSgi0+YprLi7Oiim15dpv0dvb69/yECGYAcRiADcsjO1m5J0vfeeYbOXlTvczWDza+v0ro9\nh3x7/8TC4gCQixhDBuSQXV4gW9BQ5XMlR1pQX6nG9pBvs/WzsDiAXEYgA3LIztaQykuKNG1ymd+l\nHGF+fZViTtp7qCfj783C4gByHYEMyCG7WkOaX1eVlVcSzq+vlHS4WzWTWFgcQK4jkAE5ZFdr90Dw\nyTbz6+PdqLtaMh/IWFgcQK4jkAE5IhZz2tUWysrxY1J8+aSq0oB2tYUy/t4sLA4g1xHIgBxxINir\ncDSWtS1kZqb59VXa1epDIKOFDECOI5ABOSIxNmtBfXa2kEnSgoZKX8aQsbA4gFxHIANyRKLlKVtb\nyKT4OLI9bSH1x1xG35eFxQHkOgIZkCN2tnarNFCkmTUVfpcyogX1lYr0O+3L8NQXLCwOINcRyIAc\nsaslpDl1FQoUZd+UFwnz6rwrLTM8joyFxQHkOgIZkCN2tnZn9fgxKT6GTMr8XGQsLA4g1xHIgBzg\nnNPutlBWjx+TpOmTy1VWXDSwxFOmsLA4gFxHIANyQHNXn0Lh/qxvISsqMs2vr9TODHdZtnWzbBKA\n3EYgA3JALlxhmTC/vkq7Mz2GjIXFAeQ4AhmQA3a2ZP8cZAkL6iu1q61bsQxNfcHC4gDyQbHfBQCQ\nwtGYfvdco3rC/cM+/9iWZgWKTLOnZO+UFwnz66vUG4npv/68VZWlh3/ElJUU6c1nzFF5yfinpghH\nY3p4U5MuOn6aKrwpLlhYHEA+IJABWeDxrc26+e6XRt3ntLm1Kglkf6P2qXNqVWTSNx7cfMRz1eUl\nesOps8Z97Htf3KdP3PWCZtdW6ObXnqDXLZ/JwuIA8gKBDMgCO1riY67+/KkLR2zpqSrLjUlPl8+p\n0frPXaZI9HCXZV+0X2d9+ZFjvvpyR0u3AkWm6ooS3fDL5/WPJS/KKf4+zNIPIJcRyIAssLu1W5PK\nijW/vjIvJjetLC2WBuWjEk2bXHbME8buag1pVm257v3o+br7uUa9cqAz/n5lxTp7Yd0xHRsA/EQg\nA7LA7raQ5tblRxgbyby6Su1uO7ZAtrstpHl1lQoUma5ZMXeCKgMA/2X/gBSgAOxqC2l+XfZPaXEs\n5tVPVCDL/itNAWCsCGSAz2Ixp8a2npyYY+xYzKur1IFgr3ojw19JejSdvRG1dYc1L8+DK4DCRCAD\nfHYg2Ktwf0xz8zxozK+vlHNSY3vPuF6faF3L9+AKoDARyACfFUrQSLRs7Rlnt2XidbSQAchHBDLA\nZ4llhvI9aCTGfo136ovEFZrz8jy4AihMBDLAZ7vbQgoUmWbVZv8s/MeiYVKpKksD2t02/i7LKZUl\nqi5nzUoA+YdABvhsV1tIs2srcmIW/mNhZt7UF+NrIUtMeQEA+Si/fwMAOWB3a3fBBI15dZXjnhx2\nV2tI83JgcXUAGA8CGeCz3W2hghkXlZgc1jl39J2TRPtj2nuoR/Pq8rtbF0DhIpABPgr2RtQeihRM\nC9n8+kr1RWM62Nk3ptftO9Sr/pjTfCaFBZCnCGSAjxJXWOb7LP0JibnWxjpjf2L/fJ+rDUDhIpAB\nPkoEjULpspxfn5j6YmyBbJd3IUC+z9UGoHARyAAf7S6wyU5n11aoyMbXQlYaKNL06vI0VQYA/iKQ\nAT7a1RpSXVWpJhfI3FqlxUWaWVOh3WOcHHZ3a0hz6ioUKLI0VQYA/ir2uwCg0LR1h/WTx3co3B/T\nE1tbCm5c1Ly6Sj27o01fvn9Tyq95bne7TpxZncaqAMBfBDIgwx7e2KTv/mmrykuKZDJdffpsv0vK\nqAuOn6pvP3xI//3UrjG97tXHTU1TRQDgPwIZkGEdPRFJ0prPXFIwXZXJPnTBYn3ogsV+lwEAWYUx\nZECGdfREVGRSVSl/DwEA4ghkQIYFeyOqrihREQPUAQAeAhmQYcGeiKoLsKsSADCytAYyM7vczF4x\ns61mdtMwz68ys+fMLGpmb0lnLUC26OiJqLqC7koAwGFpC2RmFpB0q6QrJC2T9HYzWzZkt92S3ivp\nl+mqA8g2wd6oaipoIQMAHJbOFrKzJG11zm13zoUl3SnpquQdnHM7nXMvSoqlsQ4gq9BlCQAYKp2B\nbLakPUmPG71tY2Zm15vZWjNb29zcPCHFAX7pIJABAIZIZyAb7hIyN54DOeduc86tcM6tmDqVySGR\n24K9EdVUEsgAAIelM5A1Spqb9HiOpH1pfD8g6/VF+9Ubiam6nEH9AIDD0hnI1kg6zswWmlmppGsl\nrU7j+wFZr7M3KkmqZlA/ACBJ2gKZcy4q6QZJD0jaJOku59wGM/u8mV0pSWZ2ppk1SrpG0g/MbEO6\n6gGyQWLZJMaQAQCSpbXfxDl3v6T7h2z7bNL9NYp3ZQIFIegFMqa9AAAkY6Z+IIOCA12WjCEDABxG\nIAMyiC5LAMBwCGRABtFlCQAYDoEMyKBgr9dCRiADACQhkAEZFOyJqjRQpLJivvUAAIfxWwHIoI6e\niKorimU23EIWAIBCRSADMijYG6G7EgBwBAIZkEFBFhYHAAyDQAZkULCHFjIAwJEIZEAGBXujTHkB\nADgCgQzIoHiXJbP0AwAGI5ABGeKcY1A/AGBYBDIgQ3oi/Yr0O7osAQBHIJABGRLs8RYW5ypLAMAQ\nBDIgQw4vm8QYMgDAYAQyIEM6vIXFaSEDAAxFIAMyJOgFMsaQAQCGIpABGXK4y5JABgAYjEAGZEhH\nKNFlyRgyAMBgBDIgQ4K93lWWtJABAIYgkAEZEuyJqLI0oJIA33YAgMH4zQBkSLA3whWWAIBhEciA\nDOnoiTAHGQBgWAQyIEOCPVGmvAAADItABmQIXZYAgJHQfwJMkJ0t3fqfdfvk5IZ9fu+hHi2dPjnD\nVQEAcgGBDJggt/1lu375zO5R9zl5dk2GqgEA5BICGTBBGtt7tHx2jVbfsHLEfcwsgxUBAHIFY8iA\nCbK3PaTZtRUysxFvAAAMh0AGTADnnPYd6tXsKRV+lwIAyEEEMmACtIci6on0a3YtgQwAMHYEMmAC\n7G3vkSTNIpABAMaBQAZMgL2HQpKkOXRZAgDGgUAGTIC9h3oliS5LAMC4EMiACbC3vUeVpQHVVjIT\nPwBg7AhkwATYeyikWd6UFwAAjBWBDJgAew/10F0JABg3AhkwAZiDDABwLAhkwDEKhaNq6w7TQgYA\nGDcCGXCM9h2Kz0FGIAMAjBeBDDhGjd6ksHRZAgDGi0AGHKN9zEEGADhGBDLgGO09FFKgyDS9utzv\nUgAAOYpABhyjve09mlFdrkARc5ABAMYnrYHMzC43s1fMbKuZ3TTM82Vm9mvv+WfMbEE66wHSYe+h\nHsaPAQCOSdoCmZkFJN0q6QpJyyS93cyWDdnt/ZLanXNLJH1L0lfTVQ+QLvsO9WoO48cAAMegOI3H\nPkvSVufcdkkyszslXSVpY9I+V0m6xbv/W0nfNTNzzrk01jWqtu6wNjd1+vX2yDHOSQeCTAoLADg2\n6QxksyXtSXrcKOnskfZxzkXNrENSvaSWNNY1qjU72/R3//1Xv94eOWphQ5XfJQAAclg6A9lwI5yH\ntnylso/M7HpJ10vSvHnzjr2yUayYP0W//ODQ3AiMrDRQpNPm1vpdBgAgh6UzkDVKmpv0eI6kfSPs\n02hmxZJqJLUNPZBz7jZJt0nSihUr0tqdWT+pTOdNKkvnWwAAAAySzqss10g6zswWmlmppGslrR6y\nz2pJ7/Huv0XS//k5fgwAAMAPaWsh88aE3SDpAUkBST9xzm0ws89LWuucWy3px5L+28y2Kt4ydm26\n6gEAAMhW6eyylHPufkn3D9n22aT7vZKuSWcNAAAA2Y6Z+gEAAHxGIAMAAPAZgQwAAMBnBDIAAACf\nEcgAAAB8RiADAADwGYEMAADAZwQyAAAAnxHIAAAAfEYgAwAA8BmBDAAAwGcEMgAAAJ+Zc87vGsbE\nzJol7Urz2zRIaknze2Qzzp/zL9TzL+Rzlzh/zr9wzz+d5z7fOTf1aDvlXCDLBDNb65xb4XcdfuH8\nOf9CPf9CPneJ8+f8C/f8s+Hc6bIEAADwGYEMAADAZwSy4d3mdwE+4/wLWyGffyGfu8T5c/6Fy/dz\nZwwZAACAz2ghAwAA8BmBbAgzu9zMXjGzrWZ2k9/1pJuZzTWzP5nZJjPbYGY3ettvMbO9ZrbOu73W\n71rTwcx2mtlL3jmu9bbVmdlDZrbF+3eK33Wmg5kdn/T5rjOzoJn9Qz5/9mb2EzM7aGbrk7YN+3lb\n3H96PwteNLMz/Kt8Yoxw/l83s5e9c7zHzGq97QvMrCfp6+D7/lV+7EY49xG/1s3sZu+zf8XMLvOn\n6okzwvn/Ouncd5rZOm97Xn320qi/67Ln+985x827SQpI2iZpkaRSSS9IWuZ3XWk+55mSzvDuT5a0\nWdIySbdI+pTf9WXg/HdKahiy7WuSbvLu3yTpq37XmYH/h4CkA5Lm5/NnL2mVpDMkrT/a5y3ptZL+\nIMkknSPpGb/rT9P5v0ZSsXf/q0nnvyB5v1y/jXDuw36tez8DX5BUJmmh93sh4Pc5TPT5D3n+3yV9\nNh8/e++cRvpdlzXf/7SQDXaWpK3Oue3OubCkOyVd5XNNaeWc2++ce8673ylpk6TZ/lblu6sk3eHd\nv0PS1T7WkikXS9rmnEv3pMu+cs49JqltyOaRPu+rJP3MxT0tqdbMZmam0vQY7vydcw8656Lew6cl\nzcl4YRkwwmc/kqsk3emc63PO7ZC0VfHfDzlrtPM3M5P0Vkm/ymhRGTTK77qs+f4nkA02W9KepMeN\nKqBwYmYLJJ0u6Rlv0w1eU+1P8rXbTpKT9KCZ/dXMrve2TXfO7Zfi38SSpvlWXeZcq8E/jAvhs08Y\n6fMuxJ8H1yneKpCw0MyeN7NHzezVfhWVZsN9rRfaZ/9qSU3OuS1J2/L2sx/yuy5rvv8JZIPZMNsK\n4jJUM5sk6XeS/sE5F5T0PUmLJZ0mab/izdn5aKVz7gxJV0j6iJmt8rugTDOzUklXSvqNt6lQPvuj\nKaifB2b2GUlRSb/wNu2XNM85d7qkT0j6pZlV+1Vfmoz0tV5Qn72kt2vwH2R5+9kP87tuxF2H2ZbW\nrwEC2WCNkuYmPZ4jaZ9PtWSMmZUo/gX6C+fc3ZLknGtyzvU752KSfqgcb64fiXNun/fvQUn3KH6e\nTYmmae/fg/5VmBFXSHrOOdckFc5nn2Skz7tgfh6Y2XskvV7SO503gMbrrmv17v9V8XFUS/2rcuKN\n8rVeSJ99saQ3Sfp1Ylu+fvbD/a5TFn3/E8gGWyPpODNb6LUaXCtptc81pZU3duDHkjY5576ZtD25\nr/yNktYPfW2uM7MqM5ucuK/44Ob1in/m7/F2e4+k//GnwowZ9NdxIXz2Q4z0ea+W9G7vaqtzJHUk\nujbyiZldLumfJF3pnAslbZ9qZgHv/iJJx0na7k+V6THK1/pqSdeaWZmZLVT83J/NdH0Zcomkl51z\njYkN+fjZj/S7Ttn0/e/3lQ/ZdlP8yorNiv9F8Bm/68nA+Z6veDPsi5LWebfXSvpvSS9521dLmul3\nrWk490WKX0n1gqQNic9bUr2kRyRt8f6t87vWNP4fVEpqlVSTtC1vP3vFg+d+SRHF/wJ+/0ift+Jd\nFrd6PwtekrTC7/rTdP5bFR8rk/j+/76375u974sXJD0n6Q1+15+Gcx/xa13SZ7zP/hVJV/hdfzrO\n39t+u6QPDdk3rz5775xG+l2XNd//zNQPAADgM7osAQAAfEYgAwAA8BmBDAAAwGcEMgAAAJ8RyAAA\nAHxGIAOQ9bxlbQ6a2foh2+vM7CEz2+L9e8QyT2Z2oZl1mNm6pNslE1jbe83suxN1PACFiUAGIBfc\nLunyYbbfJOkR59xxis8hdNMIr/+Lc+60pNvDaaoTAMaFQAYg6znnHpPUNsxTV0m6w7t/h6SrUz2m\nmS0ws5fN7A5vcenfmlml99zF3sLKL3mtc2Xe9jPN7Ekze8HMnk2s9CBplpn90Wup+5q3b8DMbjez\n9d5xPj7e8weQ/whkAHLZdOctZ+L9O22E/V49pMtysbf9eEm3OedOkRSU9PdmVq54i9zbnHPLJRVL\n+rC3nNqvJd3onDtV8SVnerzjnCbpbZKWS3qbmc31ts12zp3sHeenE3vqAPIJgQxAIRjaZbnN277H\nOfeEd//nii+vcrykHbQJRqIAAAFgSURBVM65zd72OySt8rbvd86tkSTnXNA5F/X2ecQ51+Gc65W0\nUdJ8xdf+W2Rm3/HWiwym/SwB5CwCGYBc1pRYINr79+AYXz907Tin+Bp2w7Fh9k/oS7rfL6nYOdcu\n6VRJf5b0EUk/GmNtAAoIgQxALlst6T3e/fdI+p8xvn6emZ3r3X+7pMclvSxpgZkt8ba/S9Kj3vZZ\nZnamJJnZZDMrHunAZtYgqcg59ztJ/yrpjDHWBqCAEMgAZD0z+5WkpyQdb2aNZvZ+76mvSLrUzLZI\nutR7PJyhY8je4m3fJOk9ZvaipDpJ3/O6Hd8n6Tdm9pKkmKTvO+fCio8T+46ZvSDpIUnlo5Q9W9Kf\nzWyd4mPSbh7f2QMoBObcSC3wAJC/zGyBpHudcyf7XAr+fzt2TAMAAAAgqH9rY/hACifgkAEA3Bwy\nAICZQwYAMBNkAAAzQQYAMBNkAAAzQQYAMBNkAACzAIC012a/2dHfAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7e38e5aef668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10,7))\n",
    "plt.plot(f1_p)\n",
    "plt.xlabel('10 Epochs')\n",
    "plt.ylabel('F1 Score Validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T15:58:36.165485Z",
     "iopub.status.busy": "2023-12-22T15:58:36.165068Z",
     "iopub.status.idle": "2023-12-22T15:58:36.350980Z",
     "shell.execute_reply": "2023-12-22T15:58:36.350055Z",
     "shell.execute_reply.started": "2023-12-22T15:58:36.165415Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Accuracy')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmEAAAGtCAYAAABeN6MZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIUySJGkA/wtCyXSW/oWJfAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7e38f9d97eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10,7))\n",
    "plt.plot(d_l_p)\n",
    "plt.xlabel('10 Epochs')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T15:58:36.353419Z",
     "iopub.status.busy": "2023-12-22T15:58:36.353007Z",
     "iopub.status.idle": "2023-12-22T15:58:36.359300Z",
     "shell.execute_reply": "2023-12-22T15:58:36.358401Z",
     "shell.execute_reply.started": "2023-12-22T15:58:36.353335Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91.5625\n"
     ]
    }
   ],
   "source": [
    "print(d_l_p[-1])"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 310,
     "sourceId": 23498,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 594,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
